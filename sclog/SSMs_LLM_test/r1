[0 - 7fd9a669a000]    0.242616 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7fd9a669a000]    0.242676 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7fd9a669a000]    0.242691 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7fd9a669a000]    0.242700 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7fd9a669a000]    0.242712 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7fd9a669a000]    0.263270 {3}{spec_infer}: Start execute function: top_level_task!
[0 - 7fd9a669a000]    0.263335 {3}{spec_infer}: paths.cache_folder_path is:/root/.cache/flexflow
[0 - 7fd9a669a000]    0.263351 {3}{spec_infer}: model_metadata.llm_model_config_path is:/models/opt-125m/config.json
[0 - 7fd9a669a000]    0.263354 {3}{spec_infer}: model_metadata.llm_tokenizer_path is:/models/opt-125m/
[0 - 7fd9a669a000]    0.263356 {3}{spec_infer}: model_metadata.llm_weights_path is:/models/opt-125m/half-precision
[0 - 7fd9a669a000]    0.264150 {3}{spec_infer}: model_metadata.llm_model_type is:3001
[0 - 7fd9a669a000]    0.264155 {3}{spec_infer}: model_metadata.llm_model_type is:3003
workSpaceSize (128 MB)
workSpaceSize (128 MB)
workSpaceSize (128 MB)
workSpaceSize (128 MB)
[0 - 7fd9a669a000]    0.560223 {3}{opt}: These are OPT model config:
OPT Config:
	do_layer_norm_before: 1
	dropout: 0.1
	enable_bias: 1
	ffn_dim: 3072
	hidden_size: 768
	layer_norm_elementwise_affine: 1
	max_position_embeddings: 2048
	num_attention_heads: 12
	num_hidden_layers: 12
	vocab_size: 50272
	word_embed_proj_dim: 768
	max_beam_width: 1
	max_beam_depth: 8
------start compile ----------
num_nodes = 1 num_gpus_per_node = 4
optimal_views.size = 106
views.size() = 106
Deserialized Views...
node[5000165]: type(ReLU_5000165) view(1 4 0)  inEdge(node(5000164) idx(0))
node[5000166]: type(Dense_5000166) view(1 4 0)  inEdge(node(5000165) idx(0))
node[5000167]: type(AllReduce_5000167) view(1 4 0)  inEdge(node(5000166) idx(0))
node[5000168]: type(ResidualLayerNorm_5000168) view(1 4 0)  inEdge(node(5000167) idx(0)) inEdge(node(5000163) idx(0))
node[5000169]: type(TreeIncMultiHeadSelfAttention_5000169) view(1 4 0)  inEdge(node(5000168) idx(1))
node[5000170]: type(AllReduce_5000170) view(1 4 0)  inEdge(node(5000169) idx(0))
node[5000171]: type(AddBiasResidualLayerNorm_5000171) view(1 4 0)  inEdge(node(5000168) idx(0)) inEdge(node(5000170) idx(0))
node[5000172]: type(Dense_5000172) view(1 4 0)  inEdge(node(5000171) idx(1))
node[5000173]: type(ReLU_5000173) view(1 4 0)  inEdge(node(5000172) idx(0))
node[5000174]: type(Dense_5000174) view(1 4 0)  inEdge(node(5000173) idx(0))
node[5000175]: type(AllReduce_5000175) view(1 4 0)  inEdge(node(5000174) idx(0))
node[5000176]: type(ResidualLayerNorm_5000176) view(1 4 0)  inEdge(node(5000175) idx(0)) inEdge(node(5000171) idx(0))
node[5000177]: type(TreeIncMultiHeadSelfAttention_5000177) view(1 4 0)  inEdge(node(5000176) idx(1))
node[5000178]: type(AllReduce_5000178) view(1 4 0)  inEdge(node(5000177) idx(0))
node[5000179]: type(AddBiasResidualLayerNorm_5000179) view(1 4 0)  inEdge(node(5000176) idx(0)) inEdge(node(5000178) idx(0))
node[5000180]: type(Dense_5000180) view(1 4 0)  inEdge(node(5000179) idx(1))
node[5000181]: type(ReLU_5000181) view(1 4 0)  inEdge(node(5000180) idx(0))
node[5000123]: type(AddBiasResidualLayerNorm_5000123) view(1 4 0)  inEdge(node(5000120) idx(0)) inEdge(node(5000122) idx(0))
node[5000182]: type(Dense_5000182) view(1 4 0)  inEdge(node(5000181) idx(0))
node[5000199]: type(AllReduce_5000199) view(1 4 0)  inEdge(node(5000198) idx(0))
node[5000200]: type(ResidualLayerNorm_5000200) view(1 4 0)  inEdge(node(5000199) idx(0)) inEdge(node(5000195) idx(0))
node[5000201]: type(TreeIncMultiHeadSelfAttention_5000201) view(1 4 0)  inEdge(node(5000200) idx(1))
node[5000202]: type(AllReduce_5000202) view(1 4 0)  inEdge(node(5000201) idx(0))
node[5000203]: type(AddBiasResidualLayerNorm_5000203) view(1 4 0)  inEdge(node(5000200) idx(0)) inEdge(node(5000202) idx(0))
node[5000204]: type(Dense_5000204) view(1 4 0)  inEdge(node(5000203) idx(1))
node[5000205]: type(ReLU_5000205) view(1 4 0)  inEdge(node(5000204) idx(0))
node[5000206]: type(Dense_5000206) view(1 4 0)  inEdge(node(5000205) idx(0))
node[5000207]: type(AllReduce_5000207) view(1 4 0)  inEdge(node(5000206) idx(0))
node[5000208]: type(ResidualLayerNorm_5000208) view(1 4 0)  inEdge(node(5000207) idx(0)) inEdge(node(5000203) idx(0))
node[5000209]: type(Dense_5000209) view(1 4 0)  inEdge(node(5000208) idx(1))
node[5000210]: type(Combine_5000210) view(1 1 0)  inEdge(node(5000209) idx(0))
node[5000211]: type(ArgMax_5000211) view(1 1 0)  inEdge(node(5000210) idx(0))
node[5000198]: type(Dense_5000198) view(1 4 0)  inEdge(node(5000197) idx(0))
node[5000197]: type(ReLU_5000197) view(1 4 0)  inEdge(node(5000196) idx(0))
node[5000196]: type(Dense_5000196) view(1 4 0)  inEdge(node(5000195) idx(1))
node[5000195]: type(AddBiasResidualLayerNorm_5000195) view(1 4 0)  inEdge(node(5000192) idx(0)) inEdge(node(5000194) idx(0))
node[5000194]: type(AllReduce_5000194) view(1 4 0)  inEdge(node(5000193) idx(0))
node[5000134]: type(Dense_5000134) view(1 4 0)  inEdge(node(5000133) idx(0))
node[5000193]: type(TreeIncMultiHeadSelfAttention_5000193) view(1 4 0)  inEdge(node(5000192) idx(1))
node[5000133]: type(ReLU_5000133) view(1 4 0)  inEdge(node(5000132) idx(0))
node[5000192]: type(ResidualLayerNorm_5000192) view(1 4 0)  inEdge(node(5000191) idx(0)) inEdge(node(5000187) idx(0))
node[5000132]: type(Dense_5000132) view(1 4 0)  inEdge(node(5000131) idx(1))
node[5000191]: type(AllReduce_5000191) view(1 4 0)  inEdge(node(5000190) idx(0))
node[5000131]: type(AddBiasResidualLayerNorm_5000131) view(1 4 0)  inEdge(node(5000128) idx(0)) inEdge(node(5000130) idx(0))
node[5000190]: type(Dense_5000190) view(1 4 0)  inEdge(node(5000189) idx(0))
node[5000130]: type(AllReduce_5000130) view(1 4 0)  inEdge(node(5000129) idx(0))
node[5000189]: type(ReLU_5000189) view(1 4 0)  inEdge(node(5000188) idx(0))
node[5000136]: type(ResidualLayerNorm_5000136) view(1 4 0)  inEdge(node(5000135) idx(0)) inEdge(node(5000131) idx(0))
node[5000137]: type(TreeIncMultiHeadSelfAttention_5000137) view(1 4 0)  inEdge(node(5000136) idx(1))
node[5000138]: type(AllReduce_5000138) view(1 4 0)  inEdge(node(5000137) idx(0))
node[5000139]: type(AddBiasResidualLayerNorm_5000139) view(1 4 0)  inEdge(node(5000136) idx(0)) inEdge(node(5000138) idx(0))
node[5000140]: type(Dense_5000140) view(1 4 0)  inEdge(node(5000139) idx(1))
node[5000141]: type(ReLU_5000141) view(1 4 0)  inEdge(node(5000140) idx(0))
node[5000142]: type(Dense_5000142) view(1 4 0)  inEdge(node(5000141) idx(0))
node[5000143]: type(AllReduce_5000143) view(1 4 0)  inEdge(node(5000142) idx(0))
node[5000144]: type(ResidualLayerNorm_5000144) view(1 4 0)  inEdge(node(5000143) idx(0)) inEdge(node(5000139) idx(0))
node[5000145]: type(TreeIncMultiHeadSelfAttention_5000145) view(1 4 0)  inEdge(node(5000144) idx(1))
node[5000146]: type(AllReduce_5000146) view(1 4 0)  inEdge(node(5000145) idx(0))
node[5000147]: type(AddBiasResidualLayerNorm_5000147) view(1 4 0)  inEdge(node(5000144) idx(0)) inEdge(node(5000146) idx(0))
node[5000148]: type(Dense_5000148) view(1 4 0)  inEdge(node(5000147) idx(1))
node[5000149]: type(ReLU_5000149) view(1 4 0)  inEdge(node(5000148) idx(0))
node[5000150]: type(Dense_5000150) view(1 4 0)  inEdge(node(5000149) idx(0))
node[5000151]: type(AllReduce_5000151) view(1 4 0)  inEdge(node(5000150) idx(0))
node[5000164]: type(Dense_5000164) view(1 4 0)  inEdge(node(5000163) idx(1))
node[5000163]: type(AddBiasResidualLayerNorm_5000163) view(1 4 0)  inEdge(node(5000160) idx(0)) inEdge(node(5000162) idx(0))
node[5000162]: type(AllReduce_5000162) view(1 4 0)  inEdge(node(5000161) idx(0))
node[5000161]: type(TreeIncMultiHeadSelfAttention_5000161) view(1 4 0)  inEdge(node(5000160) idx(1))
node[5000160]: type(ResidualLayerNorm_5000160) view(1 4 0)  inEdge(node(5000159) idx(0)) inEdge(node(5000155) idx(0))
node[5000159]: type(AllReduce_5000159) view(1 4 0)  inEdge(node(5000158) idx(0))
node[5000158]: type(Dense_5000158) view(1 4 0)  inEdge(node(5000157) idx(0))
node[5000157]: type(ReLU_5000157) view(1 4 0)  inEdge(node(5000156) idx(0))
node[5000156]: type(Dense_5000156) view(1 4 0)  inEdge(node(5000155) idx(1))
node[5000155]: type(AddBiasResidualLayerNorm_5000155) view(1 4 0)  inEdge(node(5000152) idx(0)) inEdge(node(5000154) idx(0))
node[5000154]: type(AllReduce_5000154) view(1 4 0)  inEdge(node(5000153) idx(0))
node[5000153]: type(TreeIncMultiHeadSelfAttention_5000153) view(1 4 0)  inEdge(node(5000152) idx(1))
node[5000152]: type(ResidualLayerNorm_5000152) view(1 4 0)  inEdge(node(5000151) idx(0)) inEdge(node(5000147) idx(0))
node[5000135]: type(AllReduce_5000135) view(1 4 0)  inEdge(node(5000134) idx(0))
node[5000118]: type(Dense_5000118) view(1 4 0)  inEdge(node(5000117) idx(0))
node[5000117]: type(ReLU_5000117) view(1 4 0)  inEdge(node(5000116) idx(0))
node[5000116]: type(Dense_5000116) view(1 4 0)  inEdge(node(5000115) idx(1))
node[5000115]: type(AddBiasResidualLayerNorm_5000115) view(1 4 0)  inEdge(node(5000112) idx(0)) inEdge(node(5000114) idx(0))
node[5000114]: type(AllReduce_5000114) view(1 4 0)  inEdge(node(5000113) idx(0))
node[5000113]: type(TreeIncMultiHeadSelfAttention_5000113) view(1 4 0)  inEdge(node(5000112) idx(1))
node[5000112]: type(ResidualLayerNorm_5000112) view(1 4 0)  inEdge(node(5000111) idx(0)) inEdge(node(5000110) idx(0))
node[5000111]: type(Replicate_5000111) view(1 4 0)  inEdge(node(5000109) idx(0))
node[5000107]: type(Input_5000107) view(1 1 0) 
node[5000109]: type(Embedding_5000109) view(1 1 0)  inEdge(node(5000107) idx(0))
node[5000110]: type(Replicate_5000110) view(1 4 0)  inEdge(node(5000108) idx(0))
node[5000106]: type(Input_5000106) view(1 1 0) 
node[5000108]: type(Embedding_5000108) view(1 1 0)  inEdge(node(5000106) idx(0))
node[5000119]: type(AllReduce_5000119) view(1 4 0)  inEdge(node(5000118) idx(0))
node[5000120]: type(ResidualLayerNorm_5000120) view(1 4 0)  inEdge(node(5000119) idx(0)) inEdge(node(5000115) idx(0))
node[5000121]: type(TreeIncMultiHeadSelfAttention_5000121) view(1 4 0)  inEdge(node(5000120) idx(1))
node[5000122]: type(AllReduce_5000122) view(1 4 0)  inEdge(node(5000121) idx(0))
node[5000183]: type(AllReduce_5000183) view(1 4 0)  inEdge(node(5000182) idx(0))
node[5000124]: type(Dense_5000124) view(1 4 0)  inEdge(node(5000123) idx(1))
node[5000184]: type(ResidualLayerNorm_5000184) view(1 4 0)  inEdge(node(5000183) idx(0)) inEdge(node(5000179) idx(0))
node[5000125]: type(ReLU_5000125) view(1 4 0)  inEdge(node(5000124) idx(0))
node[5000185]: type(TreeIncMultiHeadSelfAttention_5000185) view(1 4 0)  inEdge(node(5000184) idx(1))
node[5000126]: type(Dense_5000126) view(1 4 0)  inEdge(node(5000125) idx(0))
node[5000186]: type(AllReduce_5000186) view(1 4 0)  inEdge(node(5000185) idx(0))
node[5000127]: type(AllReduce_5000127) view(1 4 0)  inEdge(node(5000126) idx(0))
node[5000187]: type(AddBiasResidualLayerNorm_5000187) view(1 4 0)  inEdge(node(5000184) idx(0)) inEdge(node(5000186) idx(0))
node[5000128]: type(ResidualLayerNorm_5000128) view(1 4 0)  inEdge(node(5000127) idx(0)) inEdge(node(5000123) idx(0))
node[5000188]: type(Dense_5000188) view(1 4 0)  inEdge(node(5000187) idx(1))
node[5000129]: type(TreeIncMultiHeadSelfAttention_5000129) view(1 4 0)  inEdge(node(5000128) idx(1))
digraph taskgraph {
  node0 [label="{ Dense_5000164 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node1 -> node0;
  node1 [label="{ AddBiasResidualLayerNorm_5000163 }",shape=record];
  node2 -> node1;
  node3 -> node1;
  node2 [label="{ AllReduce_5000162 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node4 -> node2;
  node4 [label="{ TreeIncMultiHeadSelfAttention_5000161 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node3 -> node4;
  node3 [label="{ ResidualLayerNorm_5000160 }",shape=record];
  node5 -> node3;
  node6 -> node3;
  node6 [label="{ AllReduce_5000159 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node7 -> node6;
  node7 [label="{ Dense_5000158 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node8 -> node7;
  node8 [label="{ ReLU_5000157 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node9 -> node8;
  node9 [label="{ Dense_5000156 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node5 -> node9;
  node5 [label="{ AddBiasResidualLayerNorm_5000155 }",shape=record];
  node10 -> node5;
  node11 -> node5;
  node10 [label="{ AllReduce_5000154 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node12 -> node10;
  node12 [label="{ TreeIncMultiHeadSelfAttention_5000153 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node11 -> node12;
  node11 [label="{ ResidualLayerNorm_5000152 }",shape=record];
  node13 -> node11;
  node14 -> node11;
  node14 [label="{ AllReduce_5000151 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node15 -> node14;
  node15 [label="{ Dense_5000150 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node16 -> node15;
  node16 [label="{ ReLU_5000149 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node17 -> node16;
  node17 [label="{ Dense_5000148 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node13 -> node17;
  node13 [label="{ AddBiasResidualLayerNorm_5000147 }",shape=record];
  node18 -> node13;
  node19 -> node13;
  node18 [label="{ AllReduce_5000146 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node20 -> node18;
  node20 [label="{ TreeIncMultiHeadSelfAttention_5000145 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node19 -> node20;
  node19 [label="{ ResidualLayerNorm_5000144 }",shape=record];
  node21 -> node19;
  node22 -> node19;
  node22 [label="{ AllReduce_5000143 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node23 -> node22;
  node23 [label="{ Dense_5000142 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node24 -> node23;
  node24 [label="{ ReLU_5000141 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node25 -> node24;
  node25 [label="{ Dense_5000140 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node21 -> node25;
  node21 [label="{ AddBiasResidualLayerNorm_5000139 }",shape=record];
  node26 -> node21;
  node27 -> node21;
  node26 [label="{ AllReduce_5000138 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node28 -> node26;
  node28 [label="{ TreeIncMultiHeadSelfAttention_5000137 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node27 -> node28;
  node27 [label="{ ResidualLayerNorm_5000136 }",shape=record];
  node29 -> node27;
  node30 -> node27;
  node30 [label="{ AllReduce_5000135 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node31 -> node30;
  node32 [label="{ Dense_5000118 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node33 -> node32;
  node33 [label="{ ReLU_5000117 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node34 -> node33;
  node34 [label="{ Dense_5000116 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node35 -> node34;
  node35 [label="{ AddBiasResidualLayerNorm_5000115 }",shape=record];
  node36 -> node35;
  node37 -> node35;
  node36 [label="{ AllReduce_5000114 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node38 -> node36;
  node38 [label="{ TreeIncMultiHeadSelfAttention_5000113 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node37 -> node38;
  node37 [label="{ ResidualLayerNorm_5000112 }",shape=record];
  node39 -> node37;
  node40 -> node37;
  node40 [label="{ Replicate_5000111 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node41 -> node40;
  node39 [label="{ Replicate_5000110 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node42 -> node39;
  node41 [label="{ Embedding_5000109 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node43 -> node41;
  node43 [label="{ Input_5000107 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node42 [label="{ Embedding_5000108 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node44 -> node42;
  node44 [label="{ Input_5000106 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node45 [label="{ AllReduce_5000119 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node32 -> node45;
  node46 [label="{ ResidualLayerNorm_5000120 }",shape=record];
  node35 -> node46;
  node45 -> node46;
  node47 [label="{ TreeIncMultiHeadSelfAttention_5000121 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node46 -> node47;
  node48 [label="{ AllReduce_5000122 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node47 -> node48;
  node49 [label="{ AllReduce_5000183 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node50 -> node49;
  node51 [label="{ Dense_5000124 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node52 -> node51;
  node53 [label="{ ResidualLayerNorm_5000184 }",shape=record];
  node54 -> node53;
  node49 -> node53;
  node55 [label="{ ReLU_5000125 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node51 -> node55;
  node56 [label="{ TreeIncMultiHeadSelfAttention_5000185 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node53 -> node56;
  node57 [label="{ Dense_5000126 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node55 -> node57;
  node58 [label="{ AllReduce_5000186 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node56 -> node58;
  node59 [label="{ AllReduce_5000127 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node57 -> node59;
  node60 [label="{ AddBiasResidualLayerNorm_5000187 }",shape=record];
  node58 -> node60;
  node53 -> node60;
  node61 [label="{ ResidualLayerNorm_5000128 }",shape=record];
  node52 -> node61;
  node59 -> node61;
  node62 [label="{ Dense_5000188 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node60 -> node62;
  node63 [label="{ TreeIncMultiHeadSelfAttention_5000129 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node61 -> node63;
  node64 [label="{ ReLU_5000189 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node62 -> node64;
  node65 [label="{ AllReduce_5000130 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node63 -> node65;
  node66 [label="{ Dense_5000190 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node64 -> node66;
  node29 [label="{ AddBiasResidualLayerNorm_5000131 }",shape=record];
  node65 -> node29;
  node61 -> node29;
  node67 [label="{ AllReduce_5000191 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node66 -> node67;
  node68 [label="{ Dense_5000132 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node29 -> node68;
  node69 [label="{ ResidualLayerNorm_5000192 }",shape=record];
  node60 -> node69;
  node67 -> node69;
  node70 [label="{ ReLU_5000133 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node68 -> node70;
  node71 [label="{ TreeIncMultiHeadSelfAttention_5000193 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node69 -> node71;
  node31 [label="{ Dense_5000134 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node70 -> node31;
  node72 [label="{ AllReduce_5000194 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node71 -> node72;
  node73 [label="{ AddBiasResidualLayerNorm_5000195 }",shape=record];
  node72 -> node73;
  node69 -> node73;
  node74 [label="{ Dense_5000196 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node73 -> node74;
  node75 [label="{ ReLU_5000197 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node74 -> node75;
  node76 [label="{ Dense_5000198 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node75 -> node76;
  node77 [label="{ ArgMax_5000211 | { 1/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node78 -> node77;
  node78 [label="{ Combine_5000210 | { dim(0) | deg(4) } }",shape=record];
  node79 -> node78;
  node79 [label="{ Dense_5000209 | { 50272/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node80 -> node79;
  node80 [label="{ ResidualLayerNorm_5000208 }",shape=record];
  node81 -> node80;
  node82 -> node80;
  node82 [label="{ AllReduce_5000207 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node83 -> node82;
  node83 [label="{ Dense_5000206 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node84 -> node83;
  node84 [label="{ ReLU_5000205 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node85 -> node84;
  node85 [label="{ Dense_5000204 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node81 -> node85;
  node81 [label="{ AddBiasResidualLayerNorm_5000203 }",shape=record];
  node86 -> node81;
  node87 -> node81;
  node86 [label="{ AllReduce_5000202 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node88 -> node86;
  node88 [label="{ TreeIncMultiHeadSelfAttention_5000201 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node87 -> node88;
  node87 [label="{ ResidualLayerNorm_5000200 }",shape=record];
  node73 -> node87;
  node89 -> node87;
  node89 [label="{ AllReduce_5000199 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node76 -> node89;
  node50 [label="{ Dense_5000182 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node90 -> node50;
  node52 [label="{ AddBiasResidualLayerNorm_5000123 }",shape=record];
  node48 -> node52;
  node46 -> node52;
  node90 [label="{ ReLU_5000181 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node91 -> node90;
  node91 [label="{ Dense_5000180 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node54 -> node91;
  node54 [label="{ AddBiasResidualLayerNorm_5000179 }",shape=record];
  node92 -> node54;
  node93 -> node54;
  node92 [label="{ AllReduce_5000178 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node94 -> node92;
  node94 [label="{ TreeIncMultiHeadSelfAttention_5000177 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node93 -> node94;
  node93 [label="{ ResidualLayerNorm_5000176 }",shape=record];
  node95 -> node93;
  node96 -> node93;
  node96 [label="{ AllReduce_5000175 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node97 -> node96;
  node97 [label="{ Dense_5000174 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node98 -> node97;
  node98 [label="{ ReLU_5000173 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node99 -> node98;
  node99 [label="{ Dense_5000172 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node95 -> node99;
  node95 [label="{ AddBiasResidualLayerNorm_5000171 }",shape=record];
  node100 -> node95;
  node101 -> node95;
  node100 [label="{ AllReduce_5000170 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node102 -> node100;
  node102 [label="{ TreeIncMultiHeadSelfAttention_5000169 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node101 -> node102;
  node101 [label="{ ResidualLayerNorm_5000168 }",shape=record];
  node1 -> node101;
  node103 -> node101;
  node103 [label="{ AllReduce_5000167 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node104 -> node103;
  node104 [label="{ Dense_5000166 | { 768/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node105 -> node104;
  node105 [label="{ ReLU_5000165 | { 3072/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node0 -> node105;
}
ndim(1) dims[1 0 0 0]
ndim(1) dims[4 0 0 0]
operator[0]: type(Input) guid(2000188)
	outputs[0] region(8,1,1)
operator[1]: type(Input) guid(2000189)
	outputs[0] region(10,2,2)
operator[2]: type(Weight) guid(2000191)
	outputs[0] region(12,3,3)
operator[3]: type(FusedOp) guid(2000431)
	inputs[0] region(8,1,1)
	inputs[1] region(10,2,2)
	outputs[0] region(14,4,4)
	outputs[1] region(18,6,6)
	weights[0] region(12,3,3)
	weights[1] region(16,5,5)
operator[4]: type(Weight) guid(2000193)
	outputs[0] region(16,5,5)
operator[5]: type(Replicate) guid(2000194)
	inputs[0] region(14,4,4)
	outputs[0] region(21,7,7)
operator[6]: type(Replicate) guid(2000195)
	inputs[0] region(18,6,6)
	outputs[0] region(26,8,8)
operator[7]: type(Weight) guid(2000197)
	outputs[0] region(31,9,9)
operator[8]: type(Weight) guid(2000198)
	outputs[0] region(36,10,10)
operator[9]: type(FusedOp) guid(2000432)
	inputs[0] region(21,7,7)
	inputs[1] region(26,8,8)
	outputs[0] region(41,11,11)
	outputs[1] region(46,12,12)
	outputs[2] region(61,15,15)
	outputs[3] region(66,16,16)
	outputs[4] region(86,20,20)
	outputs[5] region(91,21,21)
	outputs[6] region(106,24,24)
	outputs[7] region(111,25,25)
	outputs[8] region(126,28,28)
	outputs[9] region(131,29,29)
	outputs[10] region(146,32,32)
	outputs[11] region(151,33,33)
	outputs[12] region(166,36,36)
	outputs[13] region(171,37,37)
	outputs[14] region(191,41,41)
	outputs[15] region(196,42,42)
	outputs[16] region(211,45,45)
	outputs[17] region(216,46,46)
	outputs[18] region(231,49,49)
	outputs[19] region(236,50,50)
	outputs[20] region(251,53,53)
	outputs[21] region(256,54,54)
	outputs[22] region(271,57,57)
	outputs[23] region(276,58,58)
	outputs[24] region(296,62,62)
	outputs[25] region(301,63,63)
	outputs[26] region(316,66,66)
	outputs[27] region(321,67,67)
	outputs[28] region(336,70,70)
	outputs[29] region(341,71,71)
	outputs[30] region(356,74,74)
	outputs[31] region(361,75,75)
	outputs[32] region(376,78,78)
	outputs[33] region(381,79,79)
	outputs[34] region(401,83,83)
	outputs[35] region(406,84,84)
	outputs[36] region(421,87,87)
	outputs[37] region(426,88,88)
	outputs[38] region(441,91,91)
	outputs[39] region(446,92,92)
	outputs[40] region(461,95,95)
	outputs[41] region(466,96,96)
	outputs[42] region(481,99,99)
	outputs[43] region(486,100,100)
	outputs[44] region(506,104,104)
	outputs[45] region(511,105,105)
	outputs[46] region(526,108,108)
	outputs[47] region(531,109,109)
	outputs[48] region(546,112,112)
	outputs[49] region(551,113,113)
	outputs[50] region(566,116,116)
	outputs[51] region(571,117,117)
	outputs[52] region(586,120,120)
	outputs[53] region(591,121,121)
	outputs[54] region(611,125,125)
	outputs[55] region(616,126,126)
	outputs[56] region(631,129,129)
	outputs[57] region(636,130,130)
	outputs[58] region(651,133,133)
	outputs[59] region(656,134,134)
	outputs[60] region(671,137,137)
	outputs[61] region(676,138,138)
	outputs[62] region(691,141,141)
	outputs[63] region(696,142,142)
	outputs[64] region(716,146,146)
	outputs[65] region(721,147,147)
	outputs[66] region(736,150,150)
	outputs[67] region(741,151,151)
	outputs[68] region(756,154,154)
	outputs[69] region(761,155,155)
	outputs[70] region(776,158,158)
	outputs[71] region(781,159,159)
	outputs[72] region(796,162,162)
	outputs[73] region(801,163,163)
	outputs[74] region(821,167,167)
	outputs[75] region(826,168,168)
	outputs[76] region(841,171,171)
	outputs[77] region(846,172,172)
	outputs[78] region(861,175,175)
	outputs[79] region(866,176,176)
	outputs[80] region(881,179,179)
	outputs[81] region(886,180,180)
	outputs[82] region(901,183,183)
	outputs[83] region(906,184,184)
	outputs[84] region(926,188,188)
	outputs[85] region(931,189,189)
	outputs[86] region(946,192,192)
	outputs[87] region(951,193,193)
	outputs[88] region(966,196,196)
	outputs[89] region(971,197,197)
	outputs[90] region(986,200,200)
	outputs[91] region(991,201,201)
	outputs[92] region(1006,204,204)
	outputs[93] region(1011,205,205)
	outputs[94] region(1031,209,209)
	outputs[95] region(1036,210,210)
	outputs[96] region(1051,213,213)
	outputs[97] region(1056,214,214)
	outputs[98] region(1071,217,217)
	outputs[99] region(1076,218,218)
	outputs[100] region(1091,221,221)
	outputs[101] region(1096,222,222)
	outputs[102] region(1111,225,225)
	outputs[103] region(1116,226,226)
	outputs[104] region(1136,230,230)
	outputs[105] region(1141,231,231)
	outputs[106] region(1156,234,234)
	outputs[107] region(1161,235,235)
	outputs[108] region(1176,238,238)
	outputs[109] region(1181,239,239)
	outputs[110] region(1196,242,242)
	outputs[111] region(1201,243,243)
	outputs[112] region(1216,246,246)
	outputs[113] region(1221,247,247)
	outputs[114] region(1241,251,251)
	outputs[115] region(1246,252,252)
	outputs[116] region(1261,255,255)
	outputs[117] region(1266,256,256)
	outputs[118] region(1281,259,259)
	outputs[119] region(1286,260,260)
	outputs[120] region(1301,263,263)
	outputs[121] region(1306,264,264)
	outputs[122] region(1316,266,266)
	weights[0] region(31,9,9)
	weights[1] region(36,10,10)
	weights[2] region(51,13,13)
	weights[3] region(56,14,14)
	weights[4] region(71,17,17)
	weights[5] region(76,18,18)
	weights[6] region(81,19,19)
	weights[7] region(96,22,22)
	weights[8] region(101,23,23)
	weights[9] region(116,26,26)
	weights[10] region(121,27,27)
	weights[11] region(136,30,30)
	weights[12] region(141,31,31)
	weights[13] region(156,34,34)
	weights[14] region(161,35,35)
	weights[15] region(176,38,38)
	weights[16] region(181,39,39)
	weights[17] region(186,40,40)
	weights[18] region(201,43,43)
	weights[19] region(206,44,44)
	weights[20] region(221,47,47)
	weights[21] region(226,48,48)
	weights[22] region(241,51,51)
	weights[23] region(246,52,52)
	weights[24] region(261,55,55)
	weights[25] region(266,56,56)
	weights[26] region(281,59,59)
	weights[27] region(286,60,60)
	weights[28] region(291,61,61)
	weights[29] region(306,64,64)
	weights[30] region(311,65,65)
	weights[31] region(326,68,68)
	weights[32] region(331,69,69)
	weights[33] region(346,72,72)
	weights[34] region(351,73,73)
	weights[35] region(366,76,76)
	weights[36] region(371,77,77)
	weights[37] region(386,80,80)
	weights[38] region(391,81,81)
	weights[39] region(396,82,82)
	weights[40] region(411,85,85)
	weights[41] region(416,86,86)
	weights[42] region(431,89,89)
	weights[43] region(436,90,90)
	weights[44] region(451,93,93)
	weights[45] region(456,94,94)
	weights[46] region(471,97,97)
	weights[47] region(476,98,98)
	weights[48] region(491,101,101)
	weights[49] region(496,102,102)
	weights[50] region(501,103,103)
	weights[51] region(516,106,106)
	weights[52] region(521,107,107)
	weights[53] region(536,110,110)
	weights[54] region(541,111,111)
	weights[55] region(556,114,114)
	weights[56] region(561,115,115)
	weights[57] region(576,118,118)
	weights[58] region(581,119,119)
	weights[59] region(596,122,122)
	weights[60] region(601,123,123)
	weights[61] region(606,124,124)
	weights[62] region(621,127,127)
	weights[63] region(626,128,128)
	weights[64] region(641,131,131)
	weights[65] region(646,132,132)
	weights[66] region(661,135,135)
	weights[67] region(666,136,136)
	weights[68] region(681,139,139)
	weights[69] region(686,140,140)
	weights[70] region(701,143,143)
	weights[71] region(706,144,144)
	weights[72] region(711,145,145)
	weights[73] region(726,148,148)
	weights[74] region(731,149,149)
	weights[75] region(746,152,152)
	weights[76] region(751,153,153)
	weights[77] region(766,156,156)
	weights[78] region(771,157,157)
	weights[79] region(786,160,160)
	weights[80] region(791,161,161)
	weights[81] region(806,164,164)
	weights[82] region(811,165,165)
	weights[83] region(816,166,166)
	weights[84] region(831,169,169)
	weights[85] region(836,170,170)
	weights[86] region(851,173,173)
	weights[87] region(856,174,174)
	weights[88] region(871,177,177)
	weights[89] region(876,178,178)
	weights[90] region(891,181,181)
	weights[91] region(896,182,182)
	weights[92] region(911,185,185)
	weights[93] region(916,186,186)
	weights[94] region(921,187,187)
	weights[95] region(936,190,190)
	weights[96] region(941,191,191)
	weights[97] region(956,194,194)
	weights[98] region(961,195,195)
	weights[99] region(976,198,198)
	weights[100] region(981,199,199)
	weights[101] region(996,202,202)
	weights[102] region(1001,203,203)
	weights[103] region(1016,206,206)
	weights[104] region(1021,207,207)
	weights[105] region(1026,208,208)
	weights[106] region(1041,211,211)
	weights[107] region(1046,212,212)
	weights[108] region(1061,215,215)
	weights[109] region(1066,216,216)
	weights[110] region(1081,219,219)
	weights[111] region(1086,220,220)
	weights[112] region(1101,223,223)
	weights[113] region(1106,224,224)
	weights[114] region(1121,227,227)
	weights[115] region(1126,228,228)
	weights[116] region(1131,229,229)
	weights[117] region(1146,232,232)
	weights[118] region(1151,233,233)
	weights[119] region(1166,236,236)
	weights[120] region(1171,237,237)
	weights[121] region(1186,240,240)
	weights[122] region(1191,241,241)
	weights[123] region(1206,244,244)
	weights[124] region(1211,245,245)
	weights[125] region(1226,248,248)
	weights[126] region(1231,249,249)
	weights[127] region(1236,250,250)
	weights[128] region(1251,253,253)
	weights[129] region(1256,254,254)
	weights[130] region(1271,257,257)
	weights[131] region(1276,258,258)
	weights[132] region(1291,261,261)
	weights[133] region(1296,262,262)
	weights[134] region(1311,265,265)
operator[10]: type(Weight) guid(2000200)
	outputs[0] region(51,13,13)
operator[11]: type(Weight) guid(2000201)
	outputs[0] region(56,14,14)
operator[12]: type(Weight) guid(2000204)
	outputs[0] region(71,17,17)
operator[13]: type(Weight) guid(2000205)
	outputs[0] region(76,18,18)
operator[14]: type(Weight) guid(2000206)
	outputs[0] region(81,19,19)
operator[15]: type(Weight) guid(2000208)
	outputs[0] region(96,22,22)
operator[16]: type(Weight) guid(2000209)
	outputs[0] region(101,23,23)
operator[17]: type(Weight) guid(2000212)
	outputs[0] region(116,26,26)
operator[18]: type(Weight) guid(2000213)
	outputs[0] region(121,27,27)
operator[19]: type(Weight) guid(2000216)
	outputs[0] region(136,30,30)
operator[20]: type(Weight) guid(2000217)
	outputs[0] region(141,31,31)
operator[21]: type(Weight) guid(2000219)
	outputs[0] region(156,34,34)
operator[22]: type(Weight) guid(2000220)
	outputs[0] region(161,35,35)
operator[23]: type(Weight) guid(2000223)
	outputs[0] region(176,38,38)
operator[24]: type(Weight) guid(2000224)
	outputs[0] region(181,39,39)
operator[25]: type(Weight) guid(2000225)
	outputs[0] region(186,40,40)
operator[26]: type(Weight) guid(2000227)
	outputs[0] region(201,43,43)
operator[27]: type(Weight) guid(2000228)
	outputs[0] region(206,44,44)
operator[28]: type(Weight) guid(2000231)
	outputs[0] region(221,47,47)
operator[29]: type(Weight) guid(2000232)
	outputs[0] region(226,48,48)
operator[30]: type(Weight) guid(2000235)
	outputs[0] region(241,51,51)
operator[31]: type(Weight) guid(2000236)
	outputs[0] region(246,52,52)
operator[32]: type(Weight) guid(2000238)
	outputs[0] region(261,55,55)
operator[33]: type(Weight) guid(2000239)
	outputs[0] region(266,56,56)
operator[34]: type(Weight) guid(2000242)
	outputs[0] region(281,59,59)
operator[35]: type(Weight) guid(2000243)
	outputs[0] region(286,60,60)
operator[36]: type(Weight) guid(2000244)
	outputs[0] region(291,61,61)
operator[37]: type(Weight) guid(2000246)
	outputs[0] region(306,64,64)
operator[38]: type(Weight) guid(2000247)
	outputs[0] region(311,65,65)
operator[39]: type(Weight) guid(2000250)
	outputs[0] region(326,68,68)
operator[40]: type(Weight) guid(2000251)
	outputs[0] region(331,69,69)
operator[41]: type(Weight) guid(2000254)
	outputs[0] region(346,72,72)
operator[42]: type(Weight) guid(2000255)
	outputs[0] region(351,73,73)
operator[43]: type(Weight) guid(2000257)
	outputs[0] region(366,76,76)
operator[44]: type(Weight) guid(2000258)
	outputs[0] region(371,77,77)
operator[45]: type(Weight) guid(2000261)
	outputs[0] region(386,80,80)
operator[46]: type(Weight) guid(2000262)
	outputs[0] region(391,81,81)
operator[47]: type(Weight) guid(2000263)
	outputs[0] region(396,82,82)
operator[48]: type(Weight) guid(2000265)
	outputs[0] region(411,85,85)
operator[49]: type(Weight) guid(2000266)
	outputs[0] region(416,86,86)
operator[50]: type(Weight) guid(2000269)
	outputs[0] region(431,89,89)
operator[51]: type(Weight) guid(2000270)
	outputs[0] region(436,90,90)
operator[52]: type(Weight) guid(2000273)
	outputs[0] region(451,93,93)
operator[53]: type(Weight) guid(2000274)
	outputs[0] region(456,94,94)
operator[54]: type(Weight) guid(2000276)
	outputs[0] region(471,97,97)
operator[55]: type(Weight) guid(2000277)
	outputs[0] region(476,98,98)
operator[56]: type(Weight) guid(2000280)
	outputs[0] region(491,101,101)
operator[57]: type(Weight) guid(2000281)
	outputs[0] region(496,102,102)
operator[58]: type(Weight) guid(2000282)
	outputs[0] region(501,103,103)
operator[59]: type(Weight) guid(2000284)
	outputs[0] region(516,106,106)
operator[60]: type(Weight) guid(2000285)
	outputs[0] region(521,107,107)
operator[61]: type(Weight) guid(2000288)
	outputs[0] region(536,110,110)
operator[62]: type(Weight) guid(2000289)
	outputs[0] region(541,111,111)
operator[63]: type(Weight) guid(2000292)
	outputs[0] region(556,114,114)
operator[64]: type(Weight) guid(2000293)
	outputs[0] region(561,115,115)
operator[65]: type(Weight) guid(2000295)
	outputs[0] region(576,118,118)
operator[66]: type(Weight) guid(2000296)
	outputs[0] region(581,119,119)
operator[67]: type(Weight) guid(2000299)
	outputs[0] region(596,122,122)
operator[68]: type(Weight) guid(2000300)
	outputs[0] region(601,123,123)
operator[69]: type(Weight) guid(2000301)
	outputs[0] region(606,124,124)
operator[70]: type(Weight) guid(2000303)
	outputs[0] region(621,127,127)
operator[71]: type(Weight) guid(2000304)
	outputs[0] region(626,128,128)
operator[72]: type(Weight) guid(2000307)
	outputs[0] region(641,131,131)
operator[73]: type(Weight) guid(2000308)
	outputs[0] region(646,132,132)
operator[74]: type(Weight) guid(2000311)
	outputs[0] region(661,135,135)
operator[75]: type(Weight) guid(2000312)
	outputs[0] region(666,136,136)
operator[76]: type(Weight) guid(2000314)
	outputs[0] region(681,139,139)
operator[77]: type(Weight) guid(2000315)
	outputs[0] region(686,140,140)
operator[78]: type(Weight) guid(2000318)
	outputs[0] region(701,143,143)
operator[79]: type(Weight) guid(2000319)
	outputs[0] region(706,144,144)
operator[80]: type(Weight) guid(2000320)
	outputs[0] region(711,145,145)
operator[81]: type(Weight) guid(2000322)
	outputs[0] region(726,148,148)
operator[82]: type(Weight) guid(2000323)
	outputs[0] region(731,149,149)
operator[83]: type(Weight) guid(2000326)
	outputs[0] region(746,152,152)
operator[84]: type(Weight) guid(2000327)
	outputs[0] region(751,153,153)
operator[85]: type(Weight) guid(2000330)
	outputs[0] region(766,156,156)
operator[86]: type(Weight) guid(2000331)
	outputs[0] region(771,157,157)
operator[87]: type(Weight) guid(2000333)
	outputs[0] region(786,160,160)
operator[88]: type(Weight) guid(2000334)
	outputs[0] region(791,161,161)
operator[89]: type(Weight) guid(2000337)
	outputs[0] region(806,164,164)
operator[90]: type(Weight) guid(2000338)
	outputs[0] region(811,165,165)
operator[91]: type(Weight) guid(2000339)
	outputs[0] region(816,166,166)
operator[92]: type(Weight) guid(2000341)
	outputs[0] region(831,169,169)
operator[93]: type(Weight) guid(2000342)
	outputs[0] region(836,170,170)
operator[94]: type(Weight) guid(2000345)
	outputs[0] region(851,173,173)
operator[95]: type(Weight) guid(2000346)
	outputs[0] region(856,174,174)
operator[96]: type(Weight) guid(2000349)
	outputs[0] region(871,177,177)
operator[97]: type(Weight) guid(2000350)
	outputs[0] region(876,178,178)
operator[98]: type(Weight) guid(2000352)
	outputs[0] region(891,181,181)
operator[99]: type(Weight) guid(2000353)
	outputs[0] region(896,182,182)
operator[100]: type(Weight) guid(2000356)
	outputs[0] region(911,185,185)
operator[101]: type(Weight) guid(2000357)
	outputs[0] region(916,186,186)
operator[102]: type(Weight) guid(2000358)
	outputs[0] region(921,187,187)
operator[103]: type(Weight) guid(2000360)
	outputs[0] region(936,190,190)
operator[104]: type(Weight) guid(2000361)
	outputs[0] region(941,191,191)
operator[105]: type(Weight) guid(2000364)
	outputs[0] region(956,194,194)
operator[106]: type(Weight) guid(2000365)
	outputs[0] region(961,195,195)
operator[107]: type(Weight) guid(2000368)
	outputs[0] region(976,198,198)
operator[108]: type(Weight) guid(2000369)
	outputs[0] region(981,199,199)
operator[109]: type(Weight) guid(2000371)
	outputs[0] region(996,202,202)
operator[110]: type(Weight) guid(2000372)
	outputs[0] region(1001,203,203)
operator[111]: type(Weight) guid(2000375)
	outputs[0] region(1016,206,206)
operator[112]: type(Weight) guid(2000376)
	outputs[0] region(1021,207,207)
operator[113]: type(Weight) guid(2000377)
	outputs[0] region(1026,208,208)
operator[114]: type(Weight) guid(2000379)
	outputs[0] region(1041,211,211)
operator[115]: type(Weight) guid(2000380)
	outputs[0] region(1046,212,212)
operator[116]: type(Weight) guid(2000383)
	outputs[0] region(1061,215,215)
operator[117]: type(Weight) guid(2000384)
	outputs[0] region(1066,216,216)
operator[118]: type(Weight) guid(2000387)
	outputs[0] region(1081,219,219)
operator[119]: type(Weight) guid(2000388)
	outputs[0] region(1086,220,220)
operator[120]: type(Weight) guid(2000390)
	outputs[0] region(1101,223,223)
operator[121]: type(Weight) guid(2000391)
	outputs[0] region(1106,224,224)
operator[122]: type(Weight) guid(2000394)
	outputs[0] region(1121,227,227)
operator[123]: type(Weight) guid(2000395)
	outputs[0] region(1126,228,228)
operator[124]: type(Weight) guid(2000396)
	outputs[0] region(1131,229,229)
operator[125]: type(Weight) guid(2000398)
	outputs[0] region(1146,232,232)
operator[126]: type(Weight) guid(2000399)
	outputs[0] region(1151,233,233)
operator[127]: type(Weight) guid(2000402)
	outputs[0] region(1166,236,236)
operator[128]: type(Weight) guid(2000403)
	outputs[0] region(1171,237,237)
operator[129]: type(Weight) guid(2000406)
	outputs[0] region(1186,240,240)
operator[130]: type(Weight) guid(2000407)
	outputs[0] region(1191,241,241)
operator[131]: type(Weight) guid(2000409)
	outputs[0] region(1206,244,244)
operator[132]: type(Weight) guid(2000410)
	outputs[0] region(1211,245,245)
operator[133]: type(Weight) guid(2000413)
	outputs[0] region(1226,248,248)
operator[134]: type(Weight) guid(2000414)
	outputs[0] region(1231,249,249)
operator[135]: type(Weight) guid(2000415)
	outputs[0] region(1236,250,250)
operator[136]: type(Weight) guid(2000417)
	outputs[0] region(1251,253,253)
operator[137]: type(Weight) guid(2000418)
	outputs[0] region(1256,254,254)
operator[138]: type(Weight) guid(2000421)
	outputs[0] region(1271,257,257)
operator[139]: type(Weight) guid(2000422)
	outputs[0] region(1276,258,258)
operator[140]: type(Weight) guid(2000425)
	outputs[0] region(1291,261,261)
operator[141]: type(Weight) guid(2000426)
	outputs[0] region(1296,262,262)
operator[142]: type(Weight) guid(2000428)
	outputs[0] region(1311,265,265)
operator[143]: type(Combine) guid(2000429)
	inputs[0] region(1316,266,266)
	outputs[0] region(1321,267,267)
operator[144]: type(ArgMax) guid(2000430)
	inputs[0] region(1321,267,267)
	outputs[0] region(1323,268,268)
operator[0]: type(0)
	outputs[0] region(8,1,1)
operator[1]: type(0)
	outputs[0] region(10,2,2)
operator[2]: type(1)
	outputs[0] region(12,3,3)
operator[3]: type(78)
	inputs[0] region(8,1,1)
	inputs[1] region(10,2,2)
	outputs[0] region(14,4,4)
	outputs[1] region(18,6,6)
operator[4]: type(1)
	outputs[0] region(16,5,5)
operator[5]: type(98)
	inputs[0] region(14,4,4)
	outputs[0] region(21,7,7)
operator[6]: type(98)
	inputs[0] region(18,6,6)
	outputs[0] region(26,8,8)
operator[7]: type(1)
	outputs[0] region(31,9,9)
operator[8]: type(1)
	outputs[0] region(36,10,10)
operator[9]: type(78)
	inputs[0] region(21,7,7)
	inputs[1] region(26,8,8)
	outputs[0] region(41,11,11)
	outputs[1] region(46,12,12)
	outputs[2] region(61,15,15)
	outputs[3] region(66,16,16)
	outputs[4] region(86,20,20)
	outputs[5] region(91,21,21)
	outputs[6] region(106,24,24)
	outputs[7] region(111,25,25)
	outputs[8] region(126,28,28)
	outputs[9] region(131,29,29)
	outputs[10] region(146,32,32)
	outputs[11] region(151,33,33)
	outputs[12] region(166,36,36)
	outputs[13] region(171,37,37)
	outputs[14] region(191,41,41)
	outputs[15] region(196,42,42)
	outputs[16] region(211,45,45)
	outputs[17] region(216,46,46)
	outputs[18] region(231,49,49)
	outputs[19] region(236,50,50)
	outputs[20] region(251,53,53)
	outputs[21] region(256,54,54)
	outputs[22] region(271,57,57)
	outputs[23] region(276,58,58)
	outputs[24] region(296,62,62)
	outputs[25] region(301,63,63)
	outputs[26] region(316,66,66)
	outputs[27] region(321,67,67)
	outputs[28] region(336,70,70)
	outputs[29] region(341,71,71)
	outputs[30] region(356,74,74)
	outputs[31] region(361,75,75)
	outputs[32] region(376,78,78)
	outputs[33] region(381,79,79)
	outputs[34] region(401,83,83)
	outputs[35] region(406,84,84)
	outputs[36] region(421,87,87)
	outputs[37] region(426,88,88)
	outputs[38] region(441,91,91)
	outputs[39] region(446,92,92)
	outputs[40] region(461,95,95)
	outputs[41] region(466,96,96)
	outputs[42] region(481,99,99)
	outputs[43] region(486,100,100)
	outputs[44] region(506,104,104)
	outputs[45] region(511,105,105)
	outputs[46] region(526,108,108)
	outputs[47] region(531,109,109)
	outputs[48] region(546,112,112)
	outputs[49] region(551,113,113)
	outputs[50] region(566,116,116)
	outputs[51] region(571,117,117)
	outputs[52] region(586,120,120)
	outputs[53] region(591,121,121)
	outputs[54] region(611,125,125)
	outputs[55] region(616,126,126)
	outputs[56] region(631,129,129)
	outputs[57] region(636,130,130)
	outputs[58] region(651,133,133)
	outputs[59] region(656,134,134)
	outputs[60] region(671,137,137)
	outputs[61] region(676,138,138)
	outputs[62] region(691,141,141)
	outputs[63] region(696,142,142)
	outputs[64] region(716,146,146)
	outputs[65] region(721,147,147)
	outputs[66] region(736,150,150)
	outputs[67] region(741,151,151)
	outputs[68] region(756,154,154)
	outputs[69] region(761,155,155)
	outputs[70] region(776,158,158)
	outputs[71] region(781,159,159)
	outputs[72] region(796,162,162)
	outputs[73] region(801,163,163)
	outputs[74] region(821,167,167)
	outputs[75] region(826,168,168)
	outputs[76] region(841,171,171)
	outputs[77] region(846,172,172)
	outputs[78] region(861,175,175)
	outputs[79] region(866,176,176)
	outputs[80] region(881,179,179)
	outputs[81] region(886,180,180)
	outputs[82] region(901,183,183)
	outputs[83] region(906,184,184)
	outputs[84] region(926,188,188)
	outputs[85] region(931,189,189)
	outputs[86] region(946,192,192)
	outputs[87] region(951,193,193)
	outputs[88] region(966,196,196)
	outputs[89] region(971,197,197)
	outputs[90] region(986,200,200)
	outputs[91] region(991,201,201)
	outputs[92] region(1006,204,204)
	outputs[93] region(1011,205,205)
	outputs[94] region(1031,209,209)
	outputs[95] region(1036,210,210)
	outputs[96] region(1051,213,213)
	outputs[97] region(1056,214,214)
	outputs[98] region(1071,217,217)
	outputs[99] region(1076,218,218)
	outputs[100] region(1091,221,221)
	outputs[101] region(1096,222,222)
	outputs[102] region(1111,225,225)
	outputs[103] region(1116,226,226)
	outputs[104] region(1136,230,230)
	outputs[105] region(1141,231,231)
	outputs[106] region(1156,234,234)
	outputs[107] region(1161,235,235)
	outputs[108] region(1176,238,238)
	outputs[109] region(1181,239,239)
	outputs[110] region(1196,242,242)
	outputs[111] region(1201,243,243)
	outputs[112] region(1216,246,246)
	outputs[113] region(1221,247,247)
	outputs[114] region(1241,251,251)
	outputs[115] region(1246,252,252)
	outputs[116] region(1261,255,255)
	outputs[117] region(1266,256,256)
	outputs[118] region(1281,259,259)
	outputs[119] region(1286,260,260)
	outputs[120] region(1301,263,263)
	outputs[121] region(1306,264,264)
	outputs[122] region(1316,266,266)
operator[10]: type(1)
	outputs[0] region(51,13,13)
operator[11]: type(1)
	outputs[0] region(56,14,14)
operator[12]: type(1)
	outputs[0] region(71,17,17)
operator[13]: type(1)
	outputs[0] region(76,18,18)
operator[14]: type(1)
	outputs[0] region(81,19,19)
operator[15]: type(1)
	outputs[0] region(96,22,22)
operator[16]: type(1)
	outputs[0] region(101,23,23)
operator[17]: type(1)
	outputs[0] region(116,26,26)
operator[18]: type(1)
	outputs[0] region(121,27,27)
operator[19]: type(1)
	outputs[0] region(136,30,30)
operator[20]: type(1)
	outputs[0] region(141,31,31)
operator[21]: type(1)
	outputs[0] region(156,34,34)
operator[22]: type(1)
	outputs[0] region(161,35,35)
operator[23]: type(1)
	outputs[0] region(176,38,38)
operator[24]: type(1)
	outputs[0] region(181,39,39)
operator[25]: type(1)
	outputs[0] region(186,40,40)
operator[26]: type(1)
	outputs[0] region(201,43,43)
operator[27]: type(1)
	outputs[0] region(206,44,44)
operator[28]: type(1)
	outputs[0] region(221,47,47)
operator[29]: type(1)
	outputs[0] region(226,48,48)
operator[30]: type(1)
	outputs[0] region(241,51,51)
operator[31]: type(1)
	outputs[0] region(246,52,52)
operator[32]: type(1)
	outputs[0] region(261,55,55)
operator[33]: type(1)
	outputs[0] region(266,56,56)
operator[34]: type(1)
	outputs[0] region(281,59,59)
operator[35]: type(1)
	outputs[0] region(286,60,60)
operator[36]: type(1)
	outputs[0] region(291,61,61)
operator[37]: type(1)
	outputs[0] region(306,64,64)
operator[38]: type(1)
	outputs[0] region(311,65,65)
operator[39]: type(1)
	outputs[0] region(326,68,68)
operator[40]: type(1)
	outputs[0] region(331,69,69)
operator[41]: type(1)
	outputs[0] region(346,72,72)
operator[42]: type(1)
	outputs[0] region(351,73,73)
operator[43]: type(1)
	outputs[0] region(366,76,76)
operator[44]: type(1)
	outputs[0] region(371,77,77)
operator[45]: type(1)
	outputs[0] region(386,80,80)
operator[46]: type(1)
	outputs[0] region(391,81,81)
operator[47]: type(1)
	outputs[0] region(396,82,82)
operator[48]: type(1)
	outputs[0] region(411,85,85)
operator[49]: type(1)
	outputs[0] region(416,86,86)
operator[50]: type(1)
	outputs[0] region(431,89,89)
operator[51]: type(1)
	outputs[0] region(436,90,90)
operator[52]: type(1)
	outputs[0] region(451,93,93)
operator[53]: type(1)
	outputs[0] region(456,94,94)
operator[54]: type(1)
	outputs[0] region(471,97,97)
operator[55]: type(1)
	outputs[0] region(476,98,98)
operator[56]: type(1)
	outputs[0] region(491,101,101)
operator[57]: type(1)
	outputs[0] region(496,102,102)
operator[58]: type(1)
	outputs[0] region(501,103,103)
operator[59]: type(1)
	outputs[0] region(516,106,106)
operator[60]: type(1)
	outputs[0] region(521,107,107)
operator[61]: type(1)
	outputs[0] region(536,110,110)
operator[62]: type(1)
	outputs[0] region(541,111,111)
operator[63]: type(1)
	outputs[0] region(556,114,114)
operator[64]: type(1)
	outputs[0] region(561,115,115)
operator[65]: type(1)
	outputs[0] region(576,118,118)
operator[66]: type(1)
	outputs[0] region(581,119,119)
operator[67]: type(1)
	outputs[0] region(596,122,122)
operator[68]: type(1)
	outputs[0] region(601,123,123)
operator[69]: type(1)
	outputs[0] region(606,124,124)
operator[70]: type(1)
	outputs[0] region(621,127,127)
operator[71]: type(1)
	outputs[0] region(626,128,128)
operator[72]: type(1)
	outputs[0] region(641,131,131)
operator[73]: type(1)
	outputs[0] region(646,132,132)
operator[74]: type(1)
	outputs[0] region(661,135,135)
operator[75]: type(1)
	outputs[0] region(666,136,136)
operator[76]: type(1)
	outputs[0] region(681,139,139)
operator[77]: type(1)
	outputs[0] region(686,140,140)
operator[78]: type(1)
	outputs[0] region(701,143,143)
operator[79]: type(1)
	outputs[0] region(706,144,144)
operator[80]: type(1)
	outputs[0] region(711,145,145)
operator[81]: type(1)
	outputs[0] region(726,148,148)
operator[82]: type(1)
	outputs[0] region(731,149,149)
operator[83]: type(1)
	outputs[0] region(746,152,152)
operator[84]: type(1)
	outputs[0] region(751,153,153)
operator[85]: type(1)
	outputs[0] region(766,156,156)
operator[86]: type(1)
	outputs[0] region(771,157,157)
operator[87]: type(1)
	outputs[0] region(786,160,160)
operator[88]: type(1)
	outputs[0] region(791,161,161)
operator[89]: type(1)
	outputs[0] region(806,164,164)
operator[90]: type(1)
	outputs[0] region(811,165,165)
operator[91]: type(1)
	outputs[0] region(816,166,166)
operator[92]: type(1)
	outputs[0] region(831,169,169)
operator[93]: type(1)
	outputs[0] region(836,170,170)
operator[94]: type(1)
	outputs[0] region(851,173,173)
operator[95]: type(1)
	outputs[0] region(856,174,174)
operator[96]: type(1)
	outputs[0] region(871,177,177)
operator[97]: type(1)
	outputs[0] region(876,178,178)
operator[98]: type(1)
	outputs[0] region(891,181,181)
operator[99]: type(1)
	outputs[0] region(896,182,182)
operator[100]: type(1)
	outputs[0] region(911,185,185)
operator[101]: type(1)
	outputs[0] region(916,186,186)
operator[102]: type(1)
	outputs[0] region(921,187,187)
operator[103]: type(1)
	outputs[0] region(936,190,190)
operator[104]: type(1)
	outputs[0] region(941,191,191)
operator[105]: type(1)
	outputs[0] region(956,194,194)
operator[106]: type(1)
	outputs[0] region(961,195,195)
operator[107]: type(1)
	outputs[0] region(976,198,198)
operator[108]: type(1)
	outputs[0] region(981,199,199)
operator[109]: type(1)
	outputs[0] region(996,202,202)
operator[110]: type(1)
	outputs[0] region(1001,203,203)
operator[111]: type(1)
	outputs[0] region(1016,206,206)
operator[112]: type(1)
	outputs[0] region(1021,207,207)
operator[113]: type(1)
	outputs[0] region(1026,208,208)
operator[114]: type(1)
	outputs[0] region(1041,211,211)
operator[115]: type(1)
	outputs[0] region(1046,212,212)
operator[116]: type(1)
	outputs[0] region(1061,215,215)
operator[117]: type(1)
	outputs[0] region(1066,216,216)
operator[118]: type(1)
	outputs[0] region(1081,219,219)
operator[119]: type(1)
	outputs[0] region(1086,220,220)
operator[120]: type(1)
	outputs[0] region(1101,223,223)
operator[121]: type(1)
	outputs[0] region(1106,224,224)
operator[122]: type(1)
	outputs[0] region(1121,227,227)
operator[123]: type(1)
	outputs[0] region(1126,228,228)
operator[124]: type(1)
	outputs[0] region(1131,229,229)
operator[125]: type(1)
	outputs[0] region(1146,232,232)
operator[126]: type(1)
	outputs[0] region(1151,233,233)
operator[127]: type(1)
	outputs[0] region(1166,236,236)
operator[128]: type(1)
	outputs[0] region(1171,237,237)
operator[129]: type(1)
	outputs[0] region(1186,240,240)
operator[130]: type(1)
	outputs[0] region(1191,241,241)
operator[131]: type(1)
	outputs[0] region(1206,244,244)
operator[132]: type(1)
	outputs[0] region(1211,245,245)
operator[133]: type(1)
	outputs[0] region(1226,248,248)
operator[134]: type(1)
	outputs[0] region(1231,249,249)
operator[135]: type(1)
	outputs[0] region(1236,250,250)
operator[136]: type(1)
	outputs[0] region(1251,253,253)
operator[137]: type(1)
	outputs[0] region(1256,254,254)
operator[138]: type(1)
	outputs[0] region(1271,257,257)
operator[139]: type(1)
	outputs[0] region(1276,258,258)
operator[140]: type(1)
	outputs[0] region(1291,261,261)
operator[141]: type(1)
	outputs[0] region(1296,262,262)
operator[142]: type(1)
	outputs[0] region(1311,265,265)
operator[143]: type(97)
	inputs[0] region(1316,266,266)
	outputs[0] region(1321,267,267)
operator[144]: type(91)
	inputs[0] region(1321,267,267)
	outputs[0] region(1323,268,268)
Loading weight file embed_tokens_weight
Loading weight file embed_positions_weight
Loading weight file layers_0_attention_layer_norm_weight
Loading weight file layers_0_attention_layer_norm_bias
Loading weight file layers_0_attention_wq_weight
Loading weight file layers_0_attention_wk_weight
Loading weight file layers_0_attention_wv_weight
Loading weight file layers_0_attention_wo_weight
Loading weight file layers_0_attention_wq_bias
Loading weight file layers_0_attention_wk_bias
Loading weight file layers_0_attention_wv_bias
Loading weight file layers_0_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_0_add_bias_residual_layer_norm_weight
Loading weight file layers_0_add_bias_residual_layer_norm_bias
Loading weight file layers_0_fc1_weight
Loading weight file layers_0_fc1_bias
Loading weight file layers_0_fc2_weight
Loading weight file layers_0_fc2_bias
Loading weight file layers_1_attention_layer_norm_weight
Loading weight file layers_1_attention_layer_norm_bias
Loading weight file layers_1_attention_wq_weight
Loading weight file layers_1_attention_wk_weight
Loading weight file layers_1_attention_wv_weight
Loading weight file layers_1_attention_wo_weight
Loading weight file layers_1_attention_wq_bias
Loading weight file layers_1_attention_wk_bias
Loading weight file layers_1_attention_wv_bias
Loading weight file layers_1_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_1_add_bias_residual_layer_norm_weight
Loading weight file layers_1_add_bias_residual_layer_norm_bias
Loading weight file layers_1_fc1_weight
Loading weight file layers_1_fc1_bias
Loading weight file layers_1_fc2_weight
Loading weight file layers_1_fc2_bias
Loading weight file layers_2_attention_layer_norm_weight
Loading weight file layers_2_attention_layer_norm_bias
Loading weight file layers_2_attention_wq_weight
Loading weight file layers_2_attention_wk_weight
Loading weight file layers_2_attention_wv_weight
Loading weight file layers_2_attention_wo_weight
Loading weight file layers_2_attention_wq_bias
Loading weight file layers_2_attention_wk_bias
Loading weight file layers_2_attention_wv_bias
Loading weight file layers_2_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_2_add_bias_residual_layer_norm_weight
Loading weight file layers_2_add_bias_residual_layer_norm_bias
Loading weight file layers_2_fc1_weight
Loading weight file layers_2_fc1_bias
Loading weight file layers_2_fc2_weight
Loading weight file layers_2_fc2_bias
Loading weight file layers_3_attention_layer_norm_weight
Loading weight file layers_3_attention_layer_norm_bias
Loading weight file layers_3_attention_wq_weight
Loading weight file layers_3_attention_wk_weight
Loading weight file layers_3_attention_wv_weight
Loading weight file layers_3_attention_wo_weight
Loading weight file layers_3_attention_wq_bias
Loading weight file layers_3_attention_wk_bias
Loading weight file layers_3_attention_wv_bias
Loading weight file layers_3_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_3_add_bias_residual_layer_norm_weight
Loading weight file layers_3_add_bias_residual_layer_norm_bias
Loading weight file layers_3_fc1_weight
Loading weight file layers_3_fc1_bias
Loading weight file layers_3_fc2_weight
Loading weight file layers_3_fc2_bias
Loading weight file layers_4_attention_layer_norm_weight
Loading weight file layers_4_attention_layer_norm_bias
Loading weight file layers_4_attention_wq_weight
Loading weight file layers_4_attention_wk_weight
Loading weight file layers_4_attention_wv_weight
Loading weight file layers_4_attention_wo_weight
Loading weight file layers_4_attention_wq_bias
Loading weight file layers_4_attention_wk_bias
Loading weight file layers_4_attention_wv_bias
Loading weight file layers_4_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_4_add_bias_residual_layer_norm_weight
Loading weight file layers_4_add_bias_residual_layer_norm_bias
Loading weight file layers_4_fc1_weight
Loading weight file layers_4_fc1_bias
Loading weight file layers_4_fc2_weight
Loading weight file layers_4_fc2_bias
Loading weight file layers_5_attention_layer_norm_weight
Loading weight file layers_5_attention_layer_norm_bias
Loading weight file layers_5_attention_wq_weight
Loading weight file layers_5_attention_wk_weight
Loading weight file layers_5_attention_wv_weight
Loading weight file layers_5_attention_wo_weight
Loading weight file layers_5_attention_wq_bias
Loading weight file layers_5_attention_wk_bias
Loading weight file layers_5_attention_wv_bias
Loading weight file layers_5_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_5_add_bias_residual_layer_norm_weight
Loading weight file layers_5_add_bias_residual_layer_norm_bias
Loading weight file layers_5_fc1_weight
Loading weight file layers_5_fc1_bias
Loading weight file layers_5_fc2_weight
Loading weight file layers_5_fc2_bias
Loading weight file layers_6_attention_layer_norm_weight
Loading weight file layers_6_attention_layer_norm_bias
Loading weight file layers_6_attention_wq_weight
Loading weight file layers_6_attention_wk_weight
Loading weight file layers_6_attention_wv_weight
Loading weight file layers_6_attention_wo_weight
Loading weight file layers_6_attention_wq_bias
Loading weight file layers_6_attention_wk_bias
Loading weight file layers_6_attention_wv_bias
Loading weight file layers_6_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_6_add_bias_residual_layer_norm_weight
Loading weight file layers_6_add_bias_residual_layer_norm_bias
Loading weight file layers_6_fc1_weight
Loading weight file layers_6_fc1_bias
Loading weight file layers_6_fc2_weight
Loading weight file layers_6_fc2_bias
Loading weight file layers_7_attention_layer_norm_weight
Loading weight file layers_7_attention_layer_norm_bias
Loading weight file layers_7_attention_wq_weight
Loading weight file layers_7_attention_wk_weight
Loading weight file layers_7_attention_wv_weight
Loading weight file layers_7_attention_wo_weight
Loading weight file layers_7_attention_wq_bias
Loading weight file layers_7_attention_wk_bias
Loading weight file layers_7_attention_wv_bias
Loading weight file layers_7_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_7_add_bias_residual_layer_norm_weight
Loading weight file layers_7_add_bias_residual_layer_norm_bias
Loading weight file layers_7_fc1_weight
Loading weight file layers_7_fc1_bias
Loading weight file layers_7_fc2_weight
Loading weight file layers_7_fc2_bias
Loading weight file layers_8_attention_layer_norm_weight
Loading weight file layers_8_attention_layer_norm_bias
Loading weight file layers_8_attention_wq_weight
Loading weight file layers_8_attention_wk_weight
Loading weight file layers_8_attention_wv_weight
Loading weight file layers_8_attention_wo_weight
Loading weight file layers_8_attention_wq_bias
Loading weight file layers_8_attention_wk_bias
Loading weight file layers_8_attention_wv_bias
Loading weight file layers_8_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_8_add_bias_residual_layer_norm_weight
Loading weight file layers_8_add_bias_residual_layer_norm_bias
Loading weight file layers_8_fc1_weight
Loading weight file layers_8_fc1_bias
Loading weight file layers_8_fc2_weight
Loading weight file layers_8_fc2_bias
Loading weight file layers_9_attention_layer_norm_weight
Loading weight file layers_9_attention_layer_norm_bias
Loading weight file layers_9_attention_wq_weight
Loading weight file layers_9_attention_wk_weight
Loading weight file layers_9_attention_wv_weight
Loading weight file layers_9_attention_wo_weight
Loading weight file layers_9_attention_wq_bias
Loading weight file layers_9_attention_wk_bias
Loading weight file layers_9_attention_wv_bias
Loading weight file layers_9_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_9_add_bias_residual_layer_norm_weight
Loading weight file layers_9_add_bias_residual_layer_norm_bias
Loading weight file layers_9_fc1_weight
Loading weight file layers_9_fc1_bias
Loading weight file layers_9_fc2_weight
Loading weight file layers_9_fc2_bias
Loading weight file layers_10_attention_layer_norm_weight
Loading weight file layers_10_attention_layer_norm_bias
Loading weight file layers_10_attention_wq_weight
Loading weight file layers_10_attention_wk_weight
Loading weight file layers_10_attention_wv_weight
Loading weight file layers_10_attention_wo_weight
Loading weight file layers_10_attention_wq_bias
Loading weight file layers_10_attention_wk_bias
Loading weight file layers_10_attention_wv_bias
Loading weight file layers_10_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_10_add_bias_residual_layer_norm_weight
Loading weight file layers_10_add_bias_residual_layer_norm_bias
Loading weight file layers_10_fc1_weight
Loading weight file layers_10_fc1_bias
Loading weight file layers_10_fc2_weight
Loading weight file layers_10_fc2_bias
Loading weight file layers_11_attention_layer_norm_weight
Loading weight file layers_11_attention_layer_norm_bias
Loading weight file layers_11_attention_wq_weight
Loading weight file layers_11_attention_wk_weight
Loading weight file layers_11_attention_wv_weight
Loading weight file layers_11_attention_wo_weight
Loading weight file layers_11_attention_wq_bias
Loading weight file layers_11_attention_wk_bias
Loading weight file layers_11_attention_wv_bias
Loading weight file layers_11_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_11_add_bias_residual_layer_norm_weight
Loading weight file layers_11_add_bias_residual_layer_norm_bias
Loading weight file layers_11_fc1_weight
Loading weight file layers_11_fc1_bias
Loading weight file layers_11_fc2_weight
Loading weight file layers_11_fc2_bias
Loading weight file final_layer_norm_weight
Loading weight file final_layer_norm_bias
Loading weight file embed_tokens_weight_lm_head
------finished loading weights----------
[0 - 7fd9a669a000]    5.872526 {3}{spec_infer}: LLM create_opt_model finished!
[0 - 7fd9a669a000]    5.875546 {3}{opt}: These are OPT model config:
OPT Config:
	do_layer_norm_before: 1
	dropout: 0.1
	enable_bias: 1
	ffn_dim: 3072
	hidden_size: 768
	layer_norm_elementwise_affine: 1
	max_position_embeddings: 2048
	num_attention_heads: 12
	num_hidden_layers: 12
	vocab_size: 50272
	word_embed_proj_dim: 768
	max_beam_width: 1
	max_beam_depth: 8
------start compile ----------
spec create operator: layers_0_attention_1000005
spec create operator: layers_1_attention_1000011
spec create operator: layers_2_attention_1000017
spec create operator: layers_3_attention_1000023
spec create operator: layers_4_attention_1000029
spec create operator: layers_5_attention_1000035
spec create operator: layers_6_attention_1000041
spec create operator: layers_7_attention_1000047
spec create operator: layers_8_attention_1000053
spec create operator: layers_9_attention_1000059
spec create operator: layers_10_attention_1000065
spec create operator: layers_11_attention_1000071
num_nodes = 1 num_gpus_per_node = 4
optimal_views.size = 80
views.size() = 80
Deserialized Views...
node[5000117]: type(Dense_5000117) view(1 1 0)  inEdge(node(5000116) idx(1))
node[5000116]: type(AddBiasResidualLayerNorm_5000116) view(1 1 0)  inEdge(node(5000114) idx(0)) inEdge(node(5000115) idx(0))
node[5000115]: type(SpecIncMultiHeadSelfAttention_5000115) view(1 1 0)  inEdge(node(5000114) idx(1))
node[5000114]: type(ResidualLayerNorm_5000114) view(1 1 0)  inEdge(node(5000113) idx(0)) inEdge(node(5000110) idx(0))
node[5000113]: type(Dense_5000113) view(1 1 0)  inEdge(node(5000112) idx(0))
node[5000112]: type(ReLU_5000112) view(1 1 0)  inEdge(node(5000111) idx(0))
node[5000111]: type(Dense_5000111) view(1 1 0)  inEdge(node(5000110) idx(1))
node[5000110]: type(AddBiasResidualLayerNorm_5000110) view(1 1 0)  inEdge(node(5000108) idx(0)) inEdge(node(5000109) idx(0))
node[5000109]: type(SpecIncMultiHeadSelfAttention_5000109) view(1 1 0)  inEdge(node(5000108) idx(1))
node[5000088]: type(ReLU_5000088) view(1 1 0)  inEdge(node(5000087) idx(0))
node[5000147]: type(Dense_5000147) view(1 1 0)  inEdge(node(5000146) idx(1))
node[5000089]: type(Dense_5000089) view(1 1 0)  inEdge(node(5000088) idx(0))
node[5000148]: type(ReLU_5000148) view(1 1 0)  inEdge(node(5000147) idx(0))
node[5000090]: type(ResidualLayerNorm_5000090) view(1 1 0)  inEdge(node(5000089) idx(0)) inEdge(node(5000086) idx(0))
node[5000149]: type(Dense_5000149) view(1 1 0)  inEdge(node(5000148) idx(0))
node[5000091]: type(SpecIncMultiHeadSelfAttention_5000091) view(1 1 0)  inEdge(node(5000090) idx(1))
node[5000150]: type(ResidualLayerNorm_5000150) view(1 1 0)  inEdge(node(5000149) idx(0)) inEdge(node(5000146) idx(0))
node[5000092]: type(AddBiasResidualLayerNorm_5000092) view(1 1 0)  inEdge(node(5000090) idx(0)) inEdge(node(5000091) idx(0))
node[5000151]: type(SpecIncMultiHeadSelfAttention_5000151) view(1 1 0)  inEdge(node(5000150) idx(1))
node[5000093]: type(Dense_5000093) view(1 1 0)  inEdge(node(5000092) idx(1))
node[5000152]: type(AddBiasResidualLayerNorm_5000152) view(1 1 0)  inEdge(node(5000150) idx(0)) inEdge(node(5000151) idx(0))
node[5000139]: type(SpecIncMultiHeadSelfAttention_5000139) view(1 1 0)  inEdge(node(5000138) idx(1))
node[5000080]: type(Input_5000080) view(1 1 0) 
node[5000118]: type(ReLU_5000118) view(1 1 0)  inEdge(node(5000117) idx(0))
node[5000119]: type(Dense_5000119) view(1 1 0)  inEdge(node(5000118) idx(0))
node[5000120]: type(ResidualLayerNorm_5000120) view(1 1 0)  inEdge(node(5000119) idx(0)) inEdge(node(5000116) idx(0))
node[5000121]: type(SpecIncMultiHeadSelfAttention_5000121) view(1 1 0)  inEdge(node(5000120) idx(1))
node[5000122]: type(AddBiasResidualLayerNorm_5000122) view(1 1 0)  inEdge(node(5000120) idx(0)) inEdge(node(5000121) idx(0))
node[5000123]: type(Dense_5000123) view(1 1 0)  inEdge(node(5000122) idx(1))
node[5000124]: type(ReLU_5000124) view(1 1 0)  inEdge(node(5000123) idx(0))
node[5000125]: type(Dense_5000125) view(1 1 0)  inEdge(node(5000124) idx(0))
node[5000138]: type(ResidualLayerNorm_5000138) view(1 1 0)  inEdge(node(5000137) idx(0)) inEdge(node(5000134) idx(0))
node[5000108]: type(ResidualLayerNorm_5000108) view(1 1 0)  inEdge(node(5000107) idx(0)) inEdge(node(5000104) idx(0))
node[5000137]: type(Dense_5000137) view(1 1 0)  inEdge(node(5000136) idx(0))
node[5000107]: type(Dense_5000107) view(1 1 0)  inEdge(node(5000106) idx(0))
node[5000136]: type(ReLU_5000136) view(1 1 0)  inEdge(node(5000135) idx(0))
node[5000106]: type(ReLU_5000106) view(1 1 0)  inEdge(node(5000105) idx(0))
node[5000135]: type(Dense_5000135) view(1 1 0)  inEdge(node(5000134) idx(1))
node[5000105]: type(Dense_5000105) view(1 1 0)  inEdge(node(5000104) idx(1))
node[5000134]: type(AddBiasResidualLayerNorm_5000134) view(1 1 0)  inEdge(node(5000132) idx(0)) inEdge(node(5000133) idx(0))
node[5000104]: type(AddBiasResidualLayerNorm_5000104) view(1 1 0)  inEdge(node(5000102) idx(0)) inEdge(node(5000103) idx(0))
node[5000133]: type(SpecIncMultiHeadSelfAttention_5000133) view(1 1 0)  inEdge(node(5000132) idx(1))
node[5000103]: type(SpecIncMultiHeadSelfAttention_5000103) view(1 1 0)  inEdge(node(5000102) idx(1))
node[5000132]: type(ResidualLayerNorm_5000132) view(1 1 0)  inEdge(node(5000131) idx(0)) inEdge(node(5000128) idx(0))
node[5000102]: type(ResidualLayerNorm_5000102) view(1 1 0)  inEdge(node(5000101) idx(0)) inEdge(node(5000098) idx(0))
node[5000131]: type(Dense_5000131) view(1 1 0)  inEdge(node(5000130) idx(0))
node[5000130]: type(ReLU_5000130) view(1 1 0)  inEdge(node(5000129) idx(0))
node[5000129]: type(Dense_5000129) view(1 1 0)  inEdge(node(5000128) idx(1))
node[5000128]: type(AddBiasResidualLayerNorm_5000128) view(1 1 0)  inEdge(node(5000126) idx(0)) inEdge(node(5000127) idx(0))
node[5000127]: type(SpecIncMultiHeadSelfAttention_5000127) view(1 1 0)  inEdge(node(5000126) idx(1))
node[5000126]: type(ResidualLayerNorm_5000126) view(1 1 0)  inEdge(node(5000125) idx(0)) inEdge(node(5000122) idx(0))
node[5000140]: type(AddBiasResidualLayerNorm_5000140) view(1 1 0)  inEdge(node(5000138) idx(0)) inEdge(node(5000139) idx(0))
node[5000081]: type(Input_5000081) view(1 1 0) 
node[5000141]: type(Dense_5000141) view(1 1 0)  inEdge(node(5000140) idx(1))
node[5000082]: type(Embedding_5000082) view(1 1 0)  inEdge(node(5000080) idx(0))
node[5000142]: type(ReLU_5000142) view(1 1 0)  inEdge(node(5000141) idx(0))
node[5000083]: type(Embedding_5000083) view(1 1 0)  inEdge(node(5000081) idx(0))
node[5000143]: type(Dense_5000143) view(1 1 0)  inEdge(node(5000142) idx(0))
node[5000084]: type(ResidualLayerNorm_5000084) view(1 1 0)  inEdge(node(5000083) idx(0)) inEdge(node(5000082) idx(0))
node[5000144]: type(ResidualLayerNorm_5000144) view(1 1 0)  inEdge(node(5000143) idx(0)) inEdge(node(5000140) idx(0))
node[5000085]: type(SpecIncMultiHeadSelfAttention_5000085) view(1 1 0)  inEdge(node(5000084) idx(1))
node[5000145]: type(SpecIncMultiHeadSelfAttention_5000145) view(1 1 0)  inEdge(node(5000144) idx(1))
node[5000086]: type(AddBiasResidualLayerNorm_5000086) view(1 1 0)  inEdge(node(5000084) idx(0)) inEdge(node(5000085) idx(0))
node[5000146]: type(AddBiasResidualLayerNorm_5000146) view(1 1 0)  inEdge(node(5000144) idx(0)) inEdge(node(5000145) idx(0))
node[5000087]: type(Dense_5000087) view(1 1 0)  inEdge(node(5000086) idx(1))
node[5000101]: type(Dense_5000101) view(1 1 0)  inEdge(node(5000100) idx(0))
node[5000159]: type(ArgMax_5000159) view(1 1 0)  inEdge(node(5000158) idx(0))
node[5000100]: type(ReLU_5000100) view(1 1 0)  inEdge(node(5000099) idx(0))
node[5000158]: type(Softmax_5000158) view(1 1 0)  inEdge(node(5000157) idx(0))
node[5000099]: type(Dense_5000099) view(1 1 0)  inEdge(node(5000098) idx(1))
node[5000157]: type(Dense_5000157) view(1 1 0)  inEdge(node(5000156) idx(1))
node[5000098]: type(AddBiasResidualLayerNorm_5000098) view(1 1 0)  inEdge(node(5000096) idx(0)) inEdge(node(5000097) idx(0))
node[5000156]: type(ResidualLayerNorm_5000156) view(1 1 0)  inEdge(node(5000155) idx(0)) inEdge(node(5000152) idx(0))
node[5000097]: type(SpecIncMultiHeadSelfAttention_5000097) view(1 1 0)  inEdge(node(5000096) idx(1))
node[5000155]: type(Dense_5000155) view(1 1 0)  inEdge(node(5000154) idx(0))
node[5000096]: type(ResidualLayerNorm_5000096) view(1 1 0)  inEdge(node(5000095) idx(0)) inEdge(node(5000092) idx(0))
node[5000154]: type(ReLU_5000154) view(1 1 0)  inEdge(node(5000153) idx(0))
node[5000095]: type(Dense_5000095) view(1 1 0)  inEdge(node(5000094) idx(0))
node[5000153]: type(Dense_5000153) view(1 1 0)  inEdge(node(5000152) idx(1))
node[5000094]: type(ReLU_5000094) view(1 1 0)  inEdge(node(5000093) idx(0))
digraph taskgraph {
  node0 [label="{ ResidualLayerNorm_5000138 }",shape=record];
  node1 -> node0;
  node2 -> node0;
  node2 [label="{ Dense_5000137 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node3 -> node2;
  node3 [label="{ ReLU_5000136 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node4 -> node3;
  node4 [label="{ Dense_5000135 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node1 -> node4;
  node1 [label="{ AddBiasResidualLayerNorm_5000134 }",shape=record];
  node5 -> node1;
  node6 -> node1;
  node5 [label="{ SpecIncMultiHeadSelfAttention_5000133 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node6 -> node5;
  node6 [label="{ ResidualLayerNorm_5000132 }",shape=record];
  node7 -> node6;
  node8 -> node6;
  node8 [label="{ Dense_5000131 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node9 -> node8;
  node9 [label="{ ReLU_5000130 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node10 -> node9;
  node10 [label="{ Dense_5000129 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node7 -> node10;
  node7 [label="{ AddBiasResidualLayerNorm_5000128 }",shape=record];
  node11 -> node7;
  node12 -> node7;
  node11 [label="{ SpecIncMultiHeadSelfAttention_5000127 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node12 -> node11;
  node12 [label="{ ResidualLayerNorm_5000126 }",shape=record];
  node13 -> node12;
  node14 -> node12;
  node14 [label="{ Dense_5000125 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node15 -> node14;
  node15 [label="{ ReLU_5000124 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node16 -> node15;
  node16 [label="{ Dense_5000123 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node13 -> node16;
  node13 [label="{ AddBiasResidualLayerNorm_5000122 }",shape=record];
  node17 -> node13;
  node18 -> node13;
  node17 [label="{ SpecIncMultiHeadSelfAttention_5000121 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node18 -> node17;
  node18 [label="{ ResidualLayerNorm_5000120 }",shape=record];
  node19 -> node18;
  node20 -> node18;
  node20 [label="{ Dense_5000119 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node21 -> node20;
  node21 [label="{ ReLU_5000118 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node22 -> node21;
  node23 [label="{ ResidualLayerNorm_5000102 }",shape=record];
  node24 -> node23;
  node25 -> node23;
  node26 [label="{ SpecIncMultiHeadSelfAttention_5000103 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node23 -> node26;
  node27 [label="{ AddBiasResidualLayerNorm_5000104 }",shape=record];
  node26 -> node27;
  node23 -> node27;
  node28 [label="{ Dense_5000105 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node27 -> node28;
  node29 [label="{ ReLU_5000106 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node28 -> node29;
  node30 [label="{ Dense_5000107 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node29 -> node30;
  node31 [label="{ ResidualLayerNorm_5000108 }",shape=record];
  node27 -> node31;
  node30 -> node31;
  node32 [label="{ SpecIncMultiHeadSelfAttention_5000139 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node0 -> node32;
  node33 [label="{ Input_5000080 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node34 [label="{ AddBiasResidualLayerNorm_5000140 }",shape=record];
  node32 -> node34;
  node0 -> node34;
  node35 [label="{ Input_5000081 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node36 [label="{ Dense_5000141 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node34 -> node36;
  node37 [label="{ Embedding_5000082 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node33 -> node37;
  node38 [label="{ ReLU_5000142 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node36 -> node38;
  node39 [label="{ Embedding_5000083 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node35 -> node39;
  node40 [label="{ Dense_5000143 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node38 -> node40;
  node41 [label="{ ResidualLayerNorm_5000084 }",shape=record];
  node37 -> node41;
  node39 -> node41;
  node42 [label="{ ResidualLayerNorm_5000144 }",shape=record];
  node34 -> node42;
  node40 -> node42;
  node43 [label="{ SpecIncMultiHeadSelfAttention_5000085 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node41 -> node43;
  node44 [label="{ SpecIncMultiHeadSelfAttention_5000145 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node42 -> node44;
  node45 [label="{ AddBiasResidualLayerNorm_5000086 }",shape=record];
  node43 -> node45;
  node41 -> node45;
  node46 [label="{ AddBiasResidualLayerNorm_5000146 }",shape=record];
  node44 -> node46;
  node42 -> node46;
  node47 [label="{ Dense_5000087 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node45 -> node47;
  node25 [label="{ Dense_5000101 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node48 -> node25;
  node49 [label="{ ArgMax_5000159 }",shape=record];
  node50 -> node49;
  node48 [label="{ ReLU_5000100 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node51 -> node48;
  node50 [label="{ Softmax_5000158 | { 50272/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node52 -> node50;
  node51 [label="{ Dense_5000099 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node24 -> node51;
  node52 [label="{ Dense_5000157 | { 50272/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node53 -> node52;
  node24 [label="{ AddBiasResidualLayerNorm_5000098 }",shape=record];
  node54 -> node24;
  node55 -> node24;
  node53 [label="{ ResidualLayerNorm_5000156 }",shape=record];
  node56 -> node53;
  node57 -> node53;
  node54 [label="{ SpecIncMultiHeadSelfAttention_5000097 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node55 -> node54;
  node57 [label="{ Dense_5000155 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node58 -> node57;
  node55 [label="{ ResidualLayerNorm_5000096 }",shape=record];
  node59 -> node55;
  node60 -> node55;
  node58 [label="{ ReLU_5000154 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node61 -> node58;
  node60 [label="{ Dense_5000095 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node62 -> node60;
  node61 [label="{ Dense_5000153 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node56 -> node61;
  node62 [label="{ ReLU_5000094 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node63 -> node62;
  node56 [label="{ AddBiasResidualLayerNorm_5000152 }",shape=record];
  node64 -> node56;
  node65 -> node56;
  node63 [label="{ Dense_5000093 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node59 -> node63;
  node64 [label="{ SpecIncMultiHeadSelfAttention_5000151 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node65 -> node64;
  node59 [label="{ AddBiasResidualLayerNorm_5000092 }",shape=record];
  node66 -> node59;
  node67 -> node59;
  node65 [label="{ ResidualLayerNorm_5000150 }",shape=record];
  node46 -> node65;
  node68 -> node65;
  node66 [label="{ SpecIncMultiHeadSelfAttention_5000091 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node67 -> node66;
  node68 [label="{ Dense_5000149 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node69 -> node68;
  node67 [label="{ ResidualLayerNorm_5000090 }",shape=record];
  node45 -> node67;
  node70 -> node67;
  node69 [label="{ ReLU_5000148 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node71 -> node69;
  node70 [label="{ Dense_5000089 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node72 -> node70;
  node71 [label="{ Dense_5000147 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node46 -> node71;
  node72 [label="{ ReLU_5000088 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node47 -> node72;
  node73 [label="{ SpecIncMultiHeadSelfAttention_5000109 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node31 -> node73;
  node74 [label="{ AddBiasResidualLayerNorm_5000110 }",shape=record];
  node73 -> node74;
  node31 -> node74;
  node75 [label="{ Dense_5000111 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node74 -> node75;
  node76 [label="{ ReLU_5000112 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node75 -> node76;
  node77 [label="{ Dense_5000113 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node76 -> node77;
  node78 [label="{ ResidualLayerNorm_5000114 }",shape=record];
  node74 -> node78;
  node77 -> node78;
  node79 [label="{ SpecIncMultiHeadSelfAttention_5000115 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node78 -> node79;
  node19 [label="{ AddBiasResidualLayerNorm_5000116 }",shape=record];
  node79 -> node19;
  node78 -> node19;
  node22 [label="{ Dense_5000117 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node19 -> node22;
}
ndim(1) dims[1 0 0 0]
operator[0]: type(Input) guid(2000160)
	outputs[0] region(1336,269,400)
operator[1]: type(Input) guid(2000161)
	outputs[0] region(1338,270,401)
operator[2]: type(Weight) guid(2000163)
	outputs[0] region(1340,271,402)
operator[3]: type(FusedOp) guid(2000377)
	inputs[0] region(1336,269,400)
	inputs[1] region(1338,270,401)
	outputs[0] region(1342,272,403)
	outputs[1] region(1346,274,405)
	outputs[2] region(1352,277,408)
	outputs[3] region(1354,278,409)
	outputs[4] region(1360,281,412)
	outputs[5] region(1368,285,416)
	outputs[6] region(1370,286,417)
	outputs[7] region(1376,289,420)
	outputs[8] region(1378,290,421)
	outputs[9] region(1384,293,424)
	outputs[10] region(1390,296,427)
	outputs[11] region(1392,297,428)
	outputs[12] region(1398,300,431)
	outputs[13] region(1406,304,435)
	outputs[14] region(1408,305,436)
	outputs[15] region(1414,308,439)
	outputs[16] region(1416,309,440)
	outputs[17] region(1422,312,443)
	outputs[18] region(1428,315,446)
	outputs[19] region(1430,316,447)
	outputs[20] region(1436,319,450)
	outputs[21] region(1444,323,454)
	outputs[22] region(1446,324,455)
	outputs[23] region(1452,327,458)
	outputs[24] region(1454,328,459)
	outputs[25] region(1460,331,462)
	outputs[26] region(1466,334,465)
	outputs[27] region(1468,335,466)
	outputs[28] region(1474,338,469)
	outputs[29] region(1482,342,473)
	outputs[30] region(1484,343,474)
	outputs[31] region(1490,346,477)
	outputs[32] region(1492,347,478)
	outputs[33] region(1498,350,481)
	outputs[34] region(1504,353,484)
	outputs[35] region(1506,354,485)
	outputs[36] region(1512,357,488)
	outputs[37] region(1520,361,492)
	outputs[38] region(1522,362,493)
	outputs[39] region(1528,365,496)
	outputs[40] region(1530,366,497)
	outputs[41] region(1536,369,500)
	outputs[42] region(1542,372,503)
	outputs[43] region(1544,373,504)
	outputs[44] region(1550,376,507)
	outputs[45] region(1558,380,511)
	outputs[46] region(1560,381,512)
	outputs[47] region(1566,384,515)
	outputs[48] region(1568,385,516)
	outputs[49] region(1574,388,519)
	outputs[50] region(1580,391,522)
	outputs[51] region(1582,392,523)
	outputs[52] region(1588,395,526)
	outputs[53] region(1596,399,530)
	outputs[54] region(1598,400,531)
	outputs[55] region(1604,403,534)
	outputs[56] region(1606,404,535)
	outputs[57] region(1612,407,538)
	outputs[58] region(1618,410,541)
	outputs[59] region(1620,411,542)
	outputs[60] region(1626,414,545)
	outputs[61] region(1634,418,549)
	outputs[62] region(1636,419,550)
	outputs[63] region(1642,422,553)
	outputs[64] region(1644,423,554)
	outputs[65] region(1650,426,557)
	outputs[66] region(1656,429,560)
	outputs[67] region(1658,430,561)
	outputs[68] region(1664,433,564)
	outputs[69] region(1672,437,568)
	outputs[70] region(1674,438,569)
	outputs[71] region(1680,441,572)
	outputs[72] region(1682,442,573)
	outputs[73] region(1688,445,576)
	outputs[74] region(1694,448,579)
	outputs[75] region(1696,449,580)
	outputs[76] region(1702,452,583)
	outputs[77] region(1710,456,587)
	outputs[78] region(1712,457,588)
	outputs[79] region(1718,460,591)
	outputs[80] region(1720,461,592)
	outputs[81] region(1726,464,595)
	outputs[82] region(1732,467,598)
	outputs[83] region(1734,468,599)
	outputs[84] region(1740,471,602)
	outputs[85] region(1748,475,606)
	outputs[86] region(1750,476,607)
	outputs[87] region(1756,479,610)
	outputs[88] region(1758,480,611)
	outputs[89] region(1764,483,614)
	outputs[90] region(1770,486,617)
	outputs[91] region(1772,487,618)
	outputs[92] region(1778,490,621)
	outputs[93] region(1786,494,625)
	outputs[94] region(1788,495,626)
	outputs[95] region(1794,498,629)
	outputs[96] region(1796,499,630)
	outputs[97] region(1802,502,633)
	outputs[98] region(1808,505,636)
	outputs[99] region(1810,506,637)
	outputs[100] region(1814,508,639)
	outputs[101] region(1816,509,640)
	weights[0] region(1340,271,402)
	weights[1] region(1344,273,404)
	weights[2] region(1348,275,406)
	weights[3] region(1350,276,407)
	weights[4] region(1356,279,410)
	weights[5] region(1358,280,411)
	weights[6] region(1362,282,413)
	weights[7] region(1364,283,414)
	weights[8] region(1366,284,415)
	weights[9] region(1372,287,418)
	weights[10] region(1374,288,419)
	weights[11] region(1380,291,422)
	weights[12] region(1382,292,423)
	weights[13] region(1386,294,425)
	weights[14] region(1388,295,426)
	weights[15] region(1394,298,429)
	weights[16] region(1396,299,430)
	weights[17] region(1400,301,432)
	weights[18] region(1402,302,433)
	weights[19] region(1404,303,434)
	weights[20] region(1410,306,437)
	weights[21] region(1412,307,438)
	weights[22] region(1418,310,441)
	weights[23] region(1420,311,442)
	weights[24] region(1424,313,444)
	weights[25] region(1426,314,445)
	weights[26] region(1432,317,448)
	weights[27] region(1434,318,449)
	weights[28] region(1438,320,451)
	weights[29] region(1440,321,452)
	weights[30] region(1442,322,453)
	weights[31] region(1448,325,456)
	weights[32] region(1450,326,457)
	weights[33] region(1456,329,460)
	weights[34] region(1458,330,461)
	weights[35] region(1462,332,463)
	weights[36] region(1464,333,464)
	weights[37] region(1470,336,467)
	weights[38] region(1472,337,468)
	weights[39] region(1476,339,470)
	weights[40] region(1478,340,471)
	weights[41] region(1480,341,472)
	weights[42] region(1486,344,475)
	weights[43] region(1488,345,476)
	weights[44] region(1494,348,479)
	weights[45] region(1496,349,480)
	weights[46] region(1500,351,482)
	weights[47] region(1502,352,483)
	weights[48] region(1508,355,486)
	weights[49] region(1510,356,487)
	weights[50] region(1514,358,489)
	weights[51] region(1516,359,490)
	weights[52] region(1518,360,491)
	weights[53] region(1524,363,494)
	weights[54] region(1526,364,495)
	weights[55] region(1532,367,498)
	weights[56] region(1534,368,499)
	weights[57] region(1538,370,501)
	weights[58] region(1540,371,502)
	weights[59] region(1546,374,505)
	weights[60] region(1548,375,506)
	weights[61] region(1552,377,508)
	weights[62] region(1554,378,509)
	weights[63] region(1556,379,510)
	weights[64] region(1562,382,513)
	weights[65] region(1564,383,514)
	weights[66] region(1570,386,517)
	weights[67] region(1572,387,518)
	weights[68] region(1576,389,520)
	weights[69] region(1578,390,521)
	weights[70] region(1584,393,524)
	weights[71] region(1586,394,525)
	weights[72] region(1590,396,527)
	weights[73] region(1592,397,528)
	weights[74] region(1594,398,529)
	weights[75] region(1600,401,532)
	weights[76] region(1602,402,533)
	weights[77] region(1608,405,536)
	weights[78] region(1610,406,537)
	weights[79] region(1614,408,539)
	weights[80] region(1616,409,540)
	weights[81] region(1622,412,543)
	weights[82] region(1624,413,544)
	weights[83] region(1628,415,546)
	weights[84] region(1630,416,547)
	weights[85] region(1632,417,548)
	weights[86] region(1638,420,551)
	weights[87] region(1640,421,552)
	weights[88] region(1646,424,555)
	weights[89] region(1648,425,556)
	weights[90] region(1652,427,558)
	weights[91] region(1654,428,559)
	weights[92] region(1660,431,562)
	weights[93] region(1662,432,563)
	weights[94] region(1666,434,565)
	weights[95] region(1668,435,566)
	weights[96] region(1670,436,567)
	weights[97] region(1676,439,570)
	weights[98] region(1678,440,571)
	weights[99] region(1684,443,574)
	weights[100] region(1686,444,575)
	weights[101] region(1690,446,577)
	weights[102] region(1692,447,578)
	weights[103] region(1698,450,581)
	weights[104] region(1700,451,582)
	weights[105] region(1704,453,584)
	weights[106] region(1706,454,585)
	weights[107] region(1708,455,586)
	weights[108] region(1714,458,589)
	weights[109] region(1716,459,590)
	weights[110] region(1722,462,593)
	weights[111] region(1724,463,594)
	weights[112] region(1728,465,596)
	weights[113] region(1730,466,597)
	weights[114] region(1736,469,600)
	weights[115] region(1738,470,601)
	weights[116] region(1742,472,603)
	weights[117] region(1744,473,604)
	weights[118] region(1746,474,605)
	weights[119] region(1752,477,608)
	weights[120] region(1754,478,609)
	weights[121] region(1760,481,612)
	weights[122] region(1762,482,613)
	weights[123] region(1766,484,615)
	weights[124] region(1768,485,616)
	weights[125] region(1774,488,619)
	weights[126] region(1776,489,620)
	weights[127] region(1780,491,622)
	weights[128] region(1782,492,623)
	weights[129] region(1784,493,624)
	weights[130] region(1790,496,627)
	weights[131] region(1792,497,628)
	weights[132] region(1798,500,631)
	weights[133] region(1800,501,632)
	weights[134] region(1804,503,634)
	weights[135] region(1806,504,635)
	weights[136] region(1812,507,638)
operator[4]: type(Weight) guid(2000165)
	outputs[0] region(1344,273,404)
operator[5]: type(Weight) guid(2000167)
	outputs[0] region(1348,275,406)
operator[6]: type(Weight) guid(2000168)
	outputs[0] region(1350,276,407)
operator[7]: type(Weight) guid(2000170)
	outputs[0] region(1356,279,410)
operator[8]: type(Weight) guid(2000171)
	outputs[0] region(1358,280,411)
operator[9]: type(Weight) guid(2000173)
	outputs[0] region(1362,282,413)
operator[10]: type(Weight) guid(2000174)
	outputs[0] region(1364,283,414)
operator[11]: type(Weight) guid(2000175)
	outputs[0] region(1366,284,415)
operator[12]: type(Weight) guid(2000177)
	outputs[0] region(1372,287,418)
operator[13]: type(Weight) guid(2000178)
	outputs[0] region(1374,288,419)
operator[14]: type(Weight) guid(2000181)
	outputs[0] region(1380,291,422)
operator[15]: type(Weight) guid(2000182)
	outputs[0] region(1382,292,423)
operator[16]: type(Weight) guid(2000184)
	outputs[0] region(1386,294,425)
operator[17]: type(Weight) guid(2000185)
	outputs[0] region(1388,295,426)
operator[18]: type(Weight) guid(2000187)
	outputs[0] region(1394,298,429)
operator[19]: type(Weight) guid(2000188)
	outputs[0] region(1396,299,430)
operator[20]: type(Weight) guid(2000190)
	outputs[0] region(1400,301,432)
operator[21]: type(Weight) guid(2000191)
	outputs[0] region(1402,302,433)
operator[22]: type(Weight) guid(2000192)
	outputs[0] region(1404,303,434)
operator[23]: type(Weight) guid(2000194)
	outputs[0] region(1410,306,437)
operator[24]: type(Weight) guid(2000195)
	outputs[0] region(1412,307,438)
operator[25]: type(Weight) guid(2000198)
	outputs[0] region(1418,310,441)
operator[26]: type(Weight) guid(2000199)
	outputs[0] region(1420,311,442)
operator[27]: type(Weight) guid(2000201)
	outputs[0] region(1424,313,444)
operator[28]: type(Weight) guid(2000202)
	outputs[0] region(1426,314,445)
operator[29]: type(Weight) guid(2000204)
	outputs[0] region(1432,317,448)
operator[30]: type(Weight) guid(2000205)
	outputs[0] region(1434,318,449)
operator[31]: type(Weight) guid(2000207)
	outputs[0] region(1438,320,451)
operator[32]: type(Weight) guid(2000208)
	outputs[0] region(1440,321,452)
operator[33]: type(Weight) guid(2000209)
	outputs[0] region(1442,322,453)
operator[34]: type(Weight) guid(2000211)
	outputs[0] region(1448,325,456)
operator[35]: type(Weight) guid(2000212)
	outputs[0] region(1450,326,457)
operator[36]: type(Weight) guid(2000215)
	outputs[0] region(1456,329,460)
operator[37]: type(Weight) guid(2000216)
	outputs[0] region(1458,330,461)
operator[38]: type(Weight) guid(2000218)
	outputs[0] region(1462,332,463)
operator[39]: type(Weight) guid(2000219)
	outputs[0] region(1464,333,464)
operator[40]: type(Weight) guid(2000221)
	outputs[0] region(1470,336,467)
operator[41]: type(Weight) guid(2000222)
	outputs[0] region(1472,337,468)
operator[42]: type(Weight) guid(2000224)
	outputs[0] region(1476,339,470)
operator[43]: type(Weight) guid(2000225)
	outputs[0] region(1478,340,471)
operator[44]: type(Weight) guid(2000226)
	outputs[0] region(1480,341,472)
operator[45]: type(Weight) guid(2000228)
	outputs[0] region(1486,344,475)
operator[46]: type(Weight) guid(2000229)
	outputs[0] region(1488,345,476)
operator[47]: type(Weight) guid(2000232)
	outputs[0] region(1494,348,479)
operator[48]: type(Weight) guid(2000233)
	outputs[0] region(1496,349,480)
operator[49]: type(Weight) guid(2000235)
	outputs[0] region(1500,351,482)
operator[50]: type(Weight) guid(2000236)
	outputs[0] region(1502,352,483)
operator[51]: type(Weight) guid(2000238)
	outputs[0] region(1508,355,486)
operator[52]: type(Weight) guid(2000239)
	outputs[0] region(1510,356,487)
operator[53]: type(Weight) guid(2000241)
	outputs[0] region(1514,358,489)
operator[54]: type(Weight) guid(2000242)
	outputs[0] region(1516,359,490)
operator[55]: type(Weight) guid(2000243)
	outputs[0] region(1518,360,491)
operator[56]: type(Weight) guid(2000245)
	outputs[0] region(1524,363,494)
operator[57]: type(Weight) guid(2000246)
	outputs[0] region(1526,364,495)
operator[58]: type(Weight) guid(2000249)
	outputs[0] region(1532,367,498)
operator[59]: type(Weight) guid(2000250)
	outputs[0] region(1534,368,499)
operator[60]: type(Weight) guid(2000252)
	outputs[0] region(1538,370,501)
operator[61]: type(Weight) guid(2000253)
	outputs[0] region(1540,371,502)
operator[62]: type(Weight) guid(2000255)
	outputs[0] region(1546,374,505)
operator[63]: type(Weight) guid(2000256)
	outputs[0] region(1548,375,506)
operator[64]: type(Weight) guid(2000258)
	outputs[0] region(1552,377,508)
operator[65]: type(Weight) guid(2000259)
	outputs[0] region(1554,378,509)
operator[66]: type(Weight) guid(2000260)
	outputs[0] region(1556,379,510)
operator[67]: type(Weight) guid(2000262)
	outputs[0] region(1562,382,513)
operator[68]: type(Weight) guid(2000263)
	outputs[0] region(1564,383,514)
operator[69]: type(Weight) guid(2000266)
	outputs[0] region(1570,386,517)
operator[70]: type(Weight) guid(2000267)
	outputs[0] region(1572,387,518)
operator[71]: type(Weight) guid(2000269)
	outputs[0] region(1576,389,520)
operator[72]: type(Weight) guid(2000270)
	outputs[0] region(1578,390,521)
operator[73]: type(Weight) guid(2000272)
	outputs[0] region(1584,393,524)
operator[74]: type(Weight) guid(2000273)
	outputs[0] region(1586,394,525)
operator[75]: type(Weight) guid(2000275)
	outputs[0] region(1590,396,527)
operator[76]: type(Weight) guid(2000276)
	outputs[0] region(1592,397,528)
operator[77]: type(Weight) guid(2000277)
	outputs[0] region(1594,398,529)
operator[78]: type(Weight) guid(2000279)
	outputs[0] region(1600,401,532)
operator[79]: type(Weight) guid(2000280)
	outputs[0] region(1602,402,533)
operator[80]: type(Weight) guid(2000283)
	outputs[0] region(1608,405,536)
operator[81]: type(Weight) guid(2000284)
	outputs[0] region(1610,406,537)
operator[82]: type(Weight) guid(2000286)
	outputs[0] region(1614,408,539)
operator[83]: type(Weight) guid(2000287)
	outputs[0] region(1616,409,540)
operator[84]: type(Weight) guid(2000289)
	outputs[0] region(1622,412,543)
operator[85]: type(Weight) guid(2000290)
	outputs[0] region(1624,413,544)
operator[86]: type(Weight) guid(2000292)
	outputs[0] region(1628,415,546)
operator[87]: type(Weight) guid(2000293)
	outputs[0] region(1630,416,547)
operator[88]: type(Weight) guid(2000294)
	outputs[0] region(1632,417,548)
operator[89]: type(Weight) guid(2000296)
	outputs[0] region(1638,420,551)
operator[90]: type(Weight) guid(2000297)
	outputs[0] region(1640,421,552)
operator[91]: type(Weight) guid(2000300)
	outputs[0] region(1646,424,555)
operator[92]: type(Weight) guid(2000301)
	outputs[0] region(1648,425,556)
operator[93]: type(Weight) guid(2000303)
	outputs[0] region(1652,427,558)
operator[94]: type(Weight) guid(2000304)
	outputs[0] region(1654,428,559)
operator[95]: type(Weight) guid(2000306)
	outputs[0] region(1660,431,562)
operator[96]: type(Weight) guid(2000307)
	outputs[0] region(1662,432,563)
operator[97]: type(Weight) guid(2000309)
	outputs[0] region(1666,434,565)
operator[98]: type(Weight) guid(2000310)
	outputs[0] region(1668,435,566)
operator[99]: type(Weight) guid(2000311)
	outputs[0] region(1670,436,567)
operator[100]: type(Weight) guid(2000313)
	outputs[0] region(1676,439,570)
operator[101]: type(Weight) guid(2000314)
	outputs[0] region(1678,440,571)
operator[102]: type(Weight) guid(2000317)
	outputs[0] region(1684,443,574)
operator[103]: type(Weight) guid(2000318)
	outputs[0] region(1686,444,575)
operator[104]: type(Weight) guid(2000320)
	outputs[0] region(1690,446,577)
operator[105]: type(Weight) guid(2000321)
	outputs[0] region(1692,447,578)
operator[106]: type(Weight) guid(2000323)
	outputs[0] region(1698,450,581)
operator[107]: type(Weight) guid(2000324)
	outputs[0] region(1700,451,582)
operator[108]: type(Weight) guid(2000326)
	outputs[0] region(1704,453,584)
operator[109]: type(Weight) guid(2000327)
	outputs[0] region(1706,454,585)
operator[110]: type(Weight) guid(2000328)
	outputs[0] region(1708,455,586)
operator[111]: type(Weight) guid(2000330)
	outputs[0] region(1714,458,589)
operator[112]: type(Weight) guid(2000331)
	outputs[0] region(1716,459,590)
operator[113]: type(Weight) guid(2000334)
	outputs[0] region(1722,462,593)
operator[114]: type(Weight) guid(2000335)
	outputs[0] region(1724,463,594)
operator[115]: type(Weight) guid(2000337)
	outputs[0] region(1728,465,596)
operator[116]: type(Weight) guid(2000338)
	outputs[0] region(1730,466,597)
operator[117]: type(Weight) guid(2000340)
	outputs[0] region(1736,469,600)
operator[118]: type(Weight) guid(2000341)
	outputs[0] region(1738,470,601)
operator[119]: type(Weight) guid(2000343)
	outputs[0] region(1742,472,603)
operator[120]: type(Weight) guid(2000344)
	outputs[0] region(1744,473,604)
operator[121]: type(Weight) guid(2000345)
	outputs[0] region(1746,474,605)
operator[122]: type(Weight) guid(2000347)
	outputs[0] region(1752,477,608)
operator[123]: type(Weight) guid(2000348)
	outputs[0] region(1754,478,609)
operator[124]: type(Weight) guid(2000351)
	outputs[0] region(1760,481,612)
operator[125]: type(Weight) guid(2000352)
	outputs[0] region(1762,482,613)
operator[126]: type(Weight) guid(2000354)
	outputs[0] region(1766,484,615)
operator[127]: type(Weight) guid(2000355)
	outputs[0] region(1768,485,616)
operator[128]: type(Weight) guid(2000357)
	outputs[0] region(1774,488,619)
operator[129]: type(Weight) guid(2000358)
	outputs[0] region(1776,489,620)
operator[130]: type(Weight) guid(2000360)
	outputs[0] region(1780,491,622)
operator[131]: type(Weight) guid(2000361)
	outputs[0] region(1782,492,623)
operator[132]: type(Weight) guid(2000362)
	outputs[0] region(1784,493,624)
operator[133]: type(Weight) guid(2000364)
	outputs[0] region(1790,496,627)
operator[134]: type(Weight) guid(2000365)
	outputs[0] region(1792,497,628)
operator[135]: type(Weight) guid(2000368)
	outputs[0] region(1798,500,631)
operator[136]: type(Weight) guid(2000369)
	outputs[0] region(1800,501,632)
operator[137]: type(Weight) guid(2000371)
	outputs[0] region(1804,503,634)
operator[138]: type(Weight) guid(2000372)
	outputs[0] region(1806,504,635)
operator[139]: type(Weight) guid(2000374)
	outputs[0] region(1812,507,638)
operator[140]: type(ArgMax) guid(2000376)
	inputs[0] region(1816,509,640)
	outputs[0] region(1818,510,641)
	outputs[1] region(1820,511,642)
operator[0]: type(0)
	outputs[0] region(1336,269,400)
operator[1]: type(0)
	outputs[0] region(1338,270,401)
operator[2]: type(1)
	outputs[0] region(1340,271,402)
operator[3]: type(78)
	inputs[0] region(1336,269,400)
	inputs[1] region(1338,270,401)
	outputs[0] region(1342,272,403)
	outputs[1] region(1346,274,405)
	outputs[2] region(1352,277,408)
	outputs[3] region(1354,278,409)
	outputs[4] region(1360,281,412)
	outputs[5] region(1368,285,416)
	outputs[6] region(1370,286,417)
	outputs[7] region(1376,289,420)
	outputs[8] region(1378,290,421)
	outputs[9] region(1384,293,424)
	outputs[10] region(1390,296,427)
	outputs[11] region(1392,297,428)
	outputs[12] region(1398,300,431)
	outputs[13] region(1406,304,435)
	outputs[14] region(1408,305,436)
	outputs[15] region(1414,308,439)
	outputs[16] region(1416,309,440)
	outputs[17] region(1422,312,443)
	outputs[18] region(1428,315,446)
	outputs[19] region(1430,316,447)
	outputs[20] region(1436,319,450)
	outputs[21] region(1444,323,454)
	outputs[22] region(1446,324,455)
	outputs[23] region(1452,327,458)
	outputs[24] region(1454,328,459)
	outputs[25] region(1460,331,462)
	outputs[26] region(1466,334,465)
	outputs[27] region(1468,335,466)
	outputs[28] region(1474,338,469)
	outputs[29] region(1482,342,473)
	outputs[30] region(1484,343,474)
	outputs[31] region(1490,346,477)
	outputs[32] region(1492,347,478)
	outputs[33] region(1498,350,481)
	outputs[34] region(1504,353,484)
	outputs[35] region(1506,354,485)
	outputs[36] region(1512,357,488)
	outputs[37] region(1520,361,492)
	outputs[38] region(1522,362,493)
	outputs[39] region(1528,365,496)
	outputs[40] region(1530,366,497)
	outputs[41] region(1536,369,500)
	outputs[42] region(1542,372,503)
	outputs[43] region(1544,373,504)
	outputs[44] region(1550,376,507)
	outputs[45] region(1558,380,511)
	outputs[46] region(1560,381,512)
	outputs[47] region(1566,384,515)
	outputs[48] region(1568,385,516)
	outputs[49] region(1574,388,519)
	outputs[50] region(1580,391,522)
	outputs[51] region(1582,392,523)
	outputs[52] region(1588,395,526)
	outputs[53] region(1596,399,530)
	outputs[54] region(1598,400,531)
	outputs[55] region(1604,403,534)
	outputs[56] region(1606,404,535)
	outputs[57] region(1612,407,538)
	outputs[58] region(1618,410,541)
	outputs[59] region(1620,411,542)
	outputs[60] region(1626,414,545)
	outputs[61] region(1634,418,549)
	outputs[62] region(1636,419,550)
	outputs[63] region(1642,422,553)
	outputs[64] region(1644,423,554)
	outputs[65] region(1650,426,557)
	outputs[66] region(1656,429,560)
	outputs[67] region(1658,430,561)
	outputs[68] region(1664,433,564)
	outputs[69] region(1672,437,568)
	outputs[70] region(1674,438,569)
	outputs[71] region(1680,441,572)
	outputs[72] region(1682,442,573)
	outputs[73] region(1688,445,576)
	outputs[74] region(1694,448,579)
	outputs[75] region(1696,449,580)
	outputs[76] region(1702,452,583)
	outputs[77] region(1710,456,587)
	outputs[78] region(1712,457,588)
	outputs[79] region(1718,460,591)
	outputs[80] region(1720,461,592)
	outputs[81] region(1726,464,595)
	outputs[82] region(1732,467,598)
	outputs[83] region(1734,468,599)
	outputs[84] region(1740,471,602)
	outputs[85] region(1748,475,606)
	outputs[86] region(1750,476,607)
	outputs[87] region(1756,479,610)
	outputs[88] region(1758,480,611)
	outputs[89] region(1764,483,614)
	outputs[90] region(1770,486,617)
	outputs[91] region(1772,487,618)
	outputs[92] region(1778,490,621)
	outputs[93] region(1786,494,625)
	outputs[94] region(1788,495,626)
	outputs[95] region(1794,498,629)
	outputs[96] region(1796,499,630)
	outputs[97] region(1802,502,633)
	outputs[98] region(1808,505,636)
	outputs[99] region(1810,506,637)
	outputs[100] region(1814,508,639)
	outputs[101] region(1816,509,640)
operator[4]: type(1)
	outputs[0] region(1344,273,404)
operator[5]: type(1)
	outputs[0] region(1348,275,406)
operator[6]: type(1)
	outputs[0] region(1350,276,407)
operator[7]: type(1)
	outputs[0] region(1356,279,410)
operator[8]: type(1)
	outputs[0] region(1358,280,411)
operator[9]: type(1)
	outputs[0] region(1362,282,413)
operator[10]: type(1)
	outputs[0] region(1364,283,414)
operator[11]: type(1)
	outputs[0] region(1366,284,415)
operator[12]: type(1)
	outputs[0] region(1372,287,418)
operator[13]: type(1)
	outputs[0] region(1374,288,419)
operator[14]: type(1)
	outputs[0] region(1380,291,422)
operator[15]: type(1)
	outputs[0] region(1382,292,423)
operator[16]: type(1)
	outputs[0] region(1386,294,425)
operator[17]: type(1)
	outputs[0] region(1388,295,426)
operator[18]: type(1)
	outputs[0] region(1394,298,429)
operator[19]: type(1)
	outputs[0] region(1396,299,430)
operator[20]: type(1)
	outputs[0] region(1400,301,432)
operator[21]: type(1)
	outputs[0] region(1402,302,433)
operator[22]: type(1)
	outputs[0] region(1404,303,434)
operator[23]: type(1)
	outputs[0] region(1410,306,437)
operator[24]: type(1)
	outputs[0] region(1412,307,438)
operator[25]: type(1)
	outputs[0] region(1418,310,441)
operator[26]: type(1)
	outputs[0] region(1420,311,442)
operator[27]: type(1)
	outputs[0] region(1424,313,444)
operator[28]: type(1)
	outputs[0] region(1426,314,445)
operator[29]: type(1)
	outputs[0] region(1432,317,448)
operator[30]: type(1)
	outputs[0] region(1434,318,449)
operator[31]: type(1)
	outputs[0] region(1438,320,451)
operator[32]: type(1)
	outputs[0] region(1440,321,452)
operator[33]: type(1)
	outputs[0] region(1442,322,453)
operator[34]: type(1)
	outputs[0] region(1448,325,456)
operator[35]: type(1)
	outputs[0] region(1450,326,457)
operator[36]: type(1)
	outputs[0] region(1456,329,460)
operator[37]: type(1)
	outputs[0] region(1458,330,461)
operator[38]: type(1)
	outputs[0] region(1462,332,463)
operator[39]: type(1)
	outputs[0] region(1464,333,464)
operator[40]: type(1)
	outputs[0] region(1470,336,467)
operator[41]: type(1)
	outputs[0] region(1472,337,468)
operator[42]: type(1)
	outputs[0] region(1476,339,470)
operator[43]: type(1)
	outputs[0] region(1478,340,471)
operator[44]: type(1)
	outputs[0] region(1480,341,472)
operator[45]: type(1)
	outputs[0] region(1486,344,475)
operator[46]: type(1)
	outputs[0] region(1488,345,476)
operator[47]: type(1)
	outputs[0] region(1494,348,479)
operator[48]: type(1)
	outputs[0] region(1496,349,480)
operator[49]: type(1)
	outputs[0] region(1500,351,482)
operator[50]: type(1)
	outputs[0] region(1502,352,483)
operator[51]: type(1)
	outputs[0] region(1508,355,486)
operator[52]: type(1)
	outputs[0] region(1510,356,487)
operator[53]: type(1)
	outputs[0] region(1514,358,489)
operator[54]: type(1)
	outputs[0] region(1516,359,490)
operator[55]: type(1)
	outputs[0] region(1518,360,491)
operator[56]: type(1)
	outputs[0] region(1524,363,494)
operator[57]: type(1)
	outputs[0] region(1526,364,495)
operator[58]: type(1)
	outputs[0] region(1532,367,498)
operator[59]: type(1)
	outputs[0] region(1534,368,499)
operator[60]: type(1)
	outputs[0] region(1538,370,501)
operator[61]: type(1)
	outputs[0] region(1540,371,502)
operator[62]: type(1)
	outputs[0] region(1546,374,505)
operator[63]: type(1)
	outputs[0] region(1548,375,506)
operator[64]: type(1)
	outputs[0] region(1552,377,508)
operator[65]: type(1)
	outputs[0] region(1554,378,509)
operator[66]: type(1)
	outputs[0] region(1556,379,510)
operator[67]: type(1)
	outputs[0] region(1562,382,513)
operator[68]: type(1)
	outputs[0] region(1564,383,514)
operator[69]: type(1)
	outputs[0] region(1570,386,517)
operator[70]: type(1)
	outputs[0] region(1572,387,518)
operator[71]: type(1)
	outputs[0] region(1576,389,520)
operator[72]: type(1)
	outputs[0] region(1578,390,521)
operator[73]: type(1)
	outputs[0] region(1584,393,524)
operator[74]: type(1)
	outputs[0] region(1586,394,525)
operator[75]: type(1)
	outputs[0] region(1590,396,527)
operator[76]: type(1)
	outputs[0] region(1592,397,528)
operator[77]: type(1)
	outputs[0] region(1594,398,529)
operator[78]: type(1)
	outputs[0] region(1600,401,532)
operator[79]: type(1)
	outputs[0] region(1602,402,533)
operator[80]: type(1)
	outputs[0] region(1608,405,536)
operator[81]: type(1)
	outputs[0] region(1610,406,537)
operator[82]: type(1)
	outputs[0] region(1614,408,539)
operator[83]: type(1)
	outputs[0] region(1616,409,540)
operator[84]: type(1)
	outputs[0] region(1622,412,543)
operator[85]: type(1)
	outputs[0] region(1624,413,544)
operator[86]: type(1)
	outputs[0] region(1628,415,546)
operator[87]: type(1)
	outputs[0] region(1630,416,547)
operator[88]: type(1)
	outputs[0] region(1632,417,548)
operator[89]: type(1)
	outputs[0] region(1638,420,551)
operator[90]: type(1)
	outputs[0] region(1640,421,552)
operator[91]: type(1)
	outputs[0] region(1646,424,555)
operator[92]: type(1)
	outputs[0] region(1648,425,556)
operator[93]: type(1)
	outputs[0] region(1652,427,558)
operator[94]: type(1)
	outputs[0] region(1654,428,559)
operator[95]: type(1)
	outputs[0] region(1660,431,562)
operator[96]: type(1)
	outputs[0] region(1662,432,563)
operator[97]: type(1)
	outputs[0] region(1666,434,565)
operator[98]: type(1)
	outputs[0] region(1668,435,566)
operator[99]: type(1)
	outputs[0] region(1670,436,567)
operator[100]: type(1)
	outputs[0] region(1676,439,570)
operator[101]: type(1)
	outputs[0] region(1678,440,571)
operator[102]: type(1)
	outputs[0] region(1684,443,574)
operator[103]: type(1)
	outputs[0] region(1686,444,575)
operator[104]: type(1)
	outputs[0] region(1690,446,577)
operator[105]: type(1)
	outputs[0] region(1692,447,578)
operator[106]: type(1)
	outputs[0] region(1698,450,581)
operator[107]: type(1)
	outputs[0] region(1700,451,582)
operator[108]: type(1)
	outputs[0] region(1704,453,584)
operator[109]: type(1)
	outputs[0] region(1706,454,585)
operator[110]: type(1)
	outputs[0] region(1708,455,586)
operator[111]: type(1)
	outputs[0] region(1714,458,589)
operator[112]: type(1)
	outputs[0] region(1716,459,590)
operator[113]: type(1)
	outputs[0] region(1722,462,593)
operator[114]: type(1)
	outputs[0] region(1724,463,594)
operator[115]: type(1)
	outputs[0] region(1728,465,596)
operator[116]: type(1)
	outputs[0] region(1730,466,597)
operator[117]: type(1)
	outputs[0] region(1736,469,600)
operator[118]: type(1)
	outputs[0] region(1738,470,601)
operator[119]: type(1)
	outputs[0] region(1742,472,603)
operator[120]: type(1)
	outputs[0] region(1744,473,604)
operator[121]: type(1)
	outputs[0] region(1746,474,605)
operator[122]: type(1)
	outputs[0] region(1752,477,608)
operator[123]: type(1)
	outputs[0] region(1754,478,609)
operator[124]: type(1)
	outputs[0] region(1760,481,612)
operator[125]: type(1)
	outputs[0] region(1762,482,613)
operator[126]: type(1)
	outputs[0] region(1766,484,615)
operator[127]: type(1)
	outputs[0] region(1768,485,616)
operator[128]: type(1)
	outputs[0] region(1774,488,619)
operator[129]: type(1)
	outputs[0] region(1776,489,620)
operator[130]: type(1)
	outputs[0] region(1780,491,622)
operator[131]: type(1)
	outputs[0] region(1782,492,623)
operator[132]: type(1)
	outputs[0] region(1784,493,624)
operator[133]: type(1)
	outputs[0] region(1790,496,627)
operator[134]: type(1)
	outputs[0] region(1792,497,628)
operator[135]: type(1)
	outputs[0] region(1798,500,631)
operator[136]: type(1)
	outputs[0] region(1800,501,632)
operator[137]: type(1)
	outputs[0] region(1804,503,634)
operator[138]: type(1)
	outputs[0] region(1806,504,635)
operator[139]: type(1)
	outputs[0] region(1812,507,638)
operator[140]: type(91)
	inputs[0] region(1816,509,640)
	outputs[0] region(1818,510,641)
	outputs[1] region(1820,511,642)
Loading weight file embed_tokens_weight
Loading weight file embed_positions_weight
Loading weight file layers_0_attention_layer_norm_weight
Loading weight file layers_0_attention_layer_norm_bias
Loading weight file layers_0_attention_wq_weight
Loading weight file layers_0_attention_wk_weight
Loading weight file layers_0_attention_wv_weight
Loading weight file layers_0_attention_wo_weight
Loading weight file layers_0_attention_wq_bias
Loading weight file layers_0_attention_wk_bias
Loading weight file layers_0_attention_wv_bias
Loading weight file layers_0_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_0_add_bias_residual_layer_norm_weight
Loading weight file layers_0_add_bias_residual_layer_norm_bias
Loading weight file layers_0_fc1_weight
Loading weight file layers_0_fc1_bias
Loading weight file layers_0_fc2_weight
Loading weight file layers_0_fc2_bias
Loading weight file layers_1_attention_layer_norm_weight
Loading weight file layers_1_attention_layer_norm_bias
Loading weight file layers_1_attention_wq_weight
Loading weight file layers_1_attention_wk_weight
Loading weight file layers_1_attention_wv_weight
Loading weight file layers_1_attention_wo_weight
Loading weight file layers_1_attention_wq_bias
Loading weight file layers_1_attention_wk_bias
Loading weight file layers_1_attention_wv_bias
Loading weight file layers_1_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_1_add_bias_residual_layer_norm_weight
Loading weight file layers_1_add_bias_residual_layer_norm_bias
Loading weight file layers_1_fc1_weight
Loading weight file layers_1_fc1_bias
Loading weight file layers_1_fc2_weight
Loading weight file layers_1_fc2_bias
Loading weight file layers_2_attention_layer_norm_weight
Loading weight file layers_2_attention_layer_norm_bias
Loading weight file layers_2_attention_wq_weight
Loading weight file layers_2_attention_wk_weight
Loading weight file layers_2_attention_wv_weight
Loading weight file layers_2_attention_wo_weight
Loading weight file layers_2_attention_wq_bias
Loading weight file layers_2_attention_wk_bias
Loading weight file layers_2_attention_wv_bias
Loading weight file layers_2_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_2_add_bias_residual_layer_norm_weight
Loading weight file layers_2_add_bias_residual_layer_norm_bias
Loading weight file layers_2_fc1_weight
Loading weight file layers_2_fc1_bias
Loading weight file layers_2_fc2_weight
Loading weight file layers_2_fc2_bias
Loading weight file layers_3_attention_layer_norm_weight
Loading weight file layers_3_attention_layer_norm_bias
Loading weight file layers_3_attention_wq_weight
Loading weight file layers_3_attention_wk_weight
Loading weight file layers_3_attention_wv_weight
Loading weight file layers_3_attention_wo_weight
Loading weight file layers_3_attention_wq_bias
Loading weight file layers_3_attention_wk_bias
Loading weight file layers_3_attention_wv_bias
Loading weight file layers_3_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_3_add_bias_residual_layer_norm_weight
Loading weight file layers_3_add_bias_residual_layer_norm_bias
Loading weight file layers_3_fc1_weight
Loading weight file layers_3_fc1_bias
Loading weight file layers_3_fc2_weight
Loading weight file layers_3_fc2_bias
Loading weight file layers_4_attention_layer_norm_weight
Loading weight file layers_4_attention_layer_norm_bias
Loading weight file layers_4_attention_wq_weight
Loading weight file layers_4_attention_wk_weight
Loading weight file layers_4_attention_wv_weight
Loading weight file layers_4_attention_wo_weight
Loading weight file layers_4_attention_wq_bias
Loading weight file layers_4_attention_wk_bias
Loading weight file layers_4_attention_wv_bias
Loading weight file layers_4_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_4_add_bias_residual_layer_norm_weight
Loading weight file layers_4_add_bias_residual_layer_norm_bias
Loading weight file layers_4_fc1_weight
Loading weight file layers_4_fc1_bias
Loading weight file layers_4_fc2_weight
Loading weight file layers_4_fc2_bias
Loading weight file layers_5_attention_layer_norm_weight
Loading weight file layers_5_attention_layer_norm_bias
Loading weight file layers_5_attention_wq_weight
Loading weight file layers_5_attention_wk_weight
Loading weight file layers_5_attention_wv_weight
Loading weight file layers_5_attention_wo_weight
Loading weight file layers_5_attention_wq_bias
Loading weight file layers_5_attention_wk_bias
Loading weight file layers_5_attention_wv_bias
Loading weight file layers_5_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_5_add_bias_residual_layer_norm_weight
Loading weight file layers_5_add_bias_residual_layer_norm_bias
Loading weight file layers_5_fc1_weight
Loading weight file layers_5_fc1_bias
Loading weight file layers_5_fc2_weight
Loading weight file layers_5_fc2_bias
Loading weight file layers_6_attention_layer_norm_weight
Loading weight file layers_6_attention_layer_norm_bias
Loading weight file layers_6_attention_wq_weight
Loading weight file layers_6_attention_wk_weight
Loading weight file layers_6_attention_wv_weight
Loading weight file layers_6_attention_wo_weight
Loading weight file layers_6_attention_wq_bias
Loading weight file layers_6_attention_wk_bias
Loading weight file layers_6_attention_wv_bias
Loading weight file layers_6_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_6_add_bias_residual_layer_norm_weight
Loading weight file layers_6_add_bias_residual_layer_norm_bias
Loading weight file layers_6_fc1_weight
Loading weight file layers_6_fc1_bias
Loading weight file layers_6_fc2_weight
Loading weight file layers_6_fc2_bias
Loading weight file layers_7_attention_layer_norm_weight
Loading weight file layers_7_attention_layer_norm_bias
Loading weight file layers_7_attention_wq_weight
Loading weight file layers_7_attention_wk_weight
Loading weight file layers_7_attention_wv_weight
Loading weight file layers_7_attention_wo_weight
Loading weight file layers_7_attention_wq_bias
Loading weight file layers_7_attention_wk_bias
Loading weight file layers_7_attention_wv_bias
Loading weight file layers_7_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_7_add_bias_residual_layer_norm_weight
Loading weight file layers_7_add_bias_residual_layer_norm_bias
Loading weight file layers_7_fc1_weight
Loading weight file layers_7_fc1_bias
Loading weight file layers_7_fc2_weight
Loading weight file layers_7_fc2_bias
Loading weight file layers_8_attention_layer_norm_weight
Loading weight file layers_8_attention_layer_norm_bias
Loading weight file layers_8_attention_wq_weight
Loading weight file layers_8_attention_wk_weight
Loading weight file layers_8_attention_wv_weight
Loading weight file layers_8_attention_wo_weight
Loading weight file layers_8_attention_wq_bias
Loading weight file layers_8_attention_wk_bias
Loading weight file layers_8_attention_wv_bias
Loading weight file layers_8_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_8_add_bias_residual_layer_norm_weight
Loading weight file layers_8_add_bias_residual_layer_norm_bias
Loading weight file layers_8_fc1_weight
Loading weight file layers_8_fc1_bias
Loading weight file layers_8_fc2_weight
Loading weight file layers_8_fc2_bias
Loading weight file layers_9_attention_layer_norm_weight
Loading weight file layers_9_attention_layer_norm_bias
Loading weight file layers_9_attention_wq_weight
Loading weight file layers_9_attention_wk_weight
Loading weight file layers_9_attention_wv_weight
Loading weight file layers_9_attention_wo_weight
Loading weight file layers_9_attention_wq_bias
Loading weight file layers_9_attention_wk_bias
Loading weight file layers_9_attention_wv_bias
Loading weight file layers_9_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_9_add_bias_residual_layer_norm_weight
Loading weight file layers_9_add_bias_residual_layer_norm_bias
Loading weight file layers_9_fc1_weight
Loading weight file layers_9_fc1_bias
Loading weight file layers_9_fc2_weight
Loading weight file layers_9_fc2_bias
Loading weight file layers_10_attention_layer_norm_weight
Loading weight file layers_10_attention_layer_norm_bias
Loading weight file layers_10_attention_wq_weight
Loading weight file layers_10_attention_wk_weight
Loading weight file layers_10_attention_wv_weight
Loading weight file layers_10_attention_wo_weight
Loading weight file layers_10_attention_wq_bias
Loading weight file layers_10_attention_wk_bias
Loading weight file layers_10_attention_wv_bias
Loading weight file layers_10_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_10_add_bias_residual_layer_norm_weight
Loading weight file layers_10_add_bias_residual_layer_norm_bias
Loading weight file layers_10_fc1_weight
Loading weight file layers_10_fc1_bias
Loading weight file layers_10_fc2_weight
Loading weight file layers_10_fc2_bias
Loading weight file layers_11_attention_layer_norm_weight
Loading weight file layers_11_attention_layer_norm_bias
Loading weight file layers_11_attention_wq_weight
Loading weight file layers_11_attention_wk_weight
Loading weight file layers_11_attention_wv_weight
Loading weight file layers_11_attention_wo_weight
Loading weight file layers_11_attention_wq_bias
Loading weight file layers_11_attention_wk_bias
Loading weight file layers_11_attention_wv_bias
Loading weight file layers_11_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_11_add_bias_residual_layer_norm_weight
Loading weight file layers_11_add_bias_residual_layer_norm_bias
Loading weight file layers_11_fc1_weight
Loading weight file layers_11_fc1_bias
Loading weight file layers_11_fc2_weight
Loading weight file layers_11_fc2_bias
Loading weight file final_layer_norm_weight
Loading weight file final_layer_norm_bias
Loading weight file embed_tokens_weight_lm_head
------finished loading weights----------
[0 - 7fd9a669a000]    8.664394 {3}{spec_infer}: SSM create_opt_model finished!
Register new model with id: 0
Prompt[0]: please introduce LeBron James, who plays basketball in NBA.

Prompt[1]: write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.
Prompt[2]: Write a comedy sketch about yourself fighting for your rights.
[0 - 7fd9a669a000]    8.664632 {3}{spec_infer}: total_num_requests: 3
[0 - 7fd9a669a000]    8.664635 {3}{spec_infer}: start SPS tree_model.generate
[0]37111
[1]6581
[2]9517
[3]957
[4]6
[5]54
[6]1974
[7]2613
[8]11
[9]2762
[10]4
[11]50118
[0 - 7fd9a669a000]    8.665198 {3}{RequestManager}: request.initial_len: 13
Num of models: 1
[0 - 7fd9a669a000]    8.665239 {3}{RequestManager}: [1000000]New request tokens: 2 37111 6581 9517 957 6 54 1974 2613 11 2762 4 50118
[0 - 7fd9a669a000]    8.665245 {3}{RequestManager}: guid:1000000
[0]29631
[1]5
[2]94
[3]26346
[4]9
[5]5
[6]22
[7]1092
[8]10046
[9]9
[10]1619
[11]113
[12]2214
[13]114
[14]5
[15]4085
[16]889
[17]58
[18]70
[19]7420
[20]13
[21]10
[22]7359
[23]12749
[24]101
[25]2512
[26]4
[27]27047
[28]349
[29]516
[30]19
[31]5
[32]12337
[33]346
[34]9
[35]167
[36]7420
[37]228
[38]5
[39]2214
[40]4
[0 - 7fd9a669a000]    8.665567 {3}{RequestManager}: request.initial_len: 42
Num of models: 1
[0 - 7fd9a669a000]    8.665597 {3}{RequestManager}: [1000001]New request tokens: 2 29631 5 94 26346 9 5 22 1092 10046 9 1619 113 2214 114 5 4085 889 58 70 7420 13 10 7359 12749 101 2512 4 27047 349 516 19 5 12337 346 9 167 7420 228 5 2214 4
[0 - 7fd9a669a000]    8.665600 {3}{RequestManager}: guid:1000001
[0]45714
[1]10
[2]5313
[3]15923
[4]59
[5]2512
[6]2190
[7]13
[8]110
[9]659
[10]4
[0 - 7fd9a669a000]    8.665685 {3}{RequestManager}: request.initial_len: 12
Num of models: 1
[0 - 7fd9a669a000]    8.665707 {3}{RequestManager}: [1000002]New request tokens: 2 45714 10 5313 15923 59 2512 2190 13 110 659 4
[0 - 7fd9a669a000]    8.665710 {3}{RequestManager}: guid:1000002
[0 - 7fd9a669a000]    8.665836 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.665844 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666102 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666129 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666148 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666155 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666353 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666366 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666376 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666382 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666565 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666589 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666594 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666765 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666777 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666788 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666792 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666966 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666990 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.666995 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667167 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667185 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667195 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667202 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667374 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667392 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667403 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667408 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667587 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667598 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667612 {3}{RequestManager}: SSMs inference time:0.0017944 s.
[0 - 7fd9a669a000]    8.667627 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667634 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667655 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667684 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.667700 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668040 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668207 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668221 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668226 {3}{RequestManager}: LLM Tree Verification time:0.000619508 s.
[0 - 7fd9a669a000]    8.668259 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668289 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668480 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668494 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668504 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668509 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668676 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668696 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668705 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668710 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668881 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668898 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668907 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.668914 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669089 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669099 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669110 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669115 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669300 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669311 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669322 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669327 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669495 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669513 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669522 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669527 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669695 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669721 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669728 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669902 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669912 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669921 {3}{RequestManager}: SSMs inference time:0.00166624 s.
[0 - 7fd9a669a000]    8.669932 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669937 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669950 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669968 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.669983 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670259 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670271 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670284 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670288 {3}{RequestManager}: LLM Tree Verification time:0.000368001 s.
[0 - 7fd9a669a000]    8.670311 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670316 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670483 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670496 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670528 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670533 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670696 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670722 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670728 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670891 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670909 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670919 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.670925 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671094 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671106 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671117 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671122 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671290 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671301 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671310 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671315 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671477 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671499 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671508 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671514 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671680 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671700 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671711 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671716 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671889 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671899 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671908 {3}{RequestManager}: SSMs inference time:0.0016008 s.
[0 - 7fd9a669a000]    8.671917 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671922 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671935 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671952 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.671965 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672233 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672258 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672262 {3}{RequestManager}: LLM Tree Verification time:0.000354777 s.
[0 - 7fd9a669a000]    8.672278 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672284 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672456 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672469 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672478 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672483 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672636 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672675 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672684 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672690 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672849 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672866 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672875 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.672883 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673039 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673051 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673062 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673067 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673231 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673243 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673252 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673258 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673403 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673430 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673436 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673584 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673601 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673610 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673617 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673764 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673774 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673782 {3}{RequestManager}: SSMs inference time:0.00150789 s.
[0 - 7fd9a669a000]    8.673791 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673796 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673807 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673823 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.673836 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.674071 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.674083 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.674093 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    8.674097 {3}{RequestManager}: LLM Tree Verification time:0.000316201 s.

############### prepare_next_batch_init ###############
SSM KV Cache Size init: 13
LLM KV Cache Size init: 0
load 13 tokens for request 1000000
total prompt in request: 13
SSM KV Cache Size init: 42
LLM KV Cache Size init: 0
load 42 tokens for request 1000001
total prompt in request: 42
SSM KV Cache Size init: 12
LLM KV Cache Size init: 0
load 12 tokens for request 1000002
total prompt in request: 12

############### prepare_next_batch_verify ###############
max_prompt_load_size: 240
new_bc.requestsInfo[i].num_tokens_in_batch: 13
max_prompt_load_size: 198
new_bc.requestsInfo[i].num_tokens_in_batch: 42
max_prompt_load_size: 186
new_bc.requestsInfo[i].num_tokens_in_batch: 12
[0 - 7fd9a669a000]    9.302103 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.302134 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.302650 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.302817 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.302849 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.302861 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303269 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303303 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303328 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303339 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303731 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303763 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303786 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.303798 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304213 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304234 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304245 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304629 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304659 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304681 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.304692 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305093 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305122 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305144 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305155 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305567 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305589 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305600 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.305982 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306010 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306034 {3}{RequestManager}: SSMs inference time:0.00397105 s.
[0 - 7fd9a669a000]    9.306057 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306069 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306100 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306145 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306181 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306757 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306791 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306823 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.306836 {3}{RequestManager}: LLM Tree Verification time:0.000806521 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 12
  Input: [12] 50118 ---> [13] 100 
[0 - 7fd9a669a000]    9.323043 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7fd9a669a000]    9.323052 {3}{RequestManager}: Input tree: 12:50118
[0 - 7fd9a669a000]    9.323057 {3}{RequestManager}: Output tree: 13:100
[0 - 7fd9a669a000]    9.323061 {3}{RequestManager}: Committed tokens: 12:12
[0 - 7fd9a669a000]    9.323069 {3}{RequestManager}: Verified: 13:100
[0 - 7fd9a669a000]    9.323073 {3}{RequestManager}: New committed: 12:12
[0 - 7fd9a669a000]    9.323076 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7fd9a669a000]    9.323236 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I
[ 1000001 ]
Index within old batch: 54
  Input: [41] 4 ---> [42] 50118 
[0 - 7fd9a669a000]    9.323291 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7fd9a669a000]    9.323295 {3}{RequestManager}: Input tree: 41:4
[0 - 7fd9a669a000]    9.323299 {3}{RequestManager}: Output tree: 42:50118
[0 - 7fd9a669a000]    9.323303 {3}{RequestManager}: Committed tokens: 54:41
[0 - 7fd9a669a000]    9.323307 {3}{RequestManager}: Verified: 42:50118
[0 - 7fd9a669a000]    9.323311 {3}{RequestManager}: New committed: 54:41
[0 - 7fd9a669a000]    9.323314 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7fd9a669a000]    9.323375 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

[ 1000002 ]
Index within old batch: 66
  Input: [11] 4 ---> [12] 50118 
[0 - 7fd9a669a000]    9.323409 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7fd9a669a000]    9.323413 {3}{RequestManager}: Input tree: 11:4
[0 - 7fd9a669a000]    9.323416 {3}{RequestManager}: Output tree: 12:50118
[0 - 7fd9a669a000]    9.323419 {3}{RequestManager}: Committed tokens: 66:11
[0 - 7fd9a669a000]    9.323423 {3}{RequestManager}: Verified: 12:50118
[0 - 7fd9a669a000]    9.323427 {3}{RequestManager}: New committed: 66:11
[0 - 7fd9a669a000]    9.323429 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7fd9a669a000]    9.323454 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.


############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]    9.489060 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.489089 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.489569 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.489612 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.489640 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.489653 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490042 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490072 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490094 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490106 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490529 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490550 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490561 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490948 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490977 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.490998 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491008 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491394 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491423 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491446 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491457 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491842 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491873 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491895 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.491906 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492288 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492315 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492336 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492349 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492738 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492763 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492785 {3}{RequestManager}: SSMs inference time:0.00375731 s.
[0 - 7fd9a669a000]    9.492806 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492818 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492851 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492906 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.492942 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.493520 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.493554 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.493578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.493591 {3}{RequestManager}: LLM Tree Verification time:0.000809586 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [13] 100 ---> [14] 437 
Index within old batch: 1
  Input: [14] 437 ---> [15] 45 
Index within old batch: 2
  Input: [15] 45 ---> [16] 686 
Index within old batch: 3
  Input: [16] 686 ---> [17] 114 
Index within old batch: 4
  Input: [17] 114 ---> [18] 47 
Index within old batch: 5
  Input: [18] 47 ---> [19] 214 
Index within old batch: 6
  Input: [19] 214 ---> [20] 22024 
Index within old batch: 7
  Input: [20] 22024 ---> [21] 50 
Index within old batch: 8
  Input: [21] 50 ---> [22] 45 
[0 - 7fd9a669a000]    9.493796 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.493808 {3}{RequestManager}: Input tree: 13:100 14:437 15:45 16:686 17:114 18:47 19:214 20:22024 21:50
[0 - 7fd9a669a000]    9.493817 {3}{RequestManager}: Output tree: 14:437 15:45 16:686 17:114 18:47 19:214 20:22024 21:50 22:45
[0 - 7fd9a669a000]    9.493826 {3}{RequestManager}: Committed tokens: 0:13 1:14 2:15 3:16 4:17 5:18 6:19 7:20 8:21
[0 - 7fd9a669a000]    9.493839 {3}{RequestManager}: Verified: 14:437 15:45 16:686 17:114 18:47 19:214 20:22024 21:50 22:45
[0 - 7fd9a669a000]    9.493847 {3}{RequestManager}: New committed: 0:13 1:14 2:15 3:16 4:17 5:18 6:19 7:20 8:21
[0 - 7fd9a669a000]    9.493850 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.493931 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not
[ 1000001 ]
Index within old batch: 9
  Input: [42] 50118 ---> [43] 50118 
Index within old batch: 10
  Input: [43] 50118 ---> [44] 100 
Index within old batch: 11
  Input: [44] 100 ---> [45] 437 
Index within old batch: 12
  Input: [45] 437 ---> [46] 45 
Index within old batch: 13
  Input: [46] 45 ---> [47] 686 
Index within old batch: 14
  Input: [47] 686 ---> [48] 114 
Index within old batch: 15
  Input: [48] 114 ---> [49] 42 
Index within old batch: 16
  Input: [49] 42 ---> [50] 16 
Index within old batch: 17
  Input: [50] 16 ---> [51] 10 
[0 - 7fd9a669a000]    9.494059 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.494067 {3}{RequestManager}: Input tree: 42:50118 43:50118 44:100 45:437 46:45 47:686 48:114 49:42 50:16
[0 - 7fd9a669a000]    9.494074 {3}{RequestManager}: Output tree: 43:50118 44:100 45:437 46:45 47:686 48:114 49:42 50:16 51:10
[0 - 7fd9a669a000]    9.494081 {3}{RequestManager}: Committed tokens: 9:42 10:43 11:44 12:45 13:46 14:47 15:48 16:49 17:50
[0 - 7fd9a669a000]    9.494091 {3}{RequestManager}: Verified: 43:50118 44:100 45:437 46:45 47:686 48:114 49:42 50:16 51:10
[0 - 7fd9a669a000]    9.494098 {3}{RequestManager}: New committed: 9:42 10:43 11:44 12:45 13:46 14:47 15:48 16:49 17:50
[0 - 7fd9a669a000]    9.494101 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.494173 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a
[ 1000002 ]
Index within old batch: 18
  Input: [12] 50118 ---> [13] 100 
Index within old batch: 19
  Input: [13] 100 ---> [14] 437 
Index within old batch: 20
  Input: [14] 437 ---> [15] 45 
Index within old batch: 21
  Input: [15] 45 ---> [16] 686 
Index within old batch: 22
  Input: [16] 686 ---> [17] 114 
Index within old batch: 23
  Input: [17] 114 ---> [18] 14 
Index within old batch: 24
  Input: [18] 14 ---> [19] 18 
Index within old batch: 25
  Input: [19] 18 ---> [20] 10 
Index within old batch: 26
  Input: [20] 10 ---> [21] 205 
[0 - 7fd9a669a000]    9.494308 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.494316 {3}{RequestManager}: Input tree: 12:50118 13:100 14:437 15:45 16:686 17:114 18:14 19:18 20:10
[0 - 7fd9a669a000]    9.494323 {3}{RequestManager}: Output tree: 13:100 14:437 15:45 16:686 17:114 18:14 19:18 20:10 21:205
[0 - 7fd9a669a000]    9.494329 {3}{RequestManager}: Committed tokens: 18:12 19:13 20:14 21:15 22:16 23:17 24:18 25:19 26:20
[0 - 7fd9a669a000]    9.494339 {3}{RequestManager}: Verified: 13:100 14:437 15:45 16:686 17:114 18:14 19:18 20:10 21:205
[0 - 7fd9a669a000]    9.494346 {3}{RequestManager}: New committed: 18:12 19:13 20:14 21:15 22:16 23:17 24:18 25:19 26:20
[0 - 7fd9a669a000]    9.494349 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.494386 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]    9.598926 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.598945 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599387 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599424 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599448 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599460 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599840 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599868 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599891 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.599902 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600278 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600304 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600327 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600337 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600741 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600762 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.600773 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601276 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601305 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601327 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601339 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601740 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601763 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.601774 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602142 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602169 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602191 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602203 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602576 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602601 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602622 {3}{RequestManager}: SSMs inference time:0.00371365 s.
[0 - 7fd9a669a000]    9.602646 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602658 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602689 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602728 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.602764 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.603305 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.603336 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.603359 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.603370 {3}{RequestManager}: LLM Tree Verification time:0.000751645 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [22] 45 ---> [23] 6 
Index within old batch: 1
  Input: [23] 6 ---> [24] 53 
Index within old batch: 2
  Input: [24] 53 ---> [25] 38 
Index within old batch: 3
  Input: [25] 38 ---> [26] 437 
Index within old batch: 4
  Input: [26] 437 ---> [27] 1256 
Index within old batch: 5
  Input: [27] 1256 ---> [28] 686 
Index within old batch: 6
  Input: [28] 686 ---> [29] 37 
Index within old batch: 7
  Input: [29] 37 ---> [30] 18 
Index within old batch: 8
  Input: [30] 18 ---> [31] 10 
[0 - 7fd9a669a000]    9.603562 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.603573 {3}{RequestManager}: Input tree: 22:45 23:6 24:53 25:38 26:437 27:1256 28:686 29:37 30:18
[0 - 7fd9a669a000]    9.603581 {3}{RequestManager}: Output tree: 23:6 24:53 25:38 26:437 27:1256 28:686 29:37 30:18 31:10
[0 - 7fd9a669a000]    9.603589 {3}{RequestManager}: Committed tokens: 0:22 1:23 2:24 3:25 4:26 5:27 6:28 7:29 8:30
[0 - 7fd9a669a000]    9.603601 {3}{RequestManager}: Verified: 23:6 24:53 25:38 26:437 27:1256 28:686 29:37 30:18 31:10
[0 - 7fd9a669a000]    9.603608 {3}{RequestManager}: New committed: 0:22 1:23 2:24 3:25 4:26 5:27 6:28 7:29 8:30
[0 - 7fd9a669a000]    9.603612 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.603678 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a
[ 1000001 ]
Index within old batch: 9
  Input: [51] 10 ---> [52] 205 
Index within old batch: 10
  Input: [52] 205 ---> [53] 1114 
Index within old batch: 11
  Input: [53] 1114 ---> [54] 6 
Index within old batch: 12
  Input: [54] 6 ---> [55] 53 
Index within old batch: 13
  Input: [55] 53 ---> [56] 38 
Index within old batch: 14
  Input: [56] 38 ---> [57] 437 
Index within old batch: 15
  Input: [57] 437 ---> [58] 45 
Index within old batch: 16
  Input: [58] 45 ---> [59] 686 
Index within old batch: 17
  Input: [59] 686 ---> [60] 114 
[0 - 7fd9a669a000]    9.603809 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.603817 {3}{RequestManager}: Input tree: 51:10 52:205 53:1114 54:6 55:53 56:38 57:437 58:45 59:686
[0 - 7fd9a669a000]    9.603824 {3}{RequestManager}: Output tree: 52:205 53:1114 54:6 55:53 56:38 57:437 58:45 59:686 60:114
[0 - 7fd9a669a000]    9.603831 {3}{RequestManager}: Committed tokens: 9:51 10:52 11:53 12:54 13:55 14:56 15:57 16:58 17:59
[0 - 7fd9a669a000]    9.603840 {3}{RequestManager}: Verified: 52:205 53:1114 54:6 55:53 56:38 57:437 58:45 59:686 60:114
[0 - 7fd9a669a000]    9.603847 {3}{RequestManager}: New committed: 9:51 10:52 11:53 12:54 13:55 14:56 15:57 16:58 17:59
[0 - 7fd9a669a000]    9.603850 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.603920 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if
[ 1000002 ]
Index within old batch: 18
  Input: [21] 205 ---> [22] 1114 
Index within old batch: 19
  Input: [22] 1114 ---> [23] 4 
Index within old batch: 20
  Input: [23] 4 ---> [24] 38 
Index within old batch: 21
  Input: [24] 38 ---> [25] 437 
Index within old batch: 22
  Input: [25] 437 ---> [26] 45 
Index within old batch: 23
  Input: [26] 45 ---> [27] 686 
Index within old batch: 24
  Input: [27] 686 ---> [28] 114 
Index within old batch: 25
  Input: [28] 114 ---> [29] 38 
Index within old batch: 26
  Input: [29] 38 ---> [30] 236 
[0 - 7fd9a669a000]    9.604039 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.604046 {3}{RequestManager}: Input tree: 21:205 22:1114 23:4 24:38 25:437 26:45 27:686 28:114 29:38
[0 - 7fd9a669a000]    9.604053 {3}{RequestManager}: Output tree: 22:1114 23:4 24:38 25:437 26:45 27:686 28:114 29:38 30:236
[0 - 7fd9a669a000]    9.604059 {3}{RequestManager}: Committed tokens: 18:21 19:22 20:23 21:24 22:25 23:26 24:27 25:28 26:29
[0 - 7fd9a669a000]    9.604068 {3}{RequestManager}: Verified: 22:1114 23:4 24:38 25:437 26:45 27:686 28:114 29:38 30:236
[0 - 7fd9a669a000]    9.604075 {3}{RequestManager}: New committed: 18:21 19:22 20:23 21:24 22:25 23:26 24:27 25:28 26:29
[0 - 7fd9a669a000]    9.604078 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.604117 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]    9.736021 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736046 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736504 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736543 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736571 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736583 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.736985 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737014 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737037 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737049 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737438 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737465 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737486 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737497 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737872 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737899 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737921 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.737932 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738307 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738334 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738355 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738366 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738735 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738763 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738783 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.738794 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739168 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739194 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739215 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739593 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739620 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739642 {3}{RequestManager}: SSMs inference time:0.0036483 s.
[0 - 7fd9a669a000]    9.739662 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739674 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739705 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739745 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.739779 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.740309 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.740341 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.740365 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.740376 {3}{RequestManager}: LLM Tree Verification time:0.00073866 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [31] 10 ---> [32] 2613 
Index within old batch: 1
  Input: [32] 2613 ---> [33] 869 
Index within old batch: 2
  Input: [33] 869 ---> [34] 4 
Index within old batch: 3
  Input: [34] 4 ---> [35] 50118 
Index within old batch: 4
  Input: [35] 50118 ---> [36] 100 
Index within old batch: 5
  Input: [36] 100 ---> [37] 437 
Index within old batch: 6
  Input: [37] 437 ---> [38] 45 
Index within old batch: 7
  Input: [38] 45 ---> [39] 22024 
Index within old batch: 8
  Input: [39] 22024 ---> [40] 4 
[0 - 7fd9a669a000]    9.740572 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.740583 {3}{RequestManager}: Input tree: 31:10 32:2613 33:869 34:4 35:50118 36:100 37:437 38:45 39:22024
[0 - 7fd9a669a000]    9.740591 {3}{RequestManager}: Output tree: 32:2613 33:869 34:4 35:50118 36:100 37:437 38:45 39:22024 40:4
[0 - 7fd9a669a000]    9.740600 {3}{RequestManager}: Committed tokens: 0:31 1:32 2:33 3:34 4:35 5:36 6:37 7:38 8:39
[0 - 7fd9a669a000]    9.740611 {3}{RequestManager}: Verified: 32:2613 33:869 34:4 35:50118 36:100 37:437 38:45 39:22024 40:4
[0 - 7fd9a669a000]    9.740619 {3}{RequestManager}: New committed: 0:31 1:32 2:33 3:34 4:35 5:36 6:37 7:38 8:39
[0 - 7fd9a669a000]    9.740622 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.740691 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking.
[ 1000001 ]
Index within old batch: 9
  Input: [60] 114 ---> [61] 24 
Index within old batch: 10
  Input: [61] 24 ---> [62] 18 
Index within old batch: 11
  Input: [62] 18 ---> [63] 10 
Index within old batch: 12
  Input: [63] 10 ---> [64] 205 
Index within old batch: 13
  Input: [64] 205 ---> [65] 1114 
Index within old batch: 14
  Input: [65] 1114 ---> [66] 7 
Index within old batch: 15
  Input: [66] 7 ---> [67] 33 
Index within old batch: 16
  Input: [67] 33 ---> [68] 10 
Index within old batch: 17
  Input: [68] 10 ---> [69] 7359 
[0 - 7fd9a669a000]    9.740839 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.740848 {3}{RequestManager}: Input tree: 60:114 61:24 62:18 63:10 64:205 65:1114 66:7 67:33 68:10
[0 - 7fd9a669a000]    9.740855 {3}{RequestManager}: Output tree: 61:24 62:18 63:10 64:205 65:1114 66:7 67:33 68:10 69:7359
[0 - 7fd9a669a000]    9.740862 {3}{RequestManager}: Committed tokens: 9:60 10:61 11:62 12:63 13:64 14:65 15:66 16:67 17:68
[0 - 7fd9a669a000]    9.740871 {3}{RequestManager}: Verified: 61:24 62:18 63:10 64:205 65:1114 66:7 67:33 68:10 69:7359
[0 - 7fd9a669a000]    9.740878 {3}{RequestManager}: New committed: 9:60 10:61 11:62 12:63 13:64 14:65 15:66 16:67 17:68
[0 - 7fd9a669a000]    9.740881 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.740964 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chat
[ 1000002 ]
Index within old batch: 18
  Input: [30] 236 ---> [31] 7 
Index within old batch: 19
  Input: [31] 7 ---> [32] 109 
Index within old batch: 20
  Input: [32] 109 ---> [33] 14 
Index within old batch: 21
  Input: [33] 14 ---> [34] 4 
Index within old batch: 22
  Input: [34] 4 ---> [35] 50118 
Index within old batch: 23
  Input: [35] 50118 ---> [36] 100 
Index within old batch: 24
  Input: [36] 100 ---> [37] 218 
Index within old batch: 25
  Input: [37] 218 ---> [38] 75 
Index within old batch: 26
  Input: [38] 75 ---> [39] 216 
[0 - 7fd9a669a000]    9.741085 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.741092 {3}{RequestManager}: Input tree: 30:236 31:7 32:109 33:14 34:4 35:50118 36:100 37:218 38:75
[0 - 7fd9a669a000]    9.741099 {3}{RequestManager}: Output tree: 31:7 32:109 33:14 34:4 35:50118 36:100 37:218 38:75 39:216
[0 - 7fd9a669a000]    9.741106 {3}{RequestManager}: Committed tokens: 18:30 19:31 20:32 21:33 22:34 23:35 24:36 25:37 26:38
[0 - 7fd9a669a000]    9.741115 {3}{RequestManager}: Verified: 31:7 32:109 33:14 34:4 35:50118 36:100 37:218 38:75 39:216
[0 - 7fd9a669a000]    9.741122 {3}{RequestManager}: New committed: 18:30 19:31 20:32 21:33 22:34 23:35 24:36 25:37 26:38
[0 - 7fd9a669a000]    9.741125 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.741183 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]    9.879873 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.879895 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880357 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880398 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880423 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880433 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880832 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880865 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880888 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.880900 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881277 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881307 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881329 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881340 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881711 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881740 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881761 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.881772 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882143 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882172 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882194 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882204 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882571 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882599 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882619 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882631 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.882994 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883021 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883042 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883053 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883414 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883441 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883461 {3}{RequestManager}: SSMs inference time:0.003608 s.
[0 - 7fd9a669a000]    9.883481 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883493 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883525 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883563 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.883594 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.884127 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.884158 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.884181 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]    9.884193 {3}{RequestManager}: LLM Tree Verification time:0.000735049 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [40] 4 ---> [41] 38 
Index within old batch: 1
  Input: [41] 38 ---> [42] 437 
Index within old batch: 2
  Input: [42] 437 ---> [43] 45 
Index within old batch: 3
  Input: [43] 45 ---> [44] 686 
Index within old batch: 4
  Input: [44] 686 ---> [45] 114 
Index within old batch: 5
  Input: [45] 114 ---> [46] 47 
Index within old batch: 6
  Input: [46] 47 ---> [47] 214 
Index within old batch: 7
  Input: [47] 214 ---> [48] 22024 
Index within old batch: 8
  Input: [48] 22024 ---> [49] 50 
[0 - 7fd9a669a000]    9.884395 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.884406 {3}{RequestManager}: Input tree: 40:4 41:38 42:437 43:45 44:686 45:114 46:47 47:214 48:22024
[0 - 7fd9a669a000]    9.884413 {3}{RequestManager}: Output tree: 41:38 42:437 43:45 44:686 45:114 46:47 47:214 48:22024 49:50
[0 - 7fd9a669a000]    9.884421 {3}{RequestManager}: Committed tokens: 0:40 1:41 2:42 3:43 4:44 5:45 6:46 7:47 8:48
[0 - 7fd9a669a000]    9.884432 {3}{RequestManager}: Verified: 41:38 42:437 43:45 44:686 45:114 46:47 47:214 48:22024 49:50
[0 - 7fd9a669a000]    9.884439 {3}{RequestManager}: New committed: 0:40 1:41 2:42 3:43 4:44 5:45 6:46 7:47 8:48
[0 - 7fd9a669a000]    9.884443 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.884505 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or
[ 1000001 ]
Index within old batch: 9
  Input: [69] 7359 ---> [70] 12749 
Index within old batch: 10
  Input: [70] 12749 ---> [71] 14 
Index within old batch: 11
  Input: [71] 14 ---> [72] 64 
Index within old batch: 12
  Input: [72] 64 ---> [73] 1166 
Index within old batch: 13
  Input: [73] 1166 ---> [74] 110 
Index within old batch: 14
  Input: [74] 5 ---> [75] 11440 
Index within old batch: 15
  Input: [75] 11440 ---> [76] 9 
Index within old batch: 16
  Input: [76] 9 ---> [77] 5 
Index within old batch: 17
  Input: [77] 5 ---> [78] 2214 
[0 - 7fd9a669a000]    9.884642 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.884649 {3}{RequestManager}: Input tree: 69:7359 70:12749 71:14 72:64 73:1166 74:5 75:11440 76:9 77:5
[0 - 7fd9a669a000]    9.884657 {3}{RequestManager}: Output tree: 70:12749 71:14 72:64 73:1166 74:110 75:11440 76:9 77:5 78:2214
[0 - 7fd9a669a000]    9.884664 {3}{RequestManager}: Committed tokens: 9:69 10:70 11:71 12:72 13:73 14:74 15:75 16:76 17:77
[0 - 7fd9a669a000]    9.884671 {3}{RequestManager}: Verified: 70:12749 71:14 72:64 73:1166 74:110
[0 - 7fd9a669a000]    9.884677 {3}{RequestManager}: New committed: 9:69 10:70 11:71 12:72 13:73
[0 - 7fd9a669a000]    9.884680 {3}{RequestManager}: Number of Verified Tokens = 5
[0 - 7fd9a669a000]    9.884777 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your
[ 1000002 ]
Index within old batch: 18
  Input: [39] 216 ---> [40] 6 
Index within old batch: 19
  Input: [40] 6 ---> [41] 38 
Index within old batch: 20
  Input: [41] 38 ---> [42] 437 
Index within old batch: 21
  Input: [42] 437 ---> [43] 45 
Index within old batch: 22
  Input: [43] 45 ---> [44] 686 
Index within old batch: 23
  Input: [44] 686 ---> [45] 1169 
Index within old batch: 24
  Input: [45] 1169 ---> [46] 4 
Index within old batch: 25
  Input: [46] 4 ---> [47] 38 
Index within old batch: 26
  Input: [47] 38 ---> [48] 437 
[0 - 7fd9a669a000]    9.884898 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]    9.884906 {3}{RequestManager}: Input tree: 39:216 40:6 41:38 42:437 43:45 44:686 45:1169 46:4 47:38
[0 - 7fd9a669a000]    9.884913 {3}{RequestManager}: Output tree: 40:6 41:38 42:437 43:45 44:686 45:1169 46:4 47:38 48:437
[0 - 7fd9a669a000]    9.884920 {3}{RequestManager}: Committed tokens: 18:39 19:40 20:41 21:42 22:43 23:44 24:45 25:46 26:47
[0 - 7fd9a669a000]    9.884929 {3}{RequestManager}: Verified: 40:6 41:38 42:437 43:45 44:686 45:1169 46:4 47:38 48:437
[0 - 7fd9a669a000]    9.884936 {3}{RequestManager}: New committed: 18:39 19:40 20:41 21:42 22:43 23:44 24:45 25:46 26:47
[0 - 7fd9a669a000]    9.884939 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]    9.884995 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.037865 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.037890 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.038437 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.038565 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.038591 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.038604 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039027 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039058 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039080 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039092 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039514 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039544 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039565 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039577 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.039979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040007 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040028 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040039 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040436 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040466 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040489 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040916 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040944 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040967 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.040979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041372 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041401 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041423 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041434 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041826 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041854 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041875 {3}{RequestManager}: SSMs inference time:0.00403097 s.
[0 - 7fd9a669a000]   10.041895 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041907 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041939 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.041981 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.042017 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.042626 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.042656 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.042679 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.042690 {3}{RequestManager}: LLM Tree Verification time:0.000818751 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [49] 50 ---> [50] 45 
Index within old batch: 1
  Input: [50] 45 ---> [51] 4 
Index within old batch: 2
  Input: [51] 4 ---> [52] 38 
Index within old batch: 3
  Input: [52] 38 ---> [53] 437 
Index within old batch: 4
  Input: [53] 437 ---> [54] 45 
Index within old batch: 5
  Input: [54] 45 ---> [55] 686 
Index within old batch: 6
  Input: [55] 686 ---> [56] 114 
Index within old batch: 7
  Input: [56] 114 ---> [57] 47 
Index within old batch: 8
  Input: [57] 47 ---> [58] 214 
[0 - 7fd9a669a000]   10.042892 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.042902 {3}{RequestManager}: Input tree: 49:50 50:45 51:4 52:38 53:437 54:45 55:686 56:114 57:47
[0 - 7fd9a669a000]   10.042911 {3}{RequestManager}: Output tree: 50:45 51:4 52:38 53:437 54:45 55:686 56:114 57:47 58:214
[0 - 7fd9a669a000]   10.042920 {3}{RequestManager}: Committed tokens: 0:49 1:50 2:51 3:52 4:53 5:54 6:55 7:56 8:57
[0 - 7fd9a669a000]   10.042932 {3}{RequestManager}: Verified: 50:45 51:4 52:38 53:437 54:45 55:686 56:114 57:47 58:214
[0 - 7fd9a669a000]   10.042939 {3}{RequestManager}: New committed: 0:49 1:50 2:51 3:52 4:53 5:54 6:55 7:56 8:57
[0 - 7fd9a669a000]   10.042943 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.043013 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're
[ 1000001 ]
Index within old batch: 9
  Input: [74] 110 ---> [75] 3731 
Index within old batch: 10
  Input: [75] 3731 ---> [76] 4 
Index within old batch: 11
  Input: [76] 4 ---> [77] 50118 
Index within old batch: 12
  Input: [77] 50118 ---> [78] 50118 
Index within old batch: 13
  Input: [78] 50118 ---> [79] 100 
Index within old batch: 14
  Input: [79] 100 ---> [80] 437 
Index within old batch: 15
  Input: [80] 437 ---> [81] 45 
Index within old batch: 16
  Input: [81] 45 ---> [82] 686 
Index within old batch: 17
  Input: [82] 686 ---> [83] 114 
[0 - 7fd9a669a000]   10.043140 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.043149 {3}{RequestManager}: Input tree: 74:110 75:3731 76:4 77:50118 78:50118 79:100 80:437 81:45 82:686
[0 - 7fd9a669a000]   10.043158 {3}{RequestManager}: Output tree: 75:3731 76:4 77:50118 78:50118 79:100 80:437 81:45 82:686 83:114
[0 - 7fd9a669a000]   10.043166 {3}{RequestManager}: Committed tokens: 9:74 10:75 11:76 12:77 13:78 14:79 15:80 16:81 17:82
[0 - 7fd9a669a000]   10.043175 {3}{RequestManager}: Verified: 75:3731 76:4 77:50118 78:50118 79:100 80:437 81:45 82:686 83:114
[0 - 7fd9a669a000]   10.043183 {3}{RequestManager}: New committed: 9:74 10:75 11:76 12:77 13:78 14:79 15:80 16:81 17:82
[0 - 7fd9a669a000]   10.043186 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.043281 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if
[ 1000002 ]
Index within old batch: 18
  Input: [48] 437 ---> [49] 45 
Index within old batch: 19
  Input: [49] 45 ---> [50] 686 
Index within old batch: 20
  Input: [50] 686 ---> [51] 114 
Index within old batch: 21
  Input: [51] 114 ---> [52] 47 
Index within old batch: 22
  Input: [52] 24 ---> [53] 18 
Index within old batch: 23
  Input: [53] 18 ---> [54] 10 
Index within old batch: 24
  Input: [54] 10 ---> [55] 205 
Index within old batch: 25
  Input: [55] 205 ---> [56] 1114 
Index within old batch: 26
  Input: [56] 1114 ---> [57] 1169 
[0 - 7fd9a669a000]   10.043399 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.043407 {3}{RequestManager}: Input tree: 48:437 49:45 50:686 51:114 52:24 53:18 54:10 55:205 56:1114
[0 - 7fd9a669a000]   10.043415 {3}{RequestManager}: Output tree: 49:45 50:686 51:114 52:47 53:18 54:10 55:205 56:1114 57:1169
[0 - 7fd9a669a000]   10.043423 {3}{RequestManager}: Committed tokens: 18:48 19:49 20:50 21:51 22:52 23:53 24:54 25:55 26:56
[0 - 7fd9a669a000]   10.043430 {3}{RequestManager}: Verified: 49:45 50:686 51:114 52:47
[0 - 7fd9a669a000]   10.043436 {3}{RequestManager}: New committed: 18:48 19:49 20:50 21:51
[0 - 7fd9a669a000]   10.043440 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7fd9a669a000]   10.043496 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.186169 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.186194 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.186652 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.186689 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.186715 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.186727 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187149 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187177 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187199 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187211 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187612 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187641 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187663 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.187675 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188077 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188106 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188128 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188139 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188537 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188565 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188588 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.188615 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189017 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189044 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189067 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189078 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189474 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189523 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189534 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189929 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189955 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.189977 {3}{RequestManager}: SSMs inference time:0.00383025 s.
[0 - 7fd9a669a000]   10.189996 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190008 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190038 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190076 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190112 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190642 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190673 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190696 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.190707 {3}{RequestManager}: LLM Tree Verification time:0.000734017 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [58] 214 ---> [59] 22024 
Index within old batch: 1
  Input: [59] 22024 ---> [60] 50 
Index within old batch: 2
  Input: [60] 50 ---> [61] 45 
Index within old batch: 3
  Input: [61] 45 ---> [62] 4 
Index within old batch: 4
  Input: [62] 4 ---> [63] 38 
Index within old batch: 5
  Input: [63] 38 ---> [64] 437 
Index within old batch: 6
  Input: [64] 437 ---> [65] 45 
Index within old batch: 7
  Input: [65] 45 ---> [66] 686 
Index within old batch: 8
  Input: [66] 686 ---> [67] 114 
[0 - 7fd9a669a000]   10.190899 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.190910 {3}{RequestManager}: Input tree: 58:214 59:22024 60:50 61:45 62:4 63:38 64:437 65:45 66:686
[0 - 7fd9a669a000]   10.190919 {3}{RequestManager}: Output tree: 59:22024 60:50 61:45 62:4 63:38 64:437 65:45 66:686 67:114
[0 - 7fd9a669a000]   10.190928 {3}{RequestManager}: Committed tokens: 0:58 1:59 2:60 3:61 4:62 5:63 6:64 7:65 8:66
[0 - 7fd9a669a000]   10.190940 {3}{RequestManager}: Verified: 59:22024 60:50 61:45 62:4 63:38 64:437 65:45 66:686 67:114
[0 - 7fd9a669a000]   10.190948 {3}{RequestManager}: New committed: 0:58 1:59 2:60 3:61 4:62 5:63 6:64 7:65 8:66
[0 - 7fd9a669a000]   10.190951 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.191029 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if
[ 1000001 ]
Index within old batch: 9
  Input: [83] 114 ---> [84] 42 
Index within old batch: 10
  Input: [84] 42 ---> [85] 16 
Index within old batch: 11
  Input: [85] 16 ---> [86] 10 
Index within old batch: 12
  Input: [86] 10 ---> [87] 205 
Index within old batch: 13
  Input: [87] 205 ---> [88] 1114 
Index within old batch: 14
  Input: [88] 1114 ---> [89] 6 
Index within old batch: 15
  Input: [89] 6 ---> [90] 53 
Index within old batch: 16
  Input: [90] 53 ---> [91] 38 
Index within old batch: 17
  Input: [91] 38 ---> [92] 437 
[0 - 7fd9a669a000]   10.191152 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.191161 {3}{RequestManager}: Input tree: 83:114 84:42 85:16 86:10 87:205 88:1114 89:6 90:53 91:38
[0 - 7fd9a669a000]   10.191168 {3}{RequestManager}: Output tree: 84:42 85:16 86:10 87:205 88:1114 89:6 90:53 91:38 92:437
[0 - 7fd9a669a000]   10.191176 {3}{RequestManager}: Committed tokens: 9:83 10:84 11:85 12:86 13:87 14:88 15:89 16:90 17:91
[0 - 7fd9a669a000]   10.191185 {3}{RequestManager}: Verified: 84:42 85:16 86:10 87:205 88:1114 89:6 90:53 91:38 92:437
[0 - 7fd9a669a000]   10.191193 {3}{RequestManager}: New committed: 9:83 10:84 11:85 12:86 13:87 14:88 15:89 16:90 17:91
[0 - 7fd9a669a000]   10.191197 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.191288 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm
[ 1000002 ]
Index within old batch: 18
  Input: [52] 47 ---> [53] 214 
Index within old batch: 19
  Input: [53] 214 ---> [54] 10 
Index within old batch: 20
  Input: [54] 10 ---> [55] 3331 
Index within old batch: 21
  Input: [55] 3331 ---> [56] 50 
Index within old batch: 22
  Input: [56] 50 ---> [57] 45 
Index within old batch: 23
  Input: [57] 45 ---> [58] 4 
Index within old batch: 24
  Input: [58] 4 ---> [59] 50118 
Index within old batch: 25
  Input: [59] 50118 ---> [60] 100 
Index within old batch: 26
  Input: [60] 100 ---> [61] 437 
[0 - 7fd9a669a000]   10.191416 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.191424 {3}{RequestManager}: Input tree: 52:47 53:214 54:10 55:3331 56:50 57:45 58:4 59:50118 60:100
[0 - 7fd9a669a000]   10.191432 {3}{RequestManager}: Output tree: 53:214 54:10 55:3331 56:50 57:45 58:4 59:50118 60:100 61:437
[0 - 7fd9a669a000]   10.191439 {3}{RequestManager}: Committed tokens: 18:52 19:53 20:54 21:55 22:56 23:57 24:58 25:59 26:60
[0 - 7fd9a669a000]   10.191448 {3}{RequestManager}: Verified: 53:214 54:10 55:3331 56:50 57:45 58:4 59:50118 60:100 61:437
[0 - 7fd9a669a000]   10.191455 {3}{RequestManager}: New committed: 18:52 19:53 20:54 21:55 22:56 23:57 24:58 25:59 26:60
[0 - 7fd9a669a000]   10.191459 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.191524 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.335717 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.335741 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336202 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336238 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336265 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336276 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336698 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336727 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336749 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.336761 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337164 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337192 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337214 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337625 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337654 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337675 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.337687 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338085 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338114 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338136 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338147 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338566 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338588 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338599 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.338995 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339022 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339044 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339056 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339444 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339471 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339493 {3}{RequestManager}: SSMs inference time:0.00379752 s.
[0 - 7fd9a669a000]   10.339512 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339526 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339557 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339594 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.339628 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.340163 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.340192 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.340216 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.340227 {3}{RequestManager}: LLM Tree Verification time:0.000738098 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [67] 114 ---> [68] 47 
Index within old batch: 1
  Input: [68] 47 ---> [69] 214 
Index within old batch: 2
  Input: [69] 214 ---> [70] 22024 
Index within old batch: 3
  Input: [70] 22024 ---> [71] 50 
Index within old batch: 4
  Input: [71] 50 ---> [72] 45 
Index within old batch: 5
  Input: [72] 45 ---> [73] 4 
Index within old batch: 6
  Input: [73] 4 ---> [74] 38 
Index within old batch: 7
  Input: [74] 38 ---> [75] 437 
Index within old batch: 8
  Input: [75] 437 ---> [76] 45 
[0 - 7fd9a669a000]   10.340416 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.340427 {3}{RequestManager}: Input tree: 67:114 68:47 69:214 70:22024 71:50 72:45 73:4 74:38 75:437
[0 - 7fd9a669a000]   10.340436 {3}{RequestManager}: Output tree: 68:47 69:214 70:22024 71:50 72:45 73:4 74:38 75:437 76:45
[0 - 7fd9a669a000]   10.340444 {3}{RequestManager}: Committed tokens: 0:67 1:68 2:69 3:70 4:71 5:72 6:73 7:74 8:75
[0 - 7fd9a669a000]   10.340455 {3}{RequestManager}: Verified: 68:47 69:214 70:22024 71:50 72:45 73:4 74:38 75:437 76:45
[0 - 7fd9a669a000]   10.340463 {3}{RequestManager}: New committed: 0:67 1:68 2:69 3:70 4:71 5:72 6:73 7:74 8:75
[0 - 7fd9a669a000]   10.340467 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.340563 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not
[ 1000001 ]
Index within old batch: 9
  Input: [92] 437 ---> [93] 45 
Index within old batch: 10
  Input: [93] 45 ---> [94] 686 
Index within old batch: 11
  Input: [94] 686 ---> [95] 114 
Index within old batch: 12
  Input: [95] 114 ---> [96] 24 
Index within old batch: 13
  Input: [96] 24 ---> [97] 18 
Index within old batch: 14
  Input: [97] 18 ---> [98] 10 
Index within old batch: 15
  Input: [98] 10 ---> [99] 205 
Index within old batch: 16
  Input: [99] 205 ---> [100] 1114 
Index within old batch: 17
  Input: [100] 1114 ---> [101] 7 
[0 - 7fd9a669a000]   10.340682 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.340690 {3}{RequestManager}: Input tree: 92:437 93:45 94:686 95:114 96:24 97:18 98:10 99:205 100:1114
[0 - 7fd9a669a000]   10.340698 {3}{RequestManager}: Output tree: 93:45 94:686 95:114 96:24 97:18 98:10 99:205 100:1114 101:7
[0 - 7fd9a669a000]   10.340705 {3}{RequestManager}: Committed tokens: 9:92 10:93 11:94 12:95 13:96 14:97 15:98 16:99 17:100
[0 - 7fd9a669a000]   10.340715 {3}{RequestManager}: Verified: 93:45 94:686 95:114 96:24 97:18 98:10 99:205 100:1114 101:7
[0 - 7fd9a669a000]   10.340722 {3}{RequestManager}: New committed: 9:92 10:93 11:94 12:95 13:96 14:97 15:98 16:99 17:100
[0 - 7fd9a669a000]   10.340726 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.340822 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to
[ 1000002 ]
Index within old batch: 18
  Input: [61] 437 ---> [62] 10 
Index within old batch: 19
  Input: [62] 10 ---> [63] 3331 
Index within old batch: 20
  Input: [63] 3331 ---> [64] 4 
Index within old batch: 21
  Input: [64] 4 ---> [65] 38 
Index within old batch: 22
  Input: [65] 38 ---> [66] 437 
Index within old batch: 23
  Input: [66] 437 ---> [67] 45 
Index within old batch: 24
  Input: [67] 45 ---> [68] 686 
Index within old batch: 25
  Input: [68] 686 ---> [69] 114 
Index within old batch: 26
  Input: [69] 114 ---> [70] 38 
[0 - 7fd9a669a000]   10.340954 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.340961 {3}{RequestManager}: Input tree: 61:437 62:10 63:3331 64:4 65:38 66:437 67:45 68:686 69:114
[0 - 7fd9a669a000]   10.340969 {3}{RequestManager}: Output tree: 62:10 63:3331 64:4 65:38 66:437 67:45 68:686 69:114 70:38
[0 - 7fd9a669a000]   10.340976 {3}{RequestManager}: Committed tokens: 18:61 19:62 20:63 21:64 22:65 23:66 24:67 25:68 26:69
[0 - 7fd9a669a000]   10.340985 {3}{RequestManager}: Verified: 62:10 63:3331 64:4 65:38 66:437 67:45 68:686 69:114 70:38
[0 - 7fd9a669a000]   10.340992 {3}{RequestManager}: New committed: 18:61 19:62 20:63 21:64 22:65 23:66 24:67 25:68 26:69
[0 - 7fd9a669a000]   10.340996 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.341062 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.477404 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.477427 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.477885 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.477926 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.477955 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.477967 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478380 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478414 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478436 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478448 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478854 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478886 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478909 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.478921 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479323 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479353 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479375 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479385 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479785 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479813 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479836 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.479847 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480244 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480273 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480295 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480306 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480723 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480751 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480774 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.480785 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481175 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481205 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481226 {3}{RequestManager}: SSMs inference time:0.00384365 s.
[0 - 7fd9a669a000]   10.481247 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481259 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481290 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481329 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481363 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481896 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481925 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481948 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.481959 {3}{RequestManager}: LLM Tree Verification time:0.000736569 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [76] 45 ---> [77] 686 
Index within old batch: 1
  Input: [77] 686 ---> [78] 114 
Index within old batch: 2
  Input: [78] 114 ---> [79] 47 
Index within old batch: 3
  Input: [79] 47 ---> [80] 214 
Index within old batch: 4
  Input: [80] 214 ---> [81] 22024 
Index within old batch: 5
  Input: [81] 22024 ---> [82] 50 
Index within old batch: 6
  Input: [82] 50 ---> [83] 45 
Index within old batch: 7
  Input: [83] 45 ---> [84] 4 
Index within old batch: 8
  Input: [84] 4 ---> [85] 38 
[0 - 7fd9a669a000]   10.482134 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.482145 {3}{RequestManager}: Input tree: 76:45 77:686 78:114 79:47 80:214 81:22024 82:50 83:45 84:4
[0 - 7fd9a669a000]   10.482154 {3}{RequestManager}: Output tree: 77:686 78:114 79:47 80:214 81:22024 82:50 83:45 84:4 85:38
[0 - 7fd9a669a000]   10.482162 {3}{RequestManager}: Committed tokens: 0:76 1:77 2:78 3:79 4:80 5:81 6:82 7:83 8:84
[0 - 7fd9a669a000]   10.482174 {3}{RequestManager}: Verified: 77:686 78:114 79:47 80:214 81:22024 82:50 83:45 84:4 85:38
[0 - 7fd9a669a000]   10.482182 {3}{RequestManager}: New committed: 0:76 1:77 2:78 3:79 4:80 5:81 6:82 7:83 8:84
[0 - 7fd9a669a000]   10.482186 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.482275 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I
[ 1000001 ]
Index within old batch: 9
  Input: [101] 7 ---> [102] 33 
Index within old batch: 10
  Input: [102] 33 ---> [103] 10 
Index within old batch: 11
  Input: [103] 10 ---> [104] 7359 
Index within old batch: 12
  Input: [104] 7359 ---> [105] 12749 
Index within old batch: 13
  Input: [105] 12749 ---> [106] 14 
Index within old batch: 14
  Input: [106] 14 ---> [107] 64 
Index within old batch: 15
  Input: [107] 64 ---> [108] 1166 
Index within old batch: 16
  Input: [108] 1166 ---> [109] 110 
Index within old batch: 17
  Input: [109] 110 ---> [110] 3731 
[0 - 7fd9a669a000]   10.482414 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.482423 {3}{RequestManager}: Input tree: 101:7 102:33 103:10 104:7359 105:12749 106:14 107:64 108:1166 109:110
[0 - 7fd9a669a000]   10.482431 {3}{RequestManager}: Output tree: 102:33 103:10 104:7359 105:12749 106:14 107:64 108:1166 109:110 110:3731
[0 - 7fd9a669a000]   10.482438 {3}{RequestManager}: Committed tokens: 9:101 10:102 11:103 12:104 13:105 14:106 15:107 16:108 17:109
[0 - 7fd9a669a000]   10.482449 {3}{RequestManager}: Verified: 102:33 103:10 104:7359 105:12749 106:14 107:64 108:1166 109:110 110:3731
[0 - 7fd9a669a000]   10.482456 {3}{RequestManager}: New committed: 9:101 10:102 11:103 12:104 13:105 14:106 15:107 16:108 17:109
[0 - 7fd9a669a000]   10.482460 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.482567 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages
[ 1000002 ]
Index within old batch: 18
  Input: [70] 38 ---> [71] 236 
Index within old batch: 19
  Input: [71] 236 ---> [72] 7 
Index within old batch: 20
  Input: [72] 7 ---> [73] 109 
Index within old batch: 21
  Input: [73] 109 ---> [74] 14 
Index within old batch: 22
  Input: [74] 14 ---> [75] 4 
Index within old batch: 23
  Input: [75] 4 ---> [76] 50118 
Index within old batch: 24
  Input: [76] 50118 ---> [77] 100 
Index within old batch: 25
  Input: [77] 100 ---> [78] 437 
Index within old batch: 26
  Input: [78] 437 ---> [79] 45 
[0 - 7fd9a669a000]   10.482689 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.482697 {3}{RequestManager}: Input tree: 70:38 71:236 72:7 73:109 74:14 75:4 76:50118 77:100 78:437
[0 - 7fd9a669a000]   10.482705 {3}{RequestManager}: Output tree: 71:236 72:7 73:109 74:14 75:4 76:50118 77:100 78:437 79:45
[0 - 7fd9a669a000]   10.482712 {3}{RequestManager}: Committed tokens: 18:70 19:71 20:72 21:73 22:74 23:75 24:76 25:77 26:78
[0 - 7fd9a669a000]   10.482722 {3}{RequestManager}: Verified: 71:236 72:7 73:109 74:14 75:4 76:50118 77:100 78:437 79:45
[0 - 7fd9a669a000]   10.482729 {3}{RequestManager}: New committed: 18:70 19:71 20:72 21:73 22:74 23:75 24:76 25:77 26:78
[0 - 7fd9a669a000]   10.482733 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.482802 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.615822 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.615844 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616298 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616337 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616361 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616373 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616775 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616805 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616828 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.616840 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617218 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617246 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617267 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617279 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617652 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617680 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617701 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.617713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618089 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618115 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618138 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618149 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618519 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618547 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618569 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618580 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618949 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618976 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.618998 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619009 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619374 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619401 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619421 {3}{RequestManager}: SSMs inference time:0.00362035 s.
[0 - 7fd9a669a000]   10.619442 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619453 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619484 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619523 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.619558 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.620084 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.620112 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.620135 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.620146 {3}{RequestManager}: LLM Tree Verification time:0.000728145 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [85] 38 ---> [86] 437 
Index within old batch: 1
  Input: [86] 437 ---> [87] 45 
Index within old batch: 2
  Input: [87] 45 ---> [88] 686 
Index within old batch: 3
  Input: [88] 686 ---> [89] 114 
Index within old batch: 4
  Input: [89] 114 ---> [90] 47 
Index within old batch: 5
  Input: [90] 47 ---> [91] 214 
Index within old batch: 6
  Input: [91] 214 ---> [92] 22024 
Index within old batch: 7
  Input: [92] 22024 ---> [93] 50 
Index within old batch: 8
  Input: [93] 50 ---> [94] 45 
[0 - 7fd9a669a000]   10.620339 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.620350 {3}{RequestManager}: Input tree: 85:38 86:437 87:45 88:686 89:114 90:47 91:214 92:22024 93:50
[0 - 7fd9a669a000]   10.620358 {3}{RequestManager}: Output tree: 86:437 87:45 88:686 89:114 90:47 91:214 92:22024 93:50 94:45
[0 - 7fd9a669a000]   10.620367 {3}{RequestManager}: Committed tokens: 0:85 1:86 2:87 3:88 4:89 5:90 6:91 7:92 8:93
[0 - 7fd9a669a000]   10.620378 {3}{RequestManager}: Verified: 86:437 87:45 88:686 89:114 90:47 91:214 92:22024 93:50 94:45
[0 - 7fd9a669a000]   10.620386 {3}{RequestManager}: New committed: 0:85 1:86 2:87 3:88 4:89 5:90 6:91 7:92 8:93
[0 - 7fd9a669a000]   10.620390 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.620495 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not
[ 1000001 ]
Index within old batch: 9
  Input: [110] 3731 ---> [111] 4 
Index within old batch: 10
  Input: [111] 4 ---> [112] 50118 
Index within old batch: 11
  Input: [112] 50118 ---> [113] 50118 
Index within old batch: 12
  Input: [113] 50118 ---> [114] 100 
Index within old batch: 13
  Input: [114] 100 ---> [115] 437 
Index within old batch: 14
  Input: [115] 437 ---> [116] 45 
Index within old batch: 15
  Input: [116] 45 ---> [117] 686 
Index within old batch: 16
  Input: [117] 686 ---> [118] 114 
Index within old batch: 17
  Input: [118] 114 ---> [119] 42 
[0 - 7fd9a669a000]   10.620628 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.620637 {3}{RequestManager}: Input tree: 110:3731 111:4 112:50118 113:50118 114:100 115:437 116:45 117:686 118:114
[0 - 7fd9a669a000]   10.620645 {3}{RequestManager}: Output tree: 111:4 112:50118 113:50118 114:100 115:437 116:45 117:686 118:114 119:42
[0 - 7fd9a669a000]   10.620652 {3}{RequestManager}: Committed tokens: 9:110 10:111 11:112 12:113 13:114 14:115 15:116 16:117 17:118
[0 - 7fd9a669a000]   10.620661 {3}{RequestManager}: Verified: 111:4 112:50118 113:50118 114:100 115:437 116:45 117:686 118:114 119:42
[0 - 7fd9a669a000]   10.620669 {3}{RequestManager}: New committed: 9:110 10:111 11:112 12:113 13:114 14:115 15:116 16:117 17:118
[0 - 7fd9a669a000]   10.620672 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.620779 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this
[ 1000002 ]
Index within old batch: 18
  Input: [79] 45 ---> [80] 686 
Index within old batch: 19
  Input: [80] 686 ---> [81] 1169 
Index within old batch: 20
  Input: [81] 1169 ---> [82] 4 
Index within old batch: 21
  Input: [82] 4 ---> [83] 38 
Index within old batch: 22
  Input: [83] 38 ---> [84] 437 
Index within old batch: 23
  Input: [84] 437 ---> [85] 45 
Index within old batch: 24
  Input: [85] 45 ---> [86] 686 
Index within old batch: 25
  Input: [86] 686 ---> [87] 1169 
Index within old batch: 26
  Input: [87] 1169 ---> [88] 4 
[0 - 7fd9a669a000]   10.620901 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.620909 {3}{RequestManager}: Input tree: 79:45 80:686 81:1169 82:4 83:38 84:437 85:45 86:686 87:1169
[0 - 7fd9a669a000]   10.620917 {3}{RequestManager}: Output tree: 80:686 81:1169 82:4 83:38 84:437 85:45 86:686 87:1169 88:4
[0 - 7fd9a669a000]   10.620924 {3}{RequestManager}: Committed tokens: 18:79 19:80 20:81 21:82 22:83 23:84 24:85 25:86 26:87
[0 - 7fd9a669a000]   10.620933 {3}{RequestManager}: Verified: 80:686 81:1169 82:4 83:38 84:437 85:45 86:686 87:1169 88:4
[0 - 7fd9a669a000]   10.620941 {3}{RequestManager}: New committed: 18:79 19:80 20:81 21:82 22:83 23:84 24:85 25:86 26:87
[0 - 7fd9a669a000]   10.620944 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.621021 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.763081 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.763102 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.763554 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.763591 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.763616 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.763629 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764012 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764041 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764065 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764077 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764472 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764524 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764535 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764908 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764937 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764959 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.764970 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765387 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765446 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765457 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765828 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765858 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765880 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.765891 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766259 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766286 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766308 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766319 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766683 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766710 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766731 {3}{RequestManager}: SSMs inference time:0.00367034 s.
[0 - 7fd9a669a000]   10.766751 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766764 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766794 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766833 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.766867 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.767393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.767421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.767443 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.767454 {3}{RequestManager}: LLM Tree Verification time:0.000726897 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [94] 45 ---> [95] 4 
Index within old batch: 1
  Input: [95] 4 ---> [96] 38 
Index within old batch: 2
  Input: [96] 38 ---> [97] 437 
Index within old batch: 3
  Input: [97] 437 ---> [98] 45 
Index within old batch: 4
  Input: [98] 45 ---> [99] 686 
Index within old batch: 5
  Input: [99] 686 ---> [100] 114 
Index within old batch: 6
  Input: [100] 114 ---> [101] 47 
Index within old batch: 7
  Input: [101] 47 ---> [102] 214 
Index within old batch: 8
  Input: [102] 214 ---> [103] 22024 
[0 - 7fd9a669a000]   10.767645 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.767656 {3}{RequestManager}: Input tree: 94:45 95:4 96:38 97:437 98:45 99:686 100:114 101:47 102:214
[0 - 7fd9a669a000]   10.767665 {3}{RequestManager}: Output tree: 95:4 96:38 97:437 98:45 99:686 100:114 101:47 102:214 103:22024
[0 - 7fd9a669a000]   10.767673 {3}{RequestManager}: Committed tokens: 0:94 1:95 2:96 3:97 4:98 5:99 6:100 7:101 8:102
[0 - 7fd9a669a000]   10.767685 {3}{RequestManager}: Verified: 95:4 96:38 97:437 98:45 99:686 100:114 101:47 102:214 103:22024
[0 - 7fd9a669a000]   10.767692 {3}{RequestManager}: New committed: 0:94 1:95 2:96 3:97 4:98 5:99 6:100 7:101 8:102
[0 - 7fd9a669a000]   10.767696 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.767794 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking
[ 1000001 ]
Index within old batch: 9
  Input: [119] 42 ---> [120] 16 
Index within old batch: 10
  Input: [120] 16 ---> [121] 10 
Index within old batch: 11
  Input: [121] 10 ---> [122] 205 
Index within old batch: 12
  Input: [122] 205 ---> [123] 1114 
Index within old batch: 13
  Input: [123] 1114 ---> [124] 6 
Index within old batch: 14
  Input: [124] 6 ---> [125] 53 
Index within old batch: 15
  Input: [125] 53 ---> [126] 38 
Index within old batch: 16
  Input: [126] 38 ---> [127] 437 
Index within old batch: 17
  Input: [127] 437 ---> [128] 45 
[0 - 7fd9a669a000]   10.767917 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.767925 {3}{RequestManager}: Input tree: 119:42 120:16 121:10 122:205 123:1114 124:6 125:53 126:38 127:437
[0 - 7fd9a669a000]   10.767933 {3}{RequestManager}: Output tree: 120:16 121:10 122:205 123:1114 124:6 125:53 126:38 127:437 128:45
[0 - 7fd9a669a000]   10.767940 {3}{RequestManager}: Committed tokens: 9:119 10:120 11:121 12:122 13:123 14:124 15:125 16:126 17:127
[0 - 7fd9a669a000]   10.767951 {3}{RequestManager}: Verified: 120:16 121:10 122:205 123:1114 124:6 125:53 126:38 127:437 128:45
[0 - 7fd9a669a000]   10.767958 {3}{RequestManager}: New committed: 9:119 10:120 11:121 12:122 13:123 14:124 15:125 16:126 17:127
[0 - 7fd9a669a000]   10.767962 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.767966 {3}{RequestManager}: [Done] guid(1000001) with final length(128)
[0 - 7fd9a669a000]   10.768082 {3}{RequestManager}: Final output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm not sure if it's a good idea to have a chatbot that can read your messages.

I'm not sure if this is a good idea, but I'm
[0 - 7fd9a669a000]   10.768096 {3}{RequestManager}: [Profile] guid(1000001) decoding_steps(11) start(8674205.0) finish(10768085.0) latency(2093880.0)
[ 1000002 ]
Index within old batch: 18
  Input: [88] 4 ---> [89] 50118 
Index within old batch: 19
  Input: [89] 50118 ---> [90] 100 
Index within old batch: 20
  Input: [90] 100 ---> [91] 437 
Index within old batch: 21
  Input: [91] 437 ---> [92] 45 
Index within old batch: 22
  Input: [92] 45 ---> [93] 686 
Index within old batch: 23
  Input: [93] 686 ---> [94] 1169 
Index within old batch: 24
  Input: [94] 1169 ---> [95] 4 
Index within old batch: 25
  Input: [95] 4 ---> [96] 50118 
Index within old batch: 26
  Input: [96] 50118 ---> [97] 100 
[0 - 7fd9a669a000]   10.768225 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.768233 {3}{RequestManager}: Input tree: 88:4 89:50118 90:100 91:437 92:45 93:686 94:1169 95:4 96:50118
[0 - 7fd9a669a000]   10.768241 {3}{RequestManager}: Output tree: 89:50118 90:100 91:437 92:45 93:686 94:1169 95:4 96:50118 97:100
[0 - 7fd9a669a000]   10.768249 {3}{RequestManager}: Committed tokens: 18:88 19:89 20:90 21:91 22:92 23:93 24:94 25:95 26:96
[0 - 7fd9a669a000]   10.768259 {3}{RequestManager}: Verified: 89:50118 90:100 91:437 92:45 93:686 94:1169 95:4 96:50118 97:100
[0 - 7fd9a669a000]   10.768266 {3}{RequestManager}: New committed: 18:88 19:89 20:90 21:91 22:92 23:93 24:94 25:95 26:96
[0 - 7fd9a669a000]   10.768270 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.768354 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.
I'm not sure either.
I

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   10.915130 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.915163 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.915647 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.915690 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.915722 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.915735 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916130 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916189 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916213 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916630 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916661 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916684 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.916697 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917078 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917107 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917129 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917141 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917518 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917546 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917568 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917580 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917951 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.917980 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918001 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918013 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918384 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918412 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918434 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918445 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918813 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918839 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918863 {3}{RequestManager}: SSMs inference time:0.00376701 s.
[0 - 7fd9a669a000]   10.918886 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918898 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918930 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.918972 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.919009 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.919549 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.919581 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.919605 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   10.919618 {3}{RequestManager}: LLM Tree Verification time:0.000759621 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [103] 22024 ---> [104] 50 
Index within old batch: 1
  Input: [104] 50 ---> [105] 45 
Index within old batch: 2
  Input: [105] 45 ---> [106] 4 
Index within old batch: 3
  Input: [106] 4 ---> [107] 38 
Index within old batch: 4
  Input: [107] 38 ---> [108] 437 
Index within old batch: 5
  Input: [108] 437 ---> [109] 45 
Index within old batch: 6
  Input: [109] 45 ---> [110] 686 
Index within old batch: 7
  Input: [110] 686 ---> [111] 114 
Index within old batch: 8
  Input: [111] 114 ---> [112] 47 
[0 - 7fd9a669a000]   10.919828 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.919842 {3}{RequestManager}: Input tree: 103:22024 104:50 105:45 106:4 107:38 108:437 109:45 110:686 111:114
[0 - 7fd9a669a000]   10.919851 {3}{RequestManager}: Output tree: 104:50 105:45 106:4 107:38 108:437 109:45 110:686 111:114 112:47
[0 - 7fd9a669a000]   10.919860 {3}{RequestManager}: Committed tokens: 0:103 1:104 2:105 3:106 4:107 5:108 6:109 7:110 8:111
[0 - 7fd9a669a000]   10.919874 {3}{RequestManager}: Verified: 104:50 105:45 106:4 107:38 108:437 109:45 110:686 111:114 112:47
[0 - 7fd9a669a000]   10.919882 {3}{RequestManager}: New committed: 0:103 1:104 2:105 3:106 4:107 5:108 6:109 7:110 8:111
[0 - 7fd9a669a000]   10.919886 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.920007 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you
[ 1000002 ]
Index within old batch: 9
  Input: [97] 100 ---> [98] 437 
Index within old batch: 10
  Input: [98] 437 ---> [99] 45 
Index within old batch: 11
  Input: [99] 45 ---> [100] 686 
Index within old batch: 12
  Input: [100] 686 ---> [101] 1169 
Index within old batch: 13
  Input: [101] 1169 ---> [102] 4 
Index within old batch: 14
  Input: [102] 4 ---> [103] 50118 
Index within old batch: 15
  Input: [103] 50118 ---> [104] 100 
Index within old batch: 16
  Input: [104] 100 ---> [105] 437 
Index within old batch: 17
  Input: [105] 437 ---> [106] 45 
[0 - 7fd9a669a000]   10.920142 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   10.920151 {3}{RequestManager}: Input tree: 97:100 98:437 99:45 100:686 101:1169 102:4 103:50118 104:100 105:437
[0 - 7fd9a669a000]   10.920159 {3}{RequestManager}: Output tree: 98:437 99:45 100:686 101:1169 102:4 103:50118 104:100 105:437 106:45
[0 - 7fd9a669a000]   10.920167 {3}{RequestManager}: Committed tokens: 9:97 10:98 11:99 12:100 13:101 14:102 15:103 16:104 17:105
[0 - 7fd9a669a000]   10.920178 {3}{RequestManager}: Verified: 98:437 99:45 100:686 101:1169 102:4 103:50118 104:100 105:437 106:45
[0 - 7fd9a669a000]   10.920185 {3}{RequestManager}: New committed: 9:97 10:98 11:99 12:100 13:101 14:102 15:103 16:104 17:105
[0 - 7fd9a669a000]   10.920189 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   10.920281 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   11.069371 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.069393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.069856 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.069897 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.069925 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.069937 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070322 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070355 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070378 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070390 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070770 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070802 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070823 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.070835 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071207 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071238 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071261 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071273 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071643 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071672 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071694 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.071705 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072077 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072107 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072128 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072141 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072527 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072556 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072590 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072959 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.072987 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073008 {3}{RequestManager}: SSMs inference time:0.00366066 s.
[0 - 7fd9a669a000]   11.073028 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073041 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073072 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073113 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073149 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073681 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073710 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073736 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.073748 {3}{RequestManager}: LLM Tree Verification time:0.000743653 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [112] 47 ---> [113] 214 
Index within old batch: 1
  Input: [113] 214 ---> [114] 22024 
Index within old batch: 2
  Input: [114] 22024 ---> [115] 50 
Index within old batch: 3
  Input: [115] 50 ---> [116] 45 
Index within old batch: 4
  Input: [116] 45 ---> [117] 4 
Index within old batch: 5
  Input: [117] 4 ---> [118] 38 
Index within old batch: 6
  Input: [118] 38 ---> [119] 437 
Index within old batch: 7
  Input: [119] 437 ---> [120] 45 
Index within old batch: 8
  Input: [120] 45 ---> [121] 686 
[0 - 7fd9a669a000]   11.073937 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   11.073948 {3}{RequestManager}: Input tree: 112:47 113:214 114:22024 115:50 116:45 117:4 118:38 119:437 120:45
[0 - 7fd9a669a000]   11.073957 {3}{RequestManager}: Output tree: 113:214 114:22024 115:50 116:45 117:4 118:38 119:437 120:45 121:686
[0 - 7fd9a669a000]   11.073965 {3}{RequestManager}: Committed tokens: 0:112 1:113 2:114 3:115 4:116 5:117 6:118 7:119 8:120
[0 - 7fd9a669a000]   11.073977 {3}{RequestManager}: Verified: 113:214 114:22024 115:50 116:45 117:4 118:38 119:437 120:45 121:686
[0 - 7fd9a669a000]   11.073985 {3}{RequestManager}: New committed: 0:112 1:113 2:114 3:115 4:116 5:117 6:118 7:119 8:120
[0 - 7fd9a669a000]   11.073988 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   11.074106 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure
[ 1000002 ]
Index within old batch: 9
  Input: [106] 45 ---> [107] 686 
Index within old batch: 10
  Input: [107] 686 ---> [108] 1169 
Index within old batch: 11
  Input: [108] 1169 ---> [109] 4 
Index within old batch: 12
  Input: [109] 4 ---> [110] 50118 
Index within old batch: 13
  Input: [110] 50118 ---> [111] 100 
Index within old batch: 14
  Input: [111] 100 ---> [112] 437 
Index within old batch: 15
  Input: [112] 437 ---> [113] 45 
Index within old batch: 16
  Input: [113] 45 ---> [114] 686 
Index within old batch: 17
  Input: [114] 686 ---> [115] 1169 
[0 - 7fd9a669a000]   11.074229 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   11.074237 {3}{RequestManager}: Input tree: 106:45 107:686 108:1169 109:4 110:50118 111:100 112:437 113:45 114:686
[0 - 7fd9a669a000]   11.074245 {3}{RequestManager}: Output tree: 107:686 108:1169 109:4 110:50118 111:100 112:437 113:45 114:686 115:1169
[0 - 7fd9a669a000]   11.074252 {3}{RequestManager}: Committed tokens: 9:106 10:107 11:108 12:109 13:110 14:111 15:112 16:113 17:114
[0 - 7fd9a669a000]   11.074262 {3}{RequestManager}: Verified: 107:686 108:1169 109:4 110:50118 111:100 112:437 113:45 114:686 115:1169
[0 - 7fd9a669a000]   11.074270 {3}{RequestManager}: New committed: 9:106 10:107 11:108 12:109 13:110 14:111 15:112 16:113 17:114
[0 - 7fd9a669a000]   11.074273 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   11.074373 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   11.218178 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.218205 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.218688 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.218731 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.218761 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.218774 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219175 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219207 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219231 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219243 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219631 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219662 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219683 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.219695 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220074 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220103 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220125 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220136 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220530 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220559 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220580 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220591 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220968 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.220996 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221019 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221030 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221409 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221438 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221460 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221471 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221833 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221862 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221885 {3}{RequestManager}: SSMs inference time:0.0037349 s.
[0 - 7fd9a669a000]   11.221938 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221957 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.221989 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222031 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222065 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222610 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222657 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222688 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.222701 {3}{RequestManager}: LLM Tree Verification time:0.000820218 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [121] 686 ---> [122] 114 
Index within old batch: 1
  Input: [122] 114 ---> [123] 47 
Index within old batch: 2
  Input: [123] 47 ---> [124] 214 
Index within old batch: 3
  Input: [124] 214 ---> [125] 22024 
Index within old batch: 4
  Input: [125] 22024 ---> [126] 50 
Index within old batch: 5
  Input: [126] 50 ---> [127] 45 
Index within old batch: 6
  Input: [127] 45 ---> [128] 4 
[0 - 7fd9a669a000]   11.222888 {3}{RequestManager}: Input tree size (7) Output tree size (7)
[0 - 7fd9a669a000]   11.222900 {3}{RequestManager}: Input tree: 121:686 122:114 123:47 124:214 125:22024 126:50 127:45
[0 - 7fd9a669a000]   11.222908 {3}{RequestManager}: Output tree: 122:114 123:47 124:214 125:22024 126:50 127:45 128:4
[0 - 7fd9a669a000]   11.222916 {3}{RequestManager}: Committed tokens: 0:121 1:122 2:123 3:124 4:125 5:126 6:127
[0 - 7fd9a669a000]   11.222927 {3}{RequestManager}: Verified: 122:114 123:47 124:214 125:22024 126:50 127:45 128:4
[0 - 7fd9a669a000]   11.222935 {3}{RequestManager}: New committed: 0:121 1:122 2:123 3:124 4:125 5:126 6:127
[0 - 7fd9a669a000]   11.222939 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7fd9a669a000]   11.222943 {3}{RequestManager}: [Done] guid(1000000) with final length(128)
[0 - 7fd9a669a000]   11.223073 {3}{RequestManager}: Final output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're joking or not, but I'm pretty sure he's a basketball player.
I'm not joking. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not. I'm not sure if you're joking or not
[0 - 7fd9a669a000]   11.223086 {3}{RequestManager}: [Profile] guid(1000000) decoding_steps(14) start(8674169.0) finish(11223076.0) latency(2548907.0)
[ 1000002 ]
Index within old batch: 7
  Input: [115] 1169 ---> [116] 4 
Index within old batch: 8
  Input: [116] 4 ---> [117] 50118 
Index within old batch: 9
  Input: [117] 50118 ---> [118] 100 
Index within old batch: 10
  Input: [118] 100 ---> [119] 437 
Index within old batch: 11
  Input: [119] 437 ---> [120] 45 
Index within old batch: 12
  Input: [120] 45 ---> [121] 686 
Index within old batch: 13
  Input: [121] 686 ---> [122] 1169 
Index within old batch: 14
  Input: [122] 1169 ---> [123] 4 
Index within old batch: 15
  Input: [123] 4 ---> [124] 50118 
[0 - 7fd9a669a000]   11.223210 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7fd9a669a000]   11.223219 {3}{RequestManager}: Input tree: 115:1169 116:4 117:50118 118:100 119:437 120:45 121:686 122:1169 123:4
[0 - 7fd9a669a000]   11.223228 {3}{RequestManager}: Output tree: 116:4 117:50118 118:100 119:437 120:45 121:686 122:1169 123:4 124:50118
[0 - 7fd9a669a000]   11.223236 {3}{RequestManager}: Committed tokens: 7:115 8:116 9:117 10:118 11:119 12:120 13:121 14:122 15:123
[0 - 7fd9a669a000]   11.223247 {3}{RequestManager}: Verified: 116:4 117:50118 118:100 119:437 120:45 121:686 122:1169 123:4 124:50118
[0 - 7fd9a669a000]   11.223254 {3}{RequestManager}: New committed: 7:115 8:116 9:117 10:118 11:119 12:120 13:121 14:122 15:123
[0 - 7fd9a669a000]   11.223258 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7fd9a669a000]   11.223369 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.


############### prepare_next_batch_verify ###############
[Verify] Request 1000002 is running
[0 - 7fd9a669a000]   11.357213 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.357238 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.357704 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.357743 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.357768 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.357779 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358161 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358192 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358215 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358602 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358630 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358651 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.358664 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359039 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359067 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359088 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359100 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359475 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359503 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359525 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359536 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359905 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359933 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359955 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.359967 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360352 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360396 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360420 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360432 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360841 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360884 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360907 {3}{RequestManager}: SSMs inference time:0.00371438 s.
[0 - 7fd9a669a000]   11.360929 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360941 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.360974 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361013 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361047 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361616 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361649 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361671 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.361684 {3}{RequestManager}: LLM Tree Verification time:0.000779855 s.

############### prepare_next_batch_init ###############
[ 1000002 ]
Index within old batch: 0
  Input: [124] 50118 ---> [125] 100 
Index within old batch: 1
  Input: [125] 100 ---> [126] 437 
Index within old batch: 2
  Input: [126] 437 ---> [127] 45 
Index within old batch: 3
  Input: [127] 45 ---> [128] 686 
[0 - 7fd9a669a000]   11.361847 {3}{RequestManager}: Input tree size (4) Output tree size (4)
[0 - 7fd9a669a000]   11.361858 {3}{RequestManager}: Input tree: 124:50118 125:100 126:437 127:45
[0 - 7fd9a669a000]   11.361865 {3}{RequestManager}: Output tree: 125:100 126:437 127:45 128:686
[0 - 7fd9a669a000]   11.361871 {3}{RequestManager}: Committed tokens: 0:124 1:125 2:126 3:127
[0 - 7fd9a669a000]   11.361881 {3}{RequestManager}: Verified: 125:100 126:437 127:45 128:686
[0 - 7fd9a669a000]   11.361887 {3}{RequestManager}: New committed: 0:124 1:125 2:126 3:127
[0 - 7fd9a669a000]   11.361891 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7fd9a669a000]   11.361895 {3}{RequestManager}: [Done] guid(1000002) with final length(128)
[0 - 7fd9a669a000]   11.362011 {3}{RequestManager}: Final output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if that's a good idea. I'm not sure if I want to do that.
I don't know, I'm not sure either. I'm not sure if you're a writer or not.
I'm a writer. I'm not sure if I want to do that.
I'm not sure either. I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not sure either.
I'm not
[0 - 7fd9a669a000]   11.362023 {3}{RequestManager}: [Profile] guid(1000002) decoding_steps(15) start(8674220.0) finish(11362014.0) latency(2687794.0)

############### prepare_next_batch_verify ###############
[0 - 7fd9a669a000]   11.420782 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.420802 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421239 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421277 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421302 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421314 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421694 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421724 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421746 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.421757 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422131 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422160 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422195 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422566 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422595 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422616 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422627 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.422996 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423025 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423046 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423058 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423428 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423455 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423477 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423489 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423853 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423880 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423902 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.423913 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424293 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424322 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424343 {3}{RequestManager}: SSMs inference time:0.00357795 s.
[0 - 7fd9a669a000]   11.424363 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424376 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424406 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424443 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.424479 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.425009 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.425038 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.425064 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7fd9a669a000]   11.425076 {3}{RequestManager}: LLM Tree Verification time:0.000735777 s.
[0 - 7fd9a669a000]   11.425103 {3}{spec_infer}: finish SPS stree_model.generate

############### prepare_next_batch_init ###############

############### prepare_next_batch_verify ###############

############### prepare_next_batch_init ###############

############### prepare_next_batch_verify ###############

############### prepare_next_batch_init ###############

############### prepare_next_batch_verify ###############

############### prepare_next_batch_init ###############

############### prepare_next_batch_verify ###############
----------inference finished--------------
----------OK--------------
