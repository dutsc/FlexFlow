[0 - 7f442c744000]    0.214587 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7f442c744000]    0.214643 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7f442c744000]    0.214657 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7f442c744000]    0.214666 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7f442c744000]    0.214677 {3}{Mapper}: Enabled Control Replication Optimizations.
[0 - 7f442c744000]    0.235368 {3}{spec_infer}: Start execute function: top_level_task!
[0 - 7f442c744000]    0.235489 {3}{spec_infer}: paths.cache_folder_path is:/root/.cache/flexflow
[0 - 7f442c744000]    0.235520 {3}{spec_infer}: model_metadata.llm_model_config_path is:/models/opt-13b/config.json
[0 - 7f442c744000]    0.235526 {3}{spec_infer}: model_metadata.llm_tokenizer_path is:/models/opt-13b/
[0 - 7f442c744000]    0.235531 {3}{spec_infer}: model_metadata.llm_weights_path is:/models/opt-13b/half-precision
[0 - 7f442c744000]    0.236060 {3}{spec_infer}: model_metadata.llm_model_type is:3001
[0 - 7f442c744000]    0.236065 {3}{spec_infer}: model_metadata.llm_model_type is:3003
workSpaceSize (128 MB)
workSpaceSize (128 MB)
workSpaceSize (128 MB)
workSpaceSize (128 MB)
[0 - 7f442c744000]    0.525277 {3}{opt}: These are OPT model config:
OPT Config:
	do_layer_norm_before: 1
	dropout: 0.1
	enable_bias: 1
	ffn_dim: 20480
	hidden_size: 5120
	layer_norm_elementwise_affine: 1
	max_position_embeddings: 2048
	num_attention_heads: 40
	num_hidden_layers: 40
	vocab_size: 50272
	word_embed_proj_dim: 5120
	max_beam_width: 1
	max_beam_depth: 8
------start compile ----------
num_nodes = 1 num_gpus_per_node = 4
optimal_views.size = 330
views.size() = 330
Deserialized Views...
node[5000513]: type(TreeIncMultiHeadSelfAttention_5000513) view(1 4 0)  inEdge(node(5000512) idx(1))
node[5000512]: type(ResidualLayerNorm_5000512) view(1 4 0)  inEdge(node(5000511) idx(0)) inEdge(node(5000507) idx(0))
node[5000511]: type(AllReduce_5000511) view(1 4 0)  inEdge(node(5000510) idx(0))
node[5000510]: type(Dense_5000510) view(1 4 0)  inEdge(node(5000509) idx(0))
node[5000509]: type(ReLU_5000509) view(1 4 0)  inEdge(node(5000508) idx(0))
node[5000508]: type(Dense_5000508) view(1 4 0)  inEdge(node(5000507) idx(1))
node[5000507]: type(AddBiasResidualLayerNorm_5000507) view(1 4 0)  inEdge(node(5000504) idx(0)) inEdge(node(5000506) idx(0))
node[5000506]: type(AllReduce_5000506) view(1 4 0)  inEdge(node(5000505) idx(0))
node[5000505]: type(TreeIncMultiHeadSelfAttention_5000505) view(1 4 0)  inEdge(node(5000504) idx(1))
node[5000504]: type(ResidualLayerNorm_5000504) view(1 4 0)  inEdge(node(5000503) idx(0)) inEdge(node(5000499) idx(0))
node[5000503]: type(AllReduce_5000503) view(1 4 0)  inEdge(node(5000502) idx(0))
node[5000502]: type(Dense_5000502) view(1 4 0)  inEdge(node(5000501) idx(0))
node[5000501]: type(ReLU_5000501) view(1 4 0)  inEdge(node(5000500) idx(0))
node[5000500]: type(Dense_5000500) view(1 4 0)  inEdge(node(5000499) idx(1))
node[5000499]: type(AddBiasResidualLayerNorm_5000499) view(1 4 0)  inEdge(node(5000496) idx(0)) inEdge(node(5000498) idx(0))
node[5000498]: type(AllReduce_5000498) view(1 4 0)  inEdge(node(5000497) idx(0))
node[5000497]: type(TreeIncMultiHeadSelfAttention_5000497) view(1 4 0)  inEdge(node(5000496) idx(1))
node[5000496]: type(ResidualLayerNorm_5000496) view(1 4 0)  inEdge(node(5000495) idx(0)) inEdge(node(5000491) idx(0))
node[5000495]: type(AllReduce_5000495) view(1 4 0)  inEdge(node(5000494) idx(0))
node[5000494]: type(Dense_5000494) view(1 4 0)  inEdge(node(5000493) idx(0))
node[5000493]: type(ReLU_5000493) view(1 4 0)  inEdge(node(5000492) idx(0))
node[5000492]: type(Dense_5000492) view(1 4 0)  inEdge(node(5000491) idx(1))
node[5000491]: type(AddBiasResidualLayerNorm_5000491) view(1 4 0)  inEdge(node(5000488) idx(0)) inEdge(node(5000490) idx(0))
node[5000490]: type(AllReduce_5000490) view(1 4 0)  inEdge(node(5000489) idx(0))
node[5000489]: type(TreeIncMultiHeadSelfAttention_5000489) view(1 4 0)  inEdge(node(5000488) idx(1))
node[5000488]: type(ResidualLayerNorm_5000488) view(1 4 0)  inEdge(node(5000487) idx(0)) inEdge(node(5000483) idx(0))
node[5000487]: type(AllReduce_5000487) view(1 4 0)  inEdge(node(5000486) idx(0))
node[5000486]: type(Dense_5000486) view(1 4 0)  inEdge(node(5000485) idx(0))
node[5000485]: type(ReLU_5000485) view(1 4 0)  inEdge(node(5000484) idx(0))
node[5000484]: type(Dense_5000484) view(1 4 0)  inEdge(node(5000483) idx(1))
node[5000483]: type(AddBiasResidualLayerNorm_5000483) view(1 4 0)  inEdge(node(5000480) idx(0)) inEdge(node(5000482) idx(0))
node[5000482]: type(AllReduce_5000482) view(1 4 0)  inEdge(node(5000481) idx(0))
node[5000481]: type(TreeIncMultiHeadSelfAttention_5000481) view(1 4 0)  inEdge(node(5000480) idx(1))
node[5000480]: type(ResidualLayerNorm_5000480) view(1 4 0)  inEdge(node(5000479) idx(0)) inEdge(node(5000475) idx(0))
node[5000479]: type(AllReduce_5000479) view(1 4 0)  inEdge(node(5000478) idx(0))
node[5000478]: type(Dense_5000478) view(1 4 0)  inEdge(node(5000477) idx(0))
node[5000477]: type(ReLU_5000477) view(1 4 0)  inEdge(node(5000476) idx(0))
node[5000476]: type(Dense_5000476) view(1 4 0)  inEdge(node(5000475) idx(1))
node[5000475]: type(AddBiasResidualLayerNorm_5000475) view(1 4 0)  inEdge(node(5000472) idx(0)) inEdge(node(5000474) idx(0))
node[5000474]: type(AllReduce_5000474) view(1 4 0)  inEdge(node(5000473) idx(0))
node[5000473]: type(TreeIncMultiHeadSelfAttention_5000473) view(1 4 0)  inEdge(node(5000472) idx(1))
node[5000472]: type(ResidualLayerNorm_5000472) view(1 4 0)  inEdge(node(5000471) idx(0)) inEdge(node(5000467) idx(0))
node[5000471]: type(AllReduce_5000471) view(1 4 0)  inEdge(node(5000470) idx(0))
node[5000470]: type(Dense_5000470) view(1 4 0)  inEdge(node(5000469) idx(0))
node[5000469]: type(ReLU_5000469) view(1 4 0)  inEdge(node(5000468) idx(0))
node[5000468]: type(Dense_5000468) view(1 4 0)  inEdge(node(5000467) idx(1))
node[5000467]: type(AddBiasResidualLayerNorm_5000467) view(1 4 0)  inEdge(node(5000464) idx(0)) inEdge(node(5000466) idx(0))
node[5000466]: type(AllReduce_5000466) view(1 4 0)  inEdge(node(5000465) idx(0))
node[5000465]: type(TreeIncMultiHeadSelfAttention_5000465) view(1 4 0)  inEdge(node(5000464) idx(1))
node[5000464]: type(ResidualLayerNorm_5000464) view(1 4 0)  inEdge(node(5000463) idx(0)) inEdge(node(5000459) idx(0))
node[5000463]: type(AllReduce_5000463) view(1 4 0)  inEdge(node(5000462) idx(0))
node[5000462]: type(Dense_5000462) view(1 4 0)  inEdge(node(5000461) idx(0))
node[5000461]: type(ReLU_5000461) view(1 4 0)  inEdge(node(5000460) idx(0))
node[5000460]: type(Dense_5000460) view(1 4 0)  inEdge(node(5000459) idx(1))
node[5000459]: type(AddBiasResidualLayerNorm_5000459) view(1 4 0)  inEdge(node(5000456) idx(0)) inEdge(node(5000458) idx(0))
node[5000458]: type(AllReduce_5000458) view(1 4 0)  inEdge(node(5000457) idx(0))
node[5000457]: type(TreeIncMultiHeadSelfAttention_5000457) view(1 4 0)  inEdge(node(5000456) idx(1))
node[5000344]: type(ResidualLayerNorm_5000344) view(1 4 0)  inEdge(node(5000343) idx(0)) inEdge(node(5000339) idx(0))
node[5000601]: type(TreeIncMultiHeadSelfAttention_5000601) view(1 4 0)  inEdge(node(5000600) idx(1))
node[5000345]: type(TreeIncMultiHeadSelfAttention_5000345) view(1 4 0)  inEdge(node(5000344) idx(1))
node[5000602]: type(AllReduce_5000602) view(1 4 0)  inEdge(node(5000601) idx(0))
node[5000346]: type(AllReduce_5000346) view(1 4 0)  inEdge(node(5000345) idx(0))
node[5000603]: type(AddBiasResidualLayerNorm_5000603) view(1 4 0)  inEdge(node(5000600) idx(0)) inEdge(node(5000602) idx(0))
node[5000347]: type(AddBiasResidualLayerNorm_5000347) view(1 4 0)  inEdge(node(5000344) idx(0)) inEdge(node(5000346) idx(0))
node[5000604]: type(Dense_5000604) view(1 4 0)  inEdge(node(5000603) idx(1))
node[5000348]: type(Dense_5000348) view(1 4 0)  inEdge(node(5000347) idx(1))
node[5000605]: type(ReLU_5000605) view(1 4 0)  inEdge(node(5000604) idx(0))
node[5000349]: type(ReLU_5000349) view(1 4 0)  inEdge(node(5000348) idx(0))
node[5000606]: type(Dense_5000606) view(1 4 0)  inEdge(node(5000605) idx(0))
node[5000350]: type(Dense_5000350) view(1 4 0)  inEdge(node(5000349) idx(0))
node[5000607]: type(AllReduce_5000607) view(1 4 0)  inEdge(node(5000606) idx(0))
node[5000351]: type(AllReduce_5000351) view(1 4 0)  inEdge(node(5000350) idx(0))
node[5000608]: type(ResidualLayerNorm_5000608) view(1 4 0)  inEdge(node(5000607) idx(0)) inEdge(node(5000603) idx(0))
node[5000588]: type(Dense_5000588) view(1 4 0)  inEdge(node(5000587) idx(1))
node[5000331]: type(Input_5000331) view(1 1 0) 
node[5000587]: type(AddBiasResidualLayerNorm_5000587) view(1 4 0)  inEdge(node(5000584) idx(0)) inEdge(node(5000586) idx(0))
node[5000330]: type(Input_5000330) view(1 1 0) 
node[5000514]: type(AllReduce_5000514) view(1 4 0)  inEdge(node(5000513) idx(0))
node[5000515]: type(AddBiasResidualLayerNorm_5000515) view(1 4 0)  inEdge(node(5000512) idx(0)) inEdge(node(5000514) idx(0))
node[5000516]: type(Dense_5000516) view(1 4 0)  inEdge(node(5000515) idx(1))
node[5000517]: type(ReLU_5000517) view(1 4 0)  inEdge(node(5000516) idx(0))
node[5000518]: type(Dense_5000518) view(1 4 0)  inEdge(node(5000517) idx(0))
node[5000519]: type(AllReduce_5000519) view(1 4 0)  inEdge(node(5000518) idx(0))
node[5000520]: type(ResidualLayerNorm_5000520) view(1 4 0)  inEdge(node(5000519) idx(0)) inEdge(node(5000515) idx(0))
node[5000521]: type(TreeIncMultiHeadSelfAttention_5000521) view(1 4 0)  inEdge(node(5000520) idx(1))
node[5000522]: type(AllReduce_5000522) view(1 4 0)  inEdge(node(5000521) idx(0))
node[5000523]: type(AddBiasResidualLayerNorm_5000523) view(1 4 0)  inEdge(node(5000520) idx(0)) inEdge(node(5000522) idx(0))
node[5000524]: type(Dense_5000524) view(1 4 0)  inEdge(node(5000523) idx(1))
node[5000525]: type(ReLU_5000525) view(1 4 0)  inEdge(node(5000524) idx(0))
node[5000526]: type(Dense_5000526) view(1 4 0)  inEdge(node(5000525) idx(0))
node[5000527]: type(AllReduce_5000527) view(1 4 0)  inEdge(node(5000526) idx(0))
node[5000431]: type(AllReduce_5000431) view(1 4 0)  inEdge(node(5000430) idx(0))
node[5000558]: type(Dense_5000558) view(1 4 0)  inEdge(node(5000557) idx(0))
node[5000432]: type(ResidualLayerNorm_5000432) view(1 4 0)  inEdge(node(5000431) idx(0)) inEdge(node(5000427) idx(0))
node[5000559]: type(AllReduce_5000559) view(1 4 0)  inEdge(node(5000558) idx(0))
node[5000433]: type(TreeIncMultiHeadSelfAttention_5000433) view(1 4 0)  inEdge(node(5000432) idx(1))
node[5000560]: type(ResidualLayerNorm_5000560) view(1 4 0)  inEdge(node(5000559) idx(0)) inEdge(node(5000555) idx(0))
node[5000434]: type(AllReduce_5000434) view(1 4 0)  inEdge(node(5000433) idx(0))
node[5000561]: type(TreeIncMultiHeadSelfAttention_5000561) view(1 4 0)  inEdge(node(5000560) idx(1))
node[5000435]: type(AddBiasResidualLayerNorm_5000435) view(1 4 0)  inEdge(node(5000432) idx(0)) inEdge(node(5000434) idx(0))
node[5000562]: type(AllReduce_5000562) view(1 4 0)  inEdge(node(5000561) idx(0))
node[5000436]: type(Dense_5000436) view(1 4 0)  inEdge(node(5000435) idx(1))
node[5000563]: type(AddBiasResidualLayerNorm_5000563) view(1 4 0)  inEdge(node(5000560) idx(0)) inEdge(node(5000562) idx(0))
node[5000437]: type(ReLU_5000437) view(1 4 0)  inEdge(node(5000436) idx(0))
node[5000564]: type(Dense_5000564) view(1 4 0)  inEdge(node(5000563) idx(1))
node[5000438]: type(Dense_5000438) view(1 4 0)  inEdge(node(5000437) idx(0))
node[5000565]: type(ReLU_5000565) view(1 4 0)  inEdge(node(5000564) idx(0))
node[5000439]: type(AllReduce_5000439) view(1 4 0)  inEdge(node(5000438) idx(0))
node[5000566]: type(Dense_5000566) view(1 4 0)  inEdge(node(5000565) idx(0))
node[5000440]: type(ResidualLayerNorm_5000440) view(1 4 0)  inEdge(node(5000439) idx(0)) inEdge(node(5000435) idx(0))
node[5000567]: type(AllReduce_5000567) view(1 4 0)  inEdge(node(5000566) idx(0))
node[5000441]: type(TreeIncMultiHeadSelfAttention_5000441) view(1 4 0)  inEdge(node(5000440) idx(1))
node[5000568]: type(ResidualLayerNorm_5000568) view(1 4 0)  inEdge(node(5000567) idx(0)) inEdge(node(5000563) idx(0))
node[5000442]: type(AllReduce_5000442) view(1 4 0)  inEdge(node(5000441) idx(0))
node[5000569]: type(TreeIncMultiHeadSelfAttention_5000569) view(1 4 0)  inEdge(node(5000568) idx(1))
node[5000443]: type(AddBiasResidualLayerNorm_5000443) view(1 4 0)  inEdge(node(5000440) idx(0)) inEdge(node(5000442) idx(0))
node[5000570]: type(AllReduce_5000570) view(1 4 0)  inEdge(node(5000569) idx(0))
node[5000444]: type(Dense_5000444) view(1 4 0)  inEdge(node(5000443) idx(1))
node[5000571]: type(AddBiasResidualLayerNorm_5000571) view(1 4 0)  inEdge(node(5000568) idx(0)) inEdge(node(5000570) idx(0))
node[5000445]: type(ReLU_5000445) view(1 4 0)  inEdge(node(5000444) idx(0))
node[5000572]: type(Dense_5000572) view(1 4 0)  inEdge(node(5000571) idx(1))
node[5000446]: type(Dense_5000446) view(1 4 0)  inEdge(node(5000445) idx(0))
node[5000573]: type(ReLU_5000573) view(1 4 0)  inEdge(node(5000572) idx(0))
node[5000586]: type(AllReduce_5000586) view(1 4 0)  inEdge(node(5000585) idx(0))
node[5000585]: type(TreeIncMultiHeadSelfAttention_5000585) view(1 4 0)  inEdge(node(5000584) idx(1))
node[5000584]: type(ResidualLayerNorm_5000584) view(1 4 0)  inEdge(node(5000583) idx(0)) inEdge(node(5000579) idx(0))
node[5000456]: type(ResidualLayerNorm_5000456) view(1 4 0)  inEdge(node(5000455) idx(0)) inEdge(node(5000451) idx(0))
node[5000583]: type(AllReduce_5000583) view(1 4 0)  inEdge(node(5000582) idx(0))
node[5000455]: type(AllReduce_5000455) view(1 4 0)  inEdge(node(5000454) idx(0))
node[5000582]: type(Dense_5000582) view(1 4 0)  inEdge(node(5000581) idx(0))
node[5000454]: type(Dense_5000454) view(1 4 0)  inEdge(node(5000453) idx(0))
node[5000581]: type(ReLU_5000581) view(1 4 0)  inEdge(node(5000580) idx(0))
node[5000453]: type(ReLU_5000453) view(1 4 0)  inEdge(node(5000452) idx(0))
node[5000580]: type(Dense_5000580) view(1 4 0)  inEdge(node(5000579) idx(1))
node[5000452]: type(Dense_5000452) view(1 4 0)  inEdge(node(5000451) idx(1))
node[5000579]: type(AddBiasResidualLayerNorm_5000579) view(1 4 0)  inEdge(node(5000576) idx(0)) inEdge(node(5000578) idx(0))
node[5000451]: type(AddBiasResidualLayerNorm_5000451) view(1 4 0)  inEdge(node(5000448) idx(0)) inEdge(node(5000450) idx(0))
node[5000578]: type(AllReduce_5000578) view(1 4 0)  inEdge(node(5000577) idx(0))
node[5000450]: type(AllReduce_5000450) view(1 4 0)  inEdge(node(5000449) idx(0))
node[5000577]: type(TreeIncMultiHeadSelfAttention_5000577) view(1 4 0)  inEdge(node(5000576) idx(1))
node[5000449]: type(TreeIncMultiHeadSelfAttention_5000449) view(1 4 0)  inEdge(node(5000448) idx(1))
node[5000576]: type(ResidualLayerNorm_5000576) view(1 4 0)  inEdge(node(5000575) idx(0)) inEdge(node(5000571) idx(0))
node[5000448]: type(ResidualLayerNorm_5000448) view(1 4 0)  inEdge(node(5000447) idx(0)) inEdge(node(5000443) idx(0))
node[5000575]: type(AllReduce_5000575) view(1 4 0)  inEdge(node(5000574) idx(0))
node[5000447]: type(AllReduce_5000447) view(1 4 0)  inEdge(node(5000446) idx(0))
node[5000574]: type(Dense_5000574) view(1 4 0)  inEdge(node(5000573) idx(0))
node[5000430]: type(Dense_5000430) view(1 4 0)  inEdge(node(5000429) idx(0))
node[5000557]: type(ReLU_5000557) view(1 4 0)  inEdge(node(5000556) idx(0))
node[5000429]: type(ReLU_5000429) view(1 4 0)  inEdge(node(5000428) idx(0))
node[5000556]: type(Dense_5000556) view(1 4 0)  inEdge(node(5000555) idx(1))
node[5000428]: type(Dense_5000428) view(1 4 0)  inEdge(node(5000427) idx(1))
node[5000555]: type(AddBiasResidualLayerNorm_5000555) view(1 4 0)  inEdge(node(5000552) idx(0)) inEdge(node(5000554) idx(0))
node[5000427]: type(AddBiasResidualLayerNorm_5000427) view(1 4 0)  inEdge(node(5000424) idx(0)) inEdge(node(5000426) idx(0))
node[5000554]: type(AllReduce_5000554) view(1 4 0)  inEdge(node(5000553) idx(0))
node[5000426]: type(AllReduce_5000426) view(1 4 0)  inEdge(node(5000425) idx(0))
node[5000553]: type(TreeIncMultiHeadSelfAttention_5000553) view(1 4 0)  inEdge(node(5000552) idx(1))
node[5000425]: type(TreeIncMultiHeadSelfAttention_5000425) view(1 4 0)  inEdge(node(5000424) idx(1))
node[5000552]: type(ResidualLayerNorm_5000552) view(1 4 0)  inEdge(node(5000551) idx(0)) inEdge(node(5000547) idx(0))
node[5000424]: type(ResidualLayerNorm_5000424) view(1 4 0)  inEdge(node(5000423) idx(0)) inEdge(node(5000419) idx(0))
node[5000551]: type(AllReduce_5000551) view(1 4 0)  inEdge(node(5000550) idx(0))
node[5000423]: type(AllReduce_5000423) view(1 4 0)  inEdge(node(5000422) idx(0))
node[5000550]: type(Dense_5000550) view(1 4 0)  inEdge(node(5000549) idx(0))
node[5000422]: type(Dense_5000422) view(1 4 0)  inEdge(node(5000421) idx(0))
node[5000549]: type(ReLU_5000549) view(1 4 0)  inEdge(node(5000548) idx(0))
node[5000421]: type(ReLU_5000421) view(1 4 0)  inEdge(node(5000420) idx(0))
node[5000548]: type(Dense_5000548) view(1 4 0)  inEdge(node(5000547) idx(1))
node[5000420]: type(Dense_5000420) view(1 4 0)  inEdge(node(5000419) idx(1))
node[5000547]: type(AddBiasResidualLayerNorm_5000547) view(1 4 0)  inEdge(node(5000544) idx(0)) inEdge(node(5000546) idx(0))
node[5000419]: type(AddBiasResidualLayerNorm_5000419) view(1 4 0)  inEdge(node(5000416) idx(0)) inEdge(node(5000418) idx(0))
node[5000546]: type(AllReduce_5000546) view(1 4 0)  inEdge(node(5000545) idx(0))
node[5000418]: type(AllReduce_5000418) view(1 4 0)  inEdge(node(5000417) idx(0))
node[5000545]: type(TreeIncMultiHeadSelfAttention_5000545) view(1 4 0)  inEdge(node(5000544) idx(1))
node[5000417]: type(TreeIncMultiHeadSelfAttention_5000417) view(1 4 0)  inEdge(node(5000416) idx(1))
node[5000544]: type(ResidualLayerNorm_5000544) view(1 4 0)  inEdge(node(5000543) idx(0)) inEdge(node(5000539) idx(0))
node[5000416]: type(ResidualLayerNorm_5000416) view(1 4 0)  inEdge(node(5000415) idx(0)) inEdge(node(5000411) idx(0))
node[5000543]: type(AllReduce_5000543) view(1 4 0)  inEdge(node(5000542) idx(0))
node[5000415]: type(AllReduce_5000415) view(1 4 0)  inEdge(node(5000414) idx(0))
node[5000542]: type(Dense_5000542) view(1 4 0)  inEdge(node(5000541) idx(0))
node[5000414]: type(Dense_5000414) view(1 4 0)  inEdge(node(5000413) idx(0))
node[5000541]: type(ReLU_5000541) view(1 4 0)  inEdge(node(5000540) idx(0))
node[5000413]: type(ReLU_5000413) view(1 4 0)  inEdge(node(5000412) idx(0))
node[5000540]: type(Dense_5000540) view(1 4 0)  inEdge(node(5000539) idx(1))
node[5000412]: type(Dense_5000412) view(1 4 0)  inEdge(node(5000411) idx(1))
node[5000539]: type(AddBiasResidualLayerNorm_5000539) view(1 4 0)  inEdge(node(5000536) idx(0)) inEdge(node(5000538) idx(0))
node[5000411]: type(AddBiasResidualLayerNorm_5000411) view(1 4 0)  inEdge(node(5000408) idx(0)) inEdge(node(5000410) idx(0))
node[5000538]: type(AllReduce_5000538) view(1 4 0)  inEdge(node(5000537) idx(0))
node[5000410]: type(AllReduce_5000410) view(1 4 0)  inEdge(node(5000409) idx(0))
node[5000537]: type(TreeIncMultiHeadSelfAttention_5000537) view(1 4 0)  inEdge(node(5000536) idx(1))
node[5000409]: type(TreeIncMultiHeadSelfAttention_5000409) view(1 4 0)  inEdge(node(5000408) idx(1))
node[5000536]: type(ResidualLayerNorm_5000536) view(1 4 0)  inEdge(node(5000535) idx(0)) inEdge(node(5000531) idx(0))
node[5000408]: type(ResidualLayerNorm_5000408) view(1 4 0)  inEdge(node(5000407) idx(0)) inEdge(node(5000403) idx(0))
node[5000535]: type(AllReduce_5000535) view(1 4 0)  inEdge(node(5000534) idx(0))
node[5000407]: type(AllReduce_5000407) view(1 4 0)  inEdge(node(5000406) idx(0))
node[5000534]: type(Dense_5000534) view(1 4 0)  inEdge(node(5000533) idx(0))
node[5000406]: type(Dense_5000406) view(1 4 0)  inEdge(node(5000405) idx(0))
node[5000533]: type(ReLU_5000533) view(1 4 0)  inEdge(node(5000532) idx(0))
node[5000532]: type(Dense_5000532) view(1 4 0)  inEdge(node(5000531) idx(1))
node[5000531]: type(AddBiasResidualLayerNorm_5000531) view(1 4 0)  inEdge(node(5000528) idx(0)) inEdge(node(5000530) idx(0))
node[5000530]: type(AllReduce_5000530) view(1 4 0)  inEdge(node(5000529) idx(0))
node[5000529]: type(TreeIncMultiHeadSelfAttention_5000529) view(1 4 0)  inEdge(node(5000528) idx(1))
node[5000528]: type(ResidualLayerNorm_5000528) view(1 4 0)  inEdge(node(5000527) idx(0)) inEdge(node(5000523) idx(0))
node[5000589]: type(ReLU_5000589) view(1 4 0)  inEdge(node(5000588) idx(0))
node[5000332]: type(Embedding_5000332) view(1 1 0)  inEdge(node(5000330) idx(0))
node[5000590]: type(Dense_5000590) view(1 4 0)  inEdge(node(5000589) idx(0))
node[5000333]: type(Embedding_5000333) view(1 1 0)  inEdge(node(5000331) idx(0))
node[5000334]: type(Replicate_5000334) view(1 4 0)  inEdge(node(5000332) idx(0))
node[5000591]: type(AllReduce_5000591) view(1 4 0)  inEdge(node(5000590) idx(0))
node[5000592]: type(ResidualLayerNorm_5000592) view(1 4 0)  inEdge(node(5000591) idx(0)) inEdge(node(5000587) idx(0))
node[5000335]: type(Replicate_5000335) view(1 4 0)  inEdge(node(5000333) idx(0))
node[5000593]: type(TreeIncMultiHeadSelfAttention_5000593) view(1 4 0)  inEdge(node(5000592) idx(1))
node[5000336]: type(ResidualLayerNorm_5000336) view(1 4 0)  inEdge(node(5000335) idx(0)) inEdge(node(5000334) idx(0))
node[5000594]: type(AllReduce_5000594) view(1 4 0)  inEdge(node(5000593) idx(0))
node[5000337]: type(TreeIncMultiHeadSelfAttention_5000337) view(1 4 0)  inEdge(node(5000336) idx(1))
node[5000595]: type(AddBiasResidualLayerNorm_5000595) view(1 4 0)  inEdge(node(5000592) idx(0)) inEdge(node(5000594) idx(0))
node[5000338]: type(AllReduce_5000338) view(1 4 0)  inEdge(node(5000337) idx(0))
node[5000596]: type(Dense_5000596) view(1 4 0)  inEdge(node(5000595) idx(1))
node[5000339]: type(AddBiasResidualLayerNorm_5000339) view(1 4 0)  inEdge(node(5000336) idx(0)) inEdge(node(5000338) idx(0))
node[5000597]: type(ReLU_5000597) view(1 4 0)  inEdge(node(5000596) idx(0))
node[5000340]: type(Dense_5000340) view(1 4 0)  inEdge(node(5000339) idx(1))
node[5000598]: type(Dense_5000598) view(1 4 0)  inEdge(node(5000597) idx(0))
node[5000341]: type(ReLU_5000341) view(1 4 0)  inEdge(node(5000340) idx(0))
node[5000599]: type(AllReduce_5000599) view(1 4 0)  inEdge(node(5000598) idx(0))
node[5000342]: type(Dense_5000342) view(1 4 0)  inEdge(node(5000341) idx(0))
node[5000600]: type(ResidualLayerNorm_5000600) view(1 4 0)  inEdge(node(5000599) idx(0)) inEdge(node(5000595) idx(0))
node[5000343]: type(AllReduce_5000343) view(1 4 0)  inEdge(node(5000342) idx(0))
node[5000631]: type(AllReduce_5000631) view(1 4 0)  inEdge(node(5000630) idx(0))
node[5000374]: type(Dense_5000374) view(1 4 0)  inEdge(node(5000373) idx(0))
node[5000632]: type(ResidualLayerNorm_5000632) view(1 4 0)  inEdge(node(5000631) idx(0)) inEdge(node(5000627) idx(0))
node[5000375]: type(AllReduce_5000375) view(1 4 0)  inEdge(node(5000374) idx(0))
node[5000633]: type(TreeIncMultiHeadSelfAttention_5000633) view(1 4 0)  inEdge(node(5000632) idx(1))
node[5000376]: type(ResidualLayerNorm_5000376) view(1 4 0)  inEdge(node(5000375) idx(0)) inEdge(node(5000371) idx(0))
node[5000634]: type(AllReduce_5000634) view(1 4 0)  inEdge(node(5000633) idx(0))
node[5000377]: type(TreeIncMultiHeadSelfAttention_5000377) view(1 4 0)  inEdge(node(5000376) idx(1))
node[5000635]: type(AddBiasResidualLayerNorm_5000635) view(1 4 0)  inEdge(node(5000632) idx(0)) inEdge(node(5000634) idx(0))
node[5000378]: type(AllReduce_5000378) view(1 4 0)  inEdge(node(5000377) idx(0))
node[5000636]: type(Dense_5000636) view(1 4 0)  inEdge(node(5000635) idx(1))
node[5000379]: type(AddBiasResidualLayerNorm_5000379) view(1 4 0)  inEdge(node(5000376) idx(0)) inEdge(node(5000378) idx(0))
node[5000637]: type(ReLU_5000637) view(1 4 0)  inEdge(node(5000636) idx(0))
node[5000380]: type(Dense_5000380) view(1 4 0)  inEdge(node(5000379) idx(1))
node[5000638]: type(Dense_5000638) view(1 4 0)  inEdge(node(5000637) idx(0))
node[5000381]: type(ReLU_5000381) view(1 4 0)  inEdge(node(5000380) idx(0))
node[5000639]: type(AllReduce_5000639) view(1 4 0)  inEdge(node(5000638) idx(0))
node[5000382]: type(Dense_5000382) view(1 4 0)  inEdge(node(5000381) idx(0))
node[5000640]: type(ResidualLayerNorm_5000640) view(1 4 0)  inEdge(node(5000639) idx(0)) inEdge(node(5000635) idx(0))
node[5000383]: type(AllReduce_5000383) view(1 4 0)  inEdge(node(5000382) idx(0))
node[5000641]: type(TreeIncMultiHeadSelfAttention_5000641) view(1 4 0)  inEdge(node(5000640) idx(1))
node[5000384]: type(ResidualLayerNorm_5000384) view(1 4 0)  inEdge(node(5000383) idx(0)) inEdge(node(5000379) idx(0))
node[5000642]: type(AllReduce_5000642) view(1 4 0)  inEdge(node(5000641) idx(0))
node[5000385]: type(TreeIncMultiHeadSelfAttention_5000385) view(1 4 0)  inEdge(node(5000384) idx(1))
node[5000643]: type(AddBiasResidualLayerNorm_5000643) view(1 4 0)  inEdge(node(5000640) idx(0)) inEdge(node(5000642) idx(0))
node[5000386]: type(AllReduce_5000386) view(1 4 0)  inEdge(node(5000385) idx(0))
node[5000644]: type(Dense_5000644) view(1 4 0)  inEdge(node(5000643) idx(1))
node[5000387]: type(AddBiasResidualLayerNorm_5000387) view(1 4 0)  inEdge(node(5000384) idx(0)) inEdge(node(5000386) idx(0))
node[5000645]: type(ReLU_5000645) view(1 4 0)  inEdge(node(5000644) idx(0))
node[5000388]: type(Dense_5000388) view(1 4 0)  inEdge(node(5000387) idx(1))
node[5000646]: type(Dense_5000646) view(1 4 0)  inEdge(node(5000645) idx(0))
node[5000389]: type(ReLU_5000389) view(1 4 0)  inEdge(node(5000388) idx(0))
node[5000405]: type(ReLU_5000405) view(1 4 0)  inEdge(node(5000404) idx(0))
node[5000659]: type(ArgMax_5000659) view(1 1 0)  inEdge(node(5000658) idx(0))
node[5000402]: type(AllReduce_5000402) view(1 4 0)  inEdge(node(5000401) idx(0))
node[5000404]: type(Dense_5000404) view(1 4 0)  inEdge(node(5000403) idx(1))
node[5000658]: type(Combine_5000658) view(1 1 0)  inEdge(node(5000657) idx(0))
node[5000401]: type(TreeIncMultiHeadSelfAttention_5000401) view(1 4 0)  inEdge(node(5000400) idx(1))
node[5000403]: type(AddBiasResidualLayerNorm_5000403) view(1 4 0)  inEdge(node(5000400) idx(0)) inEdge(node(5000402) idx(0))
node[5000657]: type(Dense_5000657) view(1 4 0)  inEdge(node(5000656) idx(1))
node[5000400]: type(ResidualLayerNorm_5000400) view(1 4 0)  inEdge(node(5000399) idx(0)) inEdge(node(5000395) idx(0))
node[5000656]: type(ResidualLayerNorm_5000656) view(1 4 0)  inEdge(node(5000655) idx(0)) inEdge(node(5000651) idx(0))
node[5000399]: type(AllReduce_5000399) view(1 4 0)  inEdge(node(5000398) idx(0))
node[5000655]: type(AllReduce_5000655) view(1 4 0)  inEdge(node(5000654) idx(0))
node[5000398]: type(Dense_5000398) view(1 4 0)  inEdge(node(5000397) idx(0))
node[5000654]: type(Dense_5000654) view(1 4 0)  inEdge(node(5000653) idx(0))
node[5000397]: type(ReLU_5000397) view(1 4 0)  inEdge(node(5000396) idx(0))
node[5000653]: type(ReLU_5000653) view(1 4 0)  inEdge(node(5000652) idx(0))
node[5000396]: type(Dense_5000396) view(1 4 0)  inEdge(node(5000395) idx(1))
node[5000652]: type(Dense_5000652) view(1 4 0)  inEdge(node(5000651) idx(1))
node[5000395]: type(AddBiasResidualLayerNorm_5000395) view(1 4 0)  inEdge(node(5000392) idx(0)) inEdge(node(5000394) idx(0))
node[5000651]: type(AddBiasResidualLayerNorm_5000651) view(1 4 0)  inEdge(node(5000648) idx(0)) inEdge(node(5000650) idx(0))
node[5000394]: type(AllReduce_5000394) view(1 4 0)  inEdge(node(5000393) idx(0))
node[5000650]: type(AllReduce_5000650) view(1 4 0)  inEdge(node(5000649) idx(0))
node[5000393]: type(TreeIncMultiHeadSelfAttention_5000393) view(1 4 0)  inEdge(node(5000392) idx(1))
node[5000649]: type(TreeIncMultiHeadSelfAttention_5000649) view(1 4 0)  inEdge(node(5000648) idx(1))
node[5000392]: type(ResidualLayerNorm_5000392) view(1 4 0)  inEdge(node(5000391) idx(0)) inEdge(node(5000387) idx(0))
node[5000648]: type(ResidualLayerNorm_5000648) view(1 4 0)  inEdge(node(5000647) idx(0)) inEdge(node(5000643) idx(0))
node[5000391]: type(AllReduce_5000391) view(1 4 0)  inEdge(node(5000390) idx(0))
node[5000647]: type(AllReduce_5000647) view(1 4 0)  inEdge(node(5000646) idx(0))
node[5000390]: type(Dense_5000390) view(1 4 0)  inEdge(node(5000389) idx(0))
node[5000630]: type(Dense_5000630) view(1 4 0)  inEdge(node(5000629) idx(0))
node[5000373]: type(ReLU_5000373) view(1 4 0)  inEdge(node(5000372) idx(0))
node[5000629]: type(ReLU_5000629) view(1 4 0)  inEdge(node(5000628) idx(0))
node[5000372]: type(Dense_5000372) view(1 4 0)  inEdge(node(5000371) idx(1))
node[5000628]: type(Dense_5000628) view(1 4 0)  inEdge(node(5000627) idx(1))
node[5000371]: type(AddBiasResidualLayerNorm_5000371) view(1 4 0)  inEdge(node(5000368) idx(0)) inEdge(node(5000370) idx(0))
node[5000627]: type(AddBiasResidualLayerNorm_5000627) view(1 4 0)  inEdge(node(5000624) idx(0)) inEdge(node(5000626) idx(0))
node[5000370]: type(AllReduce_5000370) view(1 4 0)  inEdge(node(5000369) idx(0))
node[5000626]: type(AllReduce_5000626) view(1 4 0)  inEdge(node(5000625) idx(0))
node[5000369]: type(TreeIncMultiHeadSelfAttention_5000369) view(1 4 0)  inEdge(node(5000368) idx(1))
node[5000625]: type(TreeIncMultiHeadSelfAttention_5000625) view(1 4 0)  inEdge(node(5000624) idx(1))
node[5000368]: type(ResidualLayerNorm_5000368) view(1 4 0)  inEdge(node(5000367) idx(0)) inEdge(node(5000363) idx(0))
node[5000624]: type(ResidualLayerNorm_5000624) view(1 4 0)  inEdge(node(5000623) idx(0)) inEdge(node(5000619) idx(0))
node[5000367]: type(AllReduce_5000367) view(1 4 0)  inEdge(node(5000366) idx(0))
node[5000623]: type(AllReduce_5000623) view(1 4 0)  inEdge(node(5000622) idx(0))
node[5000366]: type(Dense_5000366) view(1 4 0)  inEdge(node(5000365) idx(0))
node[5000622]: type(Dense_5000622) view(1 4 0)  inEdge(node(5000621) idx(0))
node[5000365]: type(ReLU_5000365) view(1 4 0)  inEdge(node(5000364) idx(0))
node[5000621]: type(ReLU_5000621) view(1 4 0)  inEdge(node(5000620) idx(0))
node[5000364]: type(Dense_5000364) view(1 4 0)  inEdge(node(5000363) idx(1))
node[5000620]: type(Dense_5000620) view(1 4 0)  inEdge(node(5000619) idx(1))
node[5000363]: type(AddBiasResidualLayerNorm_5000363) view(1 4 0)  inEdge(node(5000360) idx(0)) inEdge(node(5000362) idx(0))
node[5000619]: type(AddBiasResidualLayerNorm_5000619) view(1 4 0)  inEdge(node(5000616) idx(0)) inEdge(node(5000618) idx(0))
node[5000362]: type(AllReduce_5000362) view(1 4 0)  inEdge(node(5000361) idx(0))
node[5000618]: type(AllReduce_5000618) view(1 4 0)  inEdge(node(5000617) idx(0))
node[5000361]: type(TreeIncMultiHeadSelfAttention_5000361) view(1 4 0)  inEdge(node(5000360) idx(1))
node[5000617]: type(TreeIncMultiHeadSelfAttention_5000617) view(1 4 0)  inEdge(node(5000616) idx(1))
node[5000360]: type(ResidualLayerNorm_5000360) view(1 4 0)  inEdge(node(5000359) idx(0)) inEdge(node(5000355) idx(0))
node[5000616]: type(ResidualLayerNorm_5000616) view(1 4 0)  inEdge(node(5000615) idx(0)) inEdge(node(5000611) idx(0))
node[5000359]: type(AllReduce_5000359) view(1 4 0)  inEdge(node(5000358) idx(0))
node[5000615]: type(AllReduce_5000615) view(1 4 0)  inEdge(node(5000614) idx(0))
node[5000358]: type(Dense_5000358) view(1 4 0)  inEdge(node(5000357) idx(0))
node[5000614]: type(Dense_5000614) view(1 4 0)  inEdge(node(5000613) idx(0))
node[5000357]: type(ReLU_5000357) view(1 4 0)  inEdge(node(5000356) idx(0))
node[5000613]: type(ReLU_5000613) view(1 4 0)  inEdge(node(5000612) idx(0))
node[5000356]: type(Dense_5000356) view(1 4 0)  inEdge(node(5000355) idx(1))
node[5000612]: type(Dense_5000612) view(1 4 0)  inEdge(node(5000611) idx(1))
node[5000355]: type(AddBiasResidualLayerNorm_5000355) view(1 4 0)  inEdge(node(5000352) idx(0)) inEdge(node(5000354) idx(0))
node[5000611]: type(AddBiasResidualLayerNorm_5000611) view(1 4 0)  inEdge(node(5000608) idx(0)) inEdge(node(5000610) idx(0))
node[5000354]: type(AllReduce_5000354) view(1 4 0)  inEdge(node(5000353) idx(0))
node[5000610]: type(AllReduce_5000610) view(1 4 0)  inEdge(node(5000609) idx(0))
node[5000353]: type(TreeIncMultiHeadSelfAttention_5000353) view(1 4 0)  inEdge(node(5000352) idx(1))
node[5000609]: type(TreeIncMultiHeadSelfAttention_5000609) view(1 4 0)  inEdge(node(5000608) idx(1))
node[5000352]: type(ResidualLayerNorm_5000352) view(1 4 0)  inEdge(node(5000351) idx(0)) inEdge(node(5000347) idx(0))
digraph taskgraph {
  node0 [label="{ AllReduce_5000586 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node1 -> node0;
  node1 [label="{ TreeIncMultiHeadSelfAttention_5000585 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node2 -> node1;
  node2 [label="{ ResidualLayerNorm_5000584 }",shape=record];
  node3 -> node2;
  node4 -> node2;
  node4 [label="{ AllReduce_5000583 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node5 -> node4;
  node5 [label="{ Dense_5000582 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node6 -> node5;
  node6 [label="{ ReLU_5000581 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node7 -> node6;
  node7 [label="{ Dense_5000580 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node3 -> node7;
  node3 [label="{ AddBiasResidualLayerNorm_5000579 }",shape=record];
  node8 -> node3;
  node9 -> node3;
  node8 [label="{ AllReduce_5000578 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node10 -> node8;
  node10 [label="{ TreeIncMultiHeadSelfAttention_5000577 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node9 -> node10;
  node9 [label="{ ResidualLayerNorm_5000576 }",shape=record];
  node11 -> node9;
  node12 -> node9;
  node12 [label="{ AllReduce_5000575 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node13 -> node12;
  node13 [label="{ Dense_5000574 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node14 -> node13;
  node14 [label="{ ReLU_5000573 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node15 -> node14;
  node15 [label="{ Dense_5000572 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node11 -> node15;
  node11 [label="{ AddBiasResidualLayerNorm_5000571 }",shape=record];
  node16 -> node11;
  node17 -> node11;
  node16 [label="{ AllReduce_5000570 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node18 -> node16;
  node18 [label="{ TreeIncMultiHeadSelfAttention_5000569 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node17 -> node18;
  node17 [label="{ ResidualLayerNorm_5000568 }",shape=record];
  node19 -> node17;
  node20 -> node17;
  node20 [label="{ AllReduce_5000567 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node21 -> node20;
  node21 [label="{ Dense_5000566 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node22 -> node21;
  node22 [label="{ ReLU_5000565 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node23 -> node22;
  node23 [label="{ Dense_5000564 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node19 -> node23;
  node19 [label="{ AddBiasResidualLayerNorm_5000563 }",shape=record];
  node24 -> node19;
  node25 -> node19;
  node24 [label="{ AllReduce_5000562 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node26 -> node24;
  node26 [label="{ TreeIncMultiHeadSelfAttention_5000561 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node25 -> node26;
  node25 [label="{ ResidualLayerNorm_5000560 }",shape=record];
  node27 -> node25;
  node28 -> node25;
  node28 [label="{ AllReduce_5000559 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node29 -> node28;
  node29 [label="{ Dense_5000558 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node30 -> node29;
  node30 [label="{ ReLU_5000557 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node31 -> node30;
  node31 [label="{ Dense_5000556 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node27 -> node31;
  node27 [label="{ AddBiasResidualLayerNorm_5000555 }",shape=record];
  node32 -> node27;
  node33 -> node27;
  node32 [label="{ AllReduce_5000554 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node34 -> node32;
  node34 [label="{ TreeIncMultiHeadSelfAttention_5000553 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node33 -> node34;
  node33 [label="{ ResidualLayerNorm_5000552 }",shape=record];
  node35 -> node33;
  node36 -> node33;
  node36 [label="{ AllReduce_5000551 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node37 -> node36;
  node37 [label="{ Dense_5000550 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node38 -> node37;
  node38 [label="{ ReLU_5000549 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node39 -> node38;
  node39 [label="{ Dense_5000548 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node35 -> node39;
  node35 [label="{ AddBiasResidualLayerNorm_5000547 }",shape=record];
  node40 -> node35;
  node41 -> node35;
  node40 [label="{ AllReduce_5000546 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node42 -> node40;
  node42 [label="{ TreeIncMultiHeadSelfAttention_5000545 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node41 -> node42;
  node41 [label="{ ResidualLayerNorm_5000544 }",shape=record];
  node43 -> node41;
  node44 -> node41;
  node44 [label="{ AllReduce_5000543 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node45 -> node44;
  node45 [label="{ Dense_5000542 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node46 -> node45;
  node46 [label="{ ReLU_5000541 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node47 -> node46;
  node47 [label="{ Dense_5000540 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node43 -> node47;
  node43 [label="{ AddBiasResidualLayerNorm_5000539 }",shape=record];
  node48 -> node43;
  node49 -> node43;
  node48 [label="{ AllReduce_5000538 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node50 -> node48;
  node50 [label="{ TreeIncMultiHeadSelfAttention_5000537 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node49 -> node50;
  node49 [label="{ ResidualLayerNorm_5000536 }",shape=record];
  node51 -> node49;
  node52 -> node49;
  node52 [label="{ AllReduce_5000535 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node53 -> node52;
  node53 [label="{ Dense_5000534 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node54 -> node53;
  node54 [label="{ ReLU_5000533 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node55 -> node54;
  node55 [label="{ Dense_5000532 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node51 -> node55;
  node51 [label="{ AddBiasResidualLayerNorm_5000531 }",shape=record];
  node56 -> node51;
  node57 -> node51;
  node56 [label="{ AllReduce_5000530 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node58 -> node56;
  node58 [label="{ TreeIncMultiHeadSelfAttention_5000529 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node57 -> node58;
  node57 [label="{ ResidualLayerNorm_5000528 }",shape=record];
  node59 -> node57;
  node60 -> node57;
  node60 [label="{ AllReduce_5000527 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node61 -> node60;
  node61 [label="{ Dense_5000526 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node62 -> node61;
  node62 [label="{ ReLU_5000525 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node63 -> node62;
  node63 [label="{ Dense_5000524 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node59 -> node63;
  node59 [label="{ AddBiasResidualLayerNorm_5000523 }",shape=record];
  node64 -> node59;
  node65 -> node59;
  node64 [label="{ AllReduce_5000522 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node66 -> node64;
  node66 [label="{ TreeIncMultiHeadSelfAttention_5000521 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node65 -> node66;
  node65 [label="{ ResidualLayerNorm_5000520 }",shape=record];
  node67 -> node65;
  node68 -> node65;
  node68 [label="{ AllReduce_5000519 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node69 -> node68;
  node69 [label="{ Dense_5000518 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node70 -> node69;
  node70 [label="{ ReLU_5000517 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node71 -> node70;
  node71 [label="{ Dense_5000516 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node67 -> node71;
  node67 [label="{ AddBiasResidualLayerNorm_5000515 }",shape=record];
  node72 -> node67;
  node73 -> node67;
  node72 [label="{ AllReduce_5000514 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node74 -> node72;
  node75 [label="{ Dense_5000406 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node76 -> node75;
  node77 [label="{ AllReduce_5000407 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node75 -> node77;
  node78 [label="{ ResidualLayerNorm_5000408 }",shape=record];
  node79 -> node78;
  node77 -> node78;
  node80 [label="{ TreeIncMultiHeadSelfAttention_5000409 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node78 -> node80;
  node81 [label="{ AllReduce_5000410 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node80 -> node81;
  node82 [label="{ AddBiasResidualLayerNorm_5000411 }",shape=record];
  node81 -> node82;
  node78 -> node82;
  node83 [label="{ Dense_5000412 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node82 -> node83;
  node84 [label="{ ReLU_5000413 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node83 -> node84;
  node85 [label="{ Dense_5000414 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node84 -> node85;
  node86 [label="{ AllReduce_5000415 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node85 -> node86;
  node87 [label="{ ResidualLayerNorm_5000416 }",shape=record];
  node82 -> node87;
  node86 -> node87;
  node88 [label="{ TreeIncMultiHeadSelfAttention_5000417 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node87 -> node88;
  node89 [label="{ AllReduce_5000418 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node88 -> node89;
  node90 [label="{ AddBiasResidualLayerNorm_5000419 }",shape=record];
  node89 -> node90;
  node87 -> node90;
  node91 [label="{ Dense_5000420 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node90 -> node91;
  node92 [label="{ ReLU_5000421 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node91 -> node92;
  node93 [label="{ Dense_5000422 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node92 -> node93;
  node94 [label="{ AllReduce_5000423 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node93 -> node94;
  node95 [label="{ ResidualLayerNorm_5000424 }",shape=record];
  node90 -> node95;
  node94 -> node95;
  node96 [label="{ TreeIncMultiHeadSelfAttention_5000425 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node95 -> node96;
  node97 [label="{ AllReduce_5000426 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node96 -> node97;
  node98 [label="{ AddBiasResidualLayerNorm_5000427 }",shape=record];
  node97 -> node98;
  node95 -> node98;
  node99 [label="{ Dense_5000428 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node98 -> node99;
  node100 [label="{ ReLU_5000429 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node99 -> node100;
  node101 [label="{ Dense_5000430 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node100 -> node101;
  node102 [label="{ AllReduce_5000431 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node101 -> node102;
  node103 [label="{ ResidualLayerNorm_5000432 }",shape=record];
  node98 -> node103;
  node102 -> node103;
  node104 [label="{ TreeIncMultiHeadSelfAttention_5000433 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node103 -> node104;
  node105 [label="{ AllReduce_5000434 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node104 -> node105;
  node106 [label="{ AddBiasResidualLayerNorm_5000435 }",shape=record];
  node105 -> node106;
  node103 -> node106;
  node107 [label="{ Dense_5000436 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node106 -> node107;
  node108 [label="{ ReLU_5000437 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node107 -> node108;
  node109 [label="{ Dense_5000438 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node108 -> node109;
  node110 [label="{ AllReduce_5000439 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node109 -> node110;
  node111 [label="{ ResidualLayerNorm_5000440 }",shape=record];
  node106 -> node111;
  node110 -> node111;
  node112 [label="{ TreeIncMultiHeadSelfAttention_5000441 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node111 -> node112;
  node113 [label="{ AllReduce_5000442 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node112 -> node113;
  node114 [label="{ AddBiasResidualLayerNorm_5000443 }",shape=record];
  node113 -> node114;
  node111 -> node114;
  node115 [label="{ Dense_5000444 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node114 -> node115;
  node116 [label="{ ReLU_5000445 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node115 -> node116;
  node117 [label="{ Dense_5000446 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node116 -> node117;
  node118 [label="{ AllReduce_5000447 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node117 -> node118;
  node119 [label="{ ResidualLayerNorm_5000448 }",shape=record];
  node114 -> node119;
  node118 -> node119;
  node120 [label="{ TreeIncMultiHeadSelfAttention_5000449 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node119 -> node120;
  node121 [label="{ AllReduce_5000450 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node120 -> node121;
  node122 [label="{ AddBiasResidualLayerNorm_5000451 }",shape=record];
  node121 -> node122;
  node119 -> node122;
  node123 [label="{ Dense_5000452 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node122 -> node123;
  node124 [label="{ ReLU_5000453 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node123 -> node124;
  node125 [label="{ Dense_5000454 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node124 -> node125;
  node126 [label="{ AllReduce_5000455 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node125 -> node126;
  node127 [label="{ ResidualLayerNorm_5000456 }",shape=record];
  node122 -> node127;
  node126 -> node127;
  node128 [label="{ AddBiasResidualLayerNorm_5000587 }",shape=record];
  node0 -> node128;
  node2 -> node128;
  node129 [label="{ Input_5000330 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node130 [label="{ Dense_5000588 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node128 -> node130;
  node131 [label="{ Input_5000331 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node132 [label="{ ReLU_5000589 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node130 -> node132;
  node133 [label="{ Embedding_5000332 | { 5120/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node129 -> node133;
  node134 [label="{ Dense_5000590 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node132 -> node134;
  node135 [label="{ Embedding_5000333 | { 5120/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node131 -> node135;
  node136 [label="{ AllReduce_5000591 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node134 -> node136;
  node137 [label="{ Replicate_5000334 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node133 -> node137;
  node138 [label="{ ResidualLayerNorm_5000592 }",shape=record];
  node128 -> node138;
  node136 -> node138;
  node139 [label="{ Replicate_5000335 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node135 -> node139;
  node140 [label="{ TreeIncMultiHeadSelfAttention_5000593 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node138 -> node140;
  node141 [label="{ ResidualLayerNorm_5000336 }",shape=record];
  node137 -> node141;
  node139 -> node141;
  node142 [label="{ AllReduce_5000594 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node140 -> node142;
  node143 [label="{ TreeIncMultiHeadSelfAttention_5000337 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node141 -> node143;
  node144 [label="{ AddBiasResidualLayerNorm_5000595 }",shape=record];
  node142 -> node144;
  node138 -> node144;
  node145 [label="{ AllReduce_5000338 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node143 -> node145;
  node146 [label="{ Dense_5000596 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node144 -> node146;
  node147 [label="{ AddBiasResidualLayerNorm_5000339 }",shape=record];
  node145 -> node147;
  node141 -> node147;
  node148 [label="{ ReLU_5000597 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node146 -> node148;
  node149 [label="{ Dense_5000340 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node147 -> node149;
  node150 [label="{ Dense_5000598 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node148 -> node150;
  node151 [label="{ ReLU_5000341 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node149 -> node151;
  node152 [label="{ AllReduce_5000599 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node150 -> node152;
  node153 [label="{ Dense_5000342 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node151 -> node153;
  node154 [label="{ ResidualLayerNorm_5000600 }",shape=record];
  node144 -> node154;
  node152 -> node154;
  node155 [label="{ AllReduce_5000343 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node153 -> node155;
  node156 [label="{ AllReduce_5000631 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node157 -> node156;
  node158 [label="{ Dense_5000374 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node159 -> node158;
  node160 [label="{ ResidualLayerNorm_5000632 }",shape=record];
  node161 -> node160;
  node156 -> node160;
  node162 [label="{ AllReduce_5000375 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node158 -> node162;
  node163 [label="{ TreeIncMultiHeadSelfAttention_5000633 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node160 -> node163;
  node164 [label="{ ResidualLayerNorm_5000376 }",shape=record];
  node165 -> node164;
  node162 -> node164;
  node166 [label="{ AllReduce_5000634 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node163 -> node166;
  node167 [label="{ TreeIncMultiHeadSelfAttention_5000377 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node164 -> node167;
  node168 [label="{ AddBiasResidualLayerNorm_5000635 }",shape=record];
  node166 -> node168;
  node160 -> node168;
  node169 [label="{ AllReduce_5000378 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node167 -> node169;
  node170 [label="{ Dense_5000636 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node168 -> node170;
  node171 [label="{ AddBiasResidualLayerNorm_5000379 }",shape=record];
  node169 -> node171;
  node164 -> node171;
  node172 [label="{ ReLU_5000637 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node170 -> node172;
  node173 [label="{ Dense_5000380 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node171 -> node173;
  node174 [label="{ Dense_5000638 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node172 -> node174;
  node175 [label="{ ReLU_5000381 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node173 -> node175;
  node176 [label="{ AllReduce_5000639 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node174 -> node176;
  node177 [label="{ Dense_5000382 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node175 -> node177;
  node178 [label="{ ResidualLayerNorm_5000640 }",shape=record];
  node168 -> node178;
  node176 -> node178;
  node179 [label="{ AllReduce_5000383 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node177 -> node179;
  node180 [label="{ TreeIncMultiHeadSelfAttention_5000641 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node178 -> node180;
  node181 [label="{ ResidualLayerNorm_5000384 }",shape=record];
  node171 -> node181;
  node179 -> node181;
  node182 [label="{ AllReduce_5000642 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node180 -> node182;
  node183 [label="{ TreeIncMultiHeadSelfAttention_5000385 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node181 -> node183;
  node184 [label="{ AddBiasResidualLayerNorm_5000643 }",shape=record];
  node182 -> node184;
  node178 -> node184;
  node185 [label="{ AllReduce_5000386 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node183 -> node185;
  node186 [label="{ Dense_5000644 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node184 -> node186;
  node187 [label="{ AddBiasResidualLayerNorm_5000387 }",shape=record];
  node185 -> node187;
  node181 -> node187;
  node188 [label="{ ReLU_5000645 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node186 -> node188;
  node189 [label="{ Dense_5000388 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node187 -> node189;
  node190 [label="{ Dense_5000646 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node188 -> node190;
  node191 [label="{ ReLU_5000389 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node189 -> node191;
  node76 [label="{ ReLU_5000405 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node192 -> node76;
  node193 [label="{ ArgMax_5000659 | { 1/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node194 -> node193;
  node195 [label="{ AllReduce_5000402 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node196 -> node195;
  node192 [label="{ Dense_5000404 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node79 -> node192;
  node194 [label="{ Combine_5000658 | { dim(0) | deg(4) } }",shape=record];
  node197 -> node194;
  node196 [label="{ TreeIncMultiHeadSelfAttention_5000401 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node198 -> node196;
  node79 [label="{ AddBiasResidualLayerNorm_5000403 }",shape=record];
  node195 -> node79;
  node198 -> node79;
  node197 [label="{ Dense_5000657 | { 50272/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node199 -> node197;
  node198 [label="{ ResidualLayerNorm_5000400 }",shape=record];
  node200 -> node198;
  node201 -> node198;
  node199 [label="{ ResidualLayerNorm_5000656 }",shape=record];
  node202 -> node199;
  node203 -> node199;
  node201 [label="{ AllReduce_5000399 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node204 -> node201;
  node203 [label="{ AllReduce_5000655 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node205 -> node203;
  node204 [label="{ Dense_5000398 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node206 -> node204;
  node205 [label="{ Dense_5000654 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node207 -> node205;
  node206 [label="{ ReLU_5000397 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node208 -> node206;
  node207 [label="{ ReLU_5000653 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node209 -> node207;
  node208 [label="{ Dense_5000396 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node200 -> node208;
  node209 [label="{ Dense_5000652 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node202 -> node209;
  node200 [label="{ AddBiasResidualLayerNorm_5000395 }",shape=record];
  node210 -> node200;
  node211 -> node200;
  node202 [label="{ AddBiasResidualLayerNorm_5000651 }",shape=record];
  node212 -> node202;
  node213 -> node202;
  node210 [label="{ AllReduce_5000394 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node214 -> node210;
  node212 [label="{ AllReduce_5000650 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node215 -> node212;
  node214 [label="{ TreeIncMultiHeadSelfAttention_5000393 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node211 -> node214;
  node215 [label="{ TreeIncMultiHeadSelfAttention_5000649 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node213 -> node215;
  node211 [label="{ ResidualLayerNorm_5000392 }",shape=record];
  node187 -> node211;
  node216 -> node211;
  node213 [label="{ ResidualLayerNorm_5000648 }",shape=record];
  node184 -> node213;
  node217 -> node213;
  node216 [label="{ AllReduce_5000391 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node218 -> node216;
  node217 [label="{ AllReduce_5000647 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node190 -> node217;
  node218 [label="{ Dense_5000390 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node191 -> node218;
  node157 [label="{ Dense_5000630 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node219 -> node157;
  node159 [label="{ ReLU_5000373 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node220 -> node159;
  node219 [label="{ ReLU_5000629 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node221 -> node219;
  node220 [label="{ Dense_5000372 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node165 -> node220;
  node221 [label="{ Dense_5000628 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node161 -> node221;
  node165 [label="{ AddBiasResidualLayerNorm_5000371 }",shape=record];
  node222 -> node165;
  node223 -> node165;
  node161 [label="{ AddBiasResidualLayerNorm_5000627 }",shape=record];
  node224 -> node161;
  node225 -> node161;
  node222 [label="{ AllReduce_5000370 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node226 -> node222;
  node224 [label="{ AllReduce_5000626 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node227 -> node224;
  node226 [label="{ TreeIncMultiHeadSelfAttention_5000369 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node223 -> node226;
  node227 [label="{ TreeIncMultiHeadSelfAttention_5000625 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node225 -> node227;
  node223 [label="{ ResidualLayerNorm_5000368 }",shape=record];
  node228 -> node223;
  node229 -> node223;
  node225 [label="{ ResidualLayerNorm_5000624 }",shape=record];
  node230 -> node225;
  node231 -> node225;
  node229 [label="{ AllReduce_5000367 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node232 -> node229;
  node231 [label="{ AllReduce_5000623 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node233 -> node231;
  node232 [label="{ Dense_5000366 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node234 -> node232;
  node233 [label="{ Dense_5000622 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node235 -> node233;
  node234 [label="{ ReLU_5000365 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node236 -> node234;
  node235 [label="{ ReLU_5000621 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node237 -> node235;
  node236 [label="{ Dense_5000364 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node228 -> node236;
  node237 [label="{ Dense_5000620 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node230 -> node237;
  node228 [label="{ AddBiasResidualLayerNorm_5000363 }",shape=record];
  node238 -> node228;
  node239 -> node228;
  node230 [label="{ AddBiasResidualLayerNorm_5000619 }",shape=record];
  node240 -> node230;
  node241 -> node230;
  node238 [label="{ AllReduce_5000362 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node242 -> node238;
  node240 [label="{ AllReduce_5000618 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node243 -> node240;
  node242 [label="{ TreeIncMultiHeadSelfAttention_5000361 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node239 -> node242;
  node243 [label="{ TreeIncMultiHeadSelfAttention_5000617 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node241 -> node243;
  node239 [label="{ ResidualLayerNorm_5000360 }",shape=record];
  node244 -> node239;
  node245 -> node239;
  node241 [label="{ ResidualLayerNorm_5000616 }",shape=record];
  node246 -> node241;
  node247 -> node241;
  node245 [label="{ AllReduce_5000359 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node248 -> node245;
  node247 [label="{ AllReduce_5000615 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node249 -> node247;
  node248 [label="{ Dense_5000358 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node250 -> node248;
  node249 [label="{ Dense_5000614 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node251 -> node249;
  node250 [label="{ ReLU_5000357 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node252 -> node250;
  node251 [label="{ ReLU_5000613 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node253 -> node251;
  node252 [label="{ Dense_5000356 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node244 -> node252;
  node253 [label="{ Dense_5000612 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node246 -> node253;
  node244 [label="{ AddBiasResidualLayerNorm_5000355 }",shape=record];
  node254 -> node244;
  node255 -> node244;
  node246 [label="{ AddBiasResidualLayerNorm_5000611 }",shape=record];
  node256 -> node246;
  node257 -> node246;
  node254 [label="{ AllReduce_5000354 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node258 -> node254;
  node256 [label="{ AllReduce_5000610 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node259 -> node256;
  node258 [label="{ TreeIncMultiHeadSelfAttention_5000353 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node255 -> node258;
  node259 [label="{ TreeIncMultiHeadSelfAttention_5000609 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node257 -> node259;
  node255 [label="{ ResidualLayerNorm_5000352 }",shape=record];
  node260 -> node255;
  node261 -> node255;
  node257 [label="{ ResidualLayerNorm_5000608 }",shape=record];
  node262 -> node257;
  node263 -> node257;
  node261 [label="{ AllReduce_5000351 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node264 -> node261;
  node263 [label="{ AllReduce_5000607 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node265 -> node263;
  node264 [label="{ Dense_5000350 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node266 -> node264;
  node265 [label="{ Dense_5000606 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node267 -> node265;
  node266 [label="{ ReLU_5000349 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node268 -> node266;
  node267 [label="{ ReLU_5000605 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node269 -> node267;
  node268 [label="{ Dense_5000348 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node260 -> node268;
  node269 [label="{ Dense_5000604 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node262 -> node269;
  node260 [label="{ AddBiasResidualLayerNorm_5000347 }",shape=record];
  node270 -> node260;
  node271 -> node260;
  node262 [label="{ AddBiasResidualLayerNorm_5000603 }",shape=record];
  node272 -> node262;
  node154 -> node262;
  node270 [label="{ AllReduce_5000346 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node273 -> node270;
  node272 [label="{ AllReduce_5000602 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node274 -> node272;
  node273 [label="{ TreeIncMultiHeadSelfAttention_5000345 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node271 -> node273;
  node274 [label="{ TreeIncMultiHeadSelfAttention_5000601 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node154 -> node274;
  node271 [label="{ ResidualLayerNorm_5000344 }",shape=record];
  node147 -> node271;
  node155 -> node271;
  node275 [label="{ TreeIncMultiHeadSelfAttention_5000457 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node127 -> node275;
  node276 [label="{ AllReduce_5000458 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node275 -> node276;
  node277 [label="{ AddBiasResidualLayerNorm_5000459 }",shape=record];
  node276 -> node277;
  node127 -> node277;
  node278 [label="{ Dense_5000460 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node277 -> node278;
  node279 [label="{ ReLU_5000461 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node278 -> node279;
  node280 [label="{ Dense_5000462 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node279 -> node280;
  node281 [label="{ AllReduce_5000463 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node280 -> node281;
  node282 [label="{ ResidualLayerNorm_5000464 }",shape=record];
  node277 -> node282;
  node281 -> node282;
  node283 [label="{ TreeIncMultiHeadSelfAttention_5000465 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node282 -> node283;
  node284 [label="{ AllReduce_5000466 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node283 -> node284;
  node285 [label="{ AddBiasResidualLayerNorm_5000467 }",shape=record];
  node284 -> node285;
  node282 -> node285;
  node286 [label="{ Dense_5000468 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node285 -> node286;
  node287 [label="{ ReLU_5000469 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node286 -> node287;
  node288 [label="{ Dense_5000470 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node287 -> node288;
  node289 [label="{ AllReduce_5000471 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node288 -> node289;
  node290 [label="{ ResidualLayerNorm_5000472 }",shape=record];
  node285 -> node290;
  node289 -> node290;
  node291 [label="{ TreeIncMultiHeadSelfAttention_5000473 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node290 -> node291;
  node292 [label="{ AllReduce_5000474 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node291 -> node292;
  node293 [label="{ AddBiasResidualLayerNorm_5000475 }",shape=record];
  node292 -> node293;
  node290 -> node293;
  node294 [label="{ Dense_5000476 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node293 -> node294;
  node295 [label="{ ReLU_5000477 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node294 -> node295;
  node296 [label="{ Dense_5000478 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node295 -> node296;
  node297 [label="{ AllReduce_5000479 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node296 -> node297;
  node298 [label="{ ResidualLayerNorm_5000480 }",shape=record];
  node293 -> node298;
  node297 -> node298;
  node299 [label="{ TreeIncMultiHeadSelfAttention_5000481 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node298 -> node299;
  node300 [label="{ AllReduce_5000482 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node299 -> node300;
  node301 [label="{ AddBiasResidualLayerNorm_5000483 }",shape=record];
  node300 -> node301;
  node298 -> node301;
  node302 [label="{ Dense_5000484 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node301 -> node302;
  node303 [label="{ ReLU_5000485 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node302 -> node303;
  node304 [label="{ Dense_5000486 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node303 -> node304;
  node305 [label="{ AllReduce_5000487 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node304 -> node305;
  node306 [label="{ ResidualLayerNorm_5000488 }",shape=record];
  node301 -> node306;
  node305 -> node306;
  node307 [label="{ TreeIncMultiHeadSelfAttention_5000489 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node306 -> node307;
  node308 [label="{ AllReduce_5000490 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node307 -> node308;
  node309 [label="{ AddBiasResidualLayerNorm_5000491 }",shape=record];
  node308 -> node309;
  node306 -> node309;
  node310 [label="{ Dense_5000492 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node309 -> node310;
  node311 [label="{ ReLU_5000493 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node310 -> node311;
  node312 [label="{ Dense_5000494 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node311 -> node312;
  node313 [label="{ AllReduce_5000495 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node312 -> node313;
  node314 [label="{ ResidualLayerNorm_5000496 }",shape=record];
  node309 -> node314;
  node313 -> node314;
  node315 [label="{ TreeIncMultiHeadSelfAttention_5000497 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node314 -> node315;
  node316 [label="{ AllReduce_5000498 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node315 -> node316;
  node317 [label="{ AddBiasResidualLayerNorm_5000499 }",shape=record];
  node316 -> node317;
  node314 -> node317;
  node318 [label="{ Dense_5000500 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node317 -> node318;
  node319 [label="{ ReLU_5000501 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node318 -> node319;
  node320 [label="{ Dense_5000502 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node319 -> node320;
  node321 [label="{ AllReduce_5000503 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node320 -> node321;
  node322 [label="{ ResidualLayerNorm_5000504 }",shape=record];
  node317 -> node322;
  node321 -> node322;
  node323 [label="{ TreeIncMultiHeadSelfAttention_5000505 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node322 -> node323;
  node324 [label="{ AllReduce_5000506 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node323 -> node324;
  node325 [label="{ AddBiasResidualLayerNorm_5000507 }",shape=record];
  node324 -> node325;
  node322 -> node325;
  node326 [label="{ Dense_5000508 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node325 -> node326;
  node327 [label="{ ReLU_5000509 | { 20480/4 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node326 -> node327;
  node328 [label="{ Dense_5000510 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node327 -> node328;
  node329 [label="{ AllReduce_5000511 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node328 -> node329;
  node73 [label="{ ResidualLayerNorm_5000512 }",shape=record];
  node325 -> node73;
  node329 -> node73;
  node74 [label="{ TreeIncMultiHeadSelfAttention_5000513 | { 5120/1 | 1/1 | 256/1 | 4/4 } }",shape=record];
  node73 -> node74;
}
ndim(1) dims[1 0 0 0]
ndim(1) dims[4 0 0 0]
operator[0]: type(Input) guid(2000580)
	outputs[0] region(8,1,1)
operator[1]: type(Input) guid(2000581)
	outputs[0] region(10,2,2)
operator[2]: type(Weight) guid(2000583)
	outputs[0] region(12,3,3)
operator[3]: type(FusedOp) guid(2001355)
	inputs[0] region(8,1,1)
	inputs[1] region(10,2,2)
	outputs[0] region(14,4,4)
	outputs[1] region(18,6,6)
	weights[0] region(12,3,3)
	weights[1] region(16,5,5)
operator[4]: type(Weight) guid(2000585)
	outputs[0] region(16,5,5)
operator[5]: type(Replicate) guid(2000586)
	inputs[0] region(14,4,4)
	outputs[0] region(21,7,7)
operator[6]: type(Replicate) guid(2000587)
	inputs[0] region(18,6,6)
	outputs[0] region(26,8,8)
operator[7]: type(Weight) guid(2000589)
	outputs[0] region(31,9,9)
operator[8]: type(Weight) guid(2000590)
	outputs[0] region(36,10,10)
operator[9]: type(FusedOp) guid(2001356)
	inputs[0] region(21,7,7)
	inputs[1] region(26,8,8)
	outputs[0] region(41,11,11)
	outputs[1] region(46,12,12)
	outputs[2] region(61,15,15)
	outputs[3] region(66,16,16)
	outputs[4] region(86,20,20)
	outputs[5] region(91,21,21)
	outputs[6] region(106,24,24)
	outputs[7] region(111,25,25)
	outputs[8] region(126,28,28)
	outputs[9] region(131,29,29)
	outputs[10] region(146,32,32)
	outputs[11] region(151,33,33)
	outputs[12] region(166,36,36)
	outputs[13] region(171,37,37)
	outputs[14] region(191,41,41)
	outputs[15] region(196,42,42)
	outputs[16] region(211,45,45)
	outputs[17] region(216,46,46)
	outputs[18] region(231,49,49)
	outputs[19] region(236,50,50)
	outputs[20] region(251,53,53)
	outputs[21] region(256,54,54)
	outputs[22] region(271,57,57)
	outputs[23] region(276,58,58)
	outputs[24] region(296,62,62)
	outputs[25] region(301,63,63)
	outputs[26] region(316,66,66)
	outputs[27] region(321,67,67)
	outputs[28] region(336,70,70)
	outputs[29] region(341,71,71)
	outputs[30] region(356,74,74)
	outputs[31] region(361,75,75)
	outputs[32] region(376,78,78)
	outputs[33] region(381,79,79)
	outputs[34] region(401,83,83)
	outputs[35] region(406,84,84)
	outputs[36] region(421,87,87)
	outputs[37] region(426,88,88)
	outputs[38] region(441,91,91)
	outputs[39] region(446,92,92)
	outputs[40] region(461,95,95)
	outputs[41] region(466,96,96)
	outputs[42] region(481,99,99)
	outputs[43] region(486,100,100)
	outputs[44] region(506,104,104)
	outputs[45] region(511,105,105)
	outputs[46] region(526,108,108)
	outputs[47] region(531,109,109)
	outputs[48] region(546,112,112)
	outputs[49] region(551,113,113)
	outputs[50] region(566,116,116)
	outputs[51] region(571,117,117)
	outputs[52] region(586,120,120)
	outputs[53] region(591,121,121)
	outputs[54] region(611,125,125)
	outputs[55] region(616,126,126)
	outputs[56] region(631,129,129)
	outputs[57] region(636,130,130)
	outputs[58] region(651,133,133)
	outputs[59] region(656,134,134)
	outputs[60] region(671,137,137)
	outputs[61] region(676,138,138)
	outputs[62] region(691,141,141)
	outputs[63] region(696,142,142)
	outputs[64] region(716,146,146)
	outputs[65] region(721,147,147)
	outputs[66] region(736,150,150)
	outputs[67] region(741,151,151)
	outputs[68] region(756,154,154)
	outputs[69] region(761,155,155)
	outputs[70] region(776,158,158)
	outputs[71] region(781,159,159)
	outputs[72] region(796,162,162)
	outputs[73] region(801,163,163)
	outputs[74] region(821,167,167)
	outputs[75] region(826,168,168)
	outputs[76] region(841,171,171)
	outputs[77] region(846,172,172)
	outputs[78] region(861,175,175)
	outputs[79] region(866,176,176)
	outputs[80] region(881,179,179)
	outputs[81] region(886,180,180)
	outputs[82] region(901,183,183)
	outputs[83] region(906,184,184)
	outputs[84] region(926,188,188)
	outputs[85] region(931,189,189)
	outputs[86] region(946,192,192)
	outputs[87] region(951,193,193)
	outputs[88] region(966,196,196)
	outputs[89] region(971,197,197)
	outputs[90] region(986,200,200)
	outputs[91] region(991,201,201)
	outputs[92] region(1006,204,204)
	outputs[93] region(1011,205,205)
	outputs[94] region(1031,209,209)
	outputs[95] region(1036,210,210)
	outputs[96] region(1051,213,213)
	outputs[97] region(1056,214,214)
	outputs[98] region(1071,217,217)
	outputs[99] region(1076,218,218)
	outputs[100] region(1091,221,221)
	outputs[101] region(1096,222,222)
	outputs[102] region(1111,225,225)
	outputs[103] region(1116,226,226)
	outputs[104] region(1136,230,230)
	outputs[105] region(1141,231,231)
	outputs[106] region(1156,234,234)
	outputs[107] region(1161,235,235)
	outputs[108] region(1176,238,238)
	outputs[109] region(1181,239,239)
	outputs[110] region(1196,242,242)
	outputs[111] region(1201,243,243)
	outputs[112] region(1216,246,246)
	outputs[113] region(1221,247,247)
	outputs[114] region(1241,251,251)
	outputs[115] region(1246,252,252)
	outputs[116] region(1261,255,255)
	outputs[117] region(1266,256,256)
	outputs[118] region(1281,259,259)
	outputs[119] region(1286,260,260)
	outputs[120] region(1301,263,263)
	outputs[121] region(1306,264,264)
	outputs[122] region(1321,267,267)
	outputs[123] region(1326,268,268)
	outputs[124] region(1346,272,272)
	outputs[125] region(1351,273,273)
	outputs[126] region(1366,276,276)
	outputs[127] region(1371,277,277)
	outputs[128] region(1386,280,280)
	outputs[129] region(1391,281,281)
	outputs[130] region(1406,284,284)
	outputs[131] region(1411,285,285)
	outputs[132] region(1426,288,288)
	outputs[133] region(1431,289,289)
	outputs[134] region(1451,293,293)
	outputs[135] region(1456,294,294)
	outputs[136] region(1471,297,297)
	outputs[137] region(1476,298,298)
	outputs[138] region(1491,301,301)
	outputs[139] region(1496,302,302)
	outputs[140] region(1511,305,305)
	outputs[141] region(1516,306,306)
	outputs[142] region(1531,309,309)
	outputs[143] region(1536,310,310)
	outputs[144] region(1556,314,314)
	outputs[145] region(1561,315,315)
	outputs[146] region(1576,318,318)
	outputs[147] region(1581,319,319)
	outputs[148] region(1596,322,322)
	outputs[149] region(1601,323,323)
	outputs[150] region(1616,326,326)
	outputs[151] region(1621,327,327)
	outputs[152] region(1636,330,330)
	outputs[153] region(1641,331,331)
	outputs[154] region(1661,335,335)
	outputs[155] region(1666,336,336)
	outputs[156] region(1681,339,339)
	outputs[157] region(1686,340,340)
	outputs[158] region(1701,343,343)
	outputs[159] region(1706,344,344)
	outputs[160] region(1721,347,347)
	outputs[161] region(1726,348,348)
	outputs[162] region(1741,351,351)
	outputs[163] region(1746,352,352)
	outputs[164] region(1766,356,356)
	outputs[165] region(1771,357,357)
	outputs[166] region(1786,360,360)
	outputs[167] region(1791,361,361)
	outputs[168] region(1806,364,364)
	outputs[169] region(1811,365,365)
	outputs[170] region(1826,368,368)
	outputs[171] region(1831,369,369)
	outputs[172] region(1846,372,372)
	outputs[173] region(1851,373,373)
	outputs[174] region(1871,377,377)
	outputs[175] region(1876,378,378)
	outputs[176] region(1891,381,381)
	outputs[177] region(1896,382,382)
	outputs[178] region(1911,385,385)
	outputs[179] region(1916,386,386)
	outputs[180] region(1931,389,389)
	outputs[181] region(1936,390,390)
	outputs[182] region(1951,393,393)
	outputs[183] region(1956,394,394)
	outputs[184] region(1976,398,398)
	outputs[185] region(1981,399,399)
	outputs[186] region(1996,402,402)
	outputs[187] region(2001,403,403)
	outputs[188] region(2016,406,406)
	outputs[189] region(2021,407,407)
	outputs[190] region(2036,410,410)
	outputs[191] region(2041,411,411)
	outputs[192] region(2056,414,414)
	outputs[193] region(2061,415,415)
	outputs[194] region(2081,419,419)
	outputs[195] region(2086,420,420)
	outputs[196] region(2101,423,423)
	outputs[197] region(2106,424,424)
	outputs[198] region(2121,427,427)
	outputs[199] region(2126,428,428)
	outputs[200] region(2141,431,431)
	outputs[201] region(2146,432,432)
	outputs[202] region(2161,435,435)
	outputs[203] region(2166,436,436)
	outputs[204] region(2186,440,440)
	outputs[205] region(2191,441,441)
	outputs[206] region(2206,444,444)
	outputs[207] region(2211,445,445)
	outputs[208] region(2226,448,448)
	outputs[209] region(2231,449,449)
	outputs[210] region(2246,452,452)
	outputs[211] region(2251,453,453)
	outputs[212] region(2266,456,456)
	outputs[213] region(2271,457,457)
	outputs[214] region(2291,461,461)
	outputs[215] region(2296,462,462)
	outputs[216] region(2311,465,465)
	outputs[217] region(2316,466,466)
	outputs[218] region(2331,469,469)
	outputs[219] region(2336,470,470)
	outputs[220] region(2351,473,473)
	outputs[221] region(2356,474,474)
	outputs[222] region(2371,477,477)
	outputs[223] region(2376,478,478)
	outputs[224] region(2396,482,482)
	outputs[225] region(2401,483,483)
	outputs[226] region(2416,486,486)
	outputs[227] region(2421,487,487)
	outputs[228] region(2436,490,490)
	outputs[229] region(2441,491,491)
	outputs[230] region(2456,494,494)
	outputs[231] region(2461,495,495)
	outputs[232] region(2476,498,498)
	outputs[233] region(2481,499,499)
	outputs[234] region(2501,503,503)
	outputs[235] region(2506,504,504)
	outputs[236] region(2521,507,507)
	outputs[237] region(2526,508,508)
	outputs[238] region(2541,511,511)
	outputs[239] region(2546,512,512)
	outputs[240] region(2561,515,515)
	outputs[241] region(2566,516,516)
	outputs[242] region(2581,519,519)
	outputs[243] region(2586,520,520)
	outputs[244] region(2606,524,524)
	outputs[245] region(2611,525,525)
	outputs[246] region(2626,528,528)
	outputs[247] region(2631,529,529)
	outputs[248] region(2646,532,532)
	outputs[249] region(2651,533,533)
	outputs[250] region(2666,536,536)
	outputs[251] region(2671,537,537)
	outputs[252] region(2686,540,540)
	outputs[253] region(2691,541,541)
	outputs[254] region(2711,545,545)
	outputs[255] region(2716,546,546)
	outputs[256] region(2731,549,549)
	outputs[257] region(2736,550,550)
	outputs[258] region(2751,553,553)
	outputs[259] region(2756,554,554)
	outputs[260] region(2771,557,557)
	outputs[261] region(2776,558,558)
	outputs[262] region(2791,561,561)
	outputs[263] region(2796,562,562)
	outputs[264] region(2816,566,566)
	outputs[265] region(2821,567,567)
	outputs[266] region(2836,570,570)
	outputs[267] region(2841,571,571)
	outputs[268] region(2856,574,574)
	outputs[269] region(2861,575,575)
	outputs[270] region(2876,578,578)
	outputs[271] region(2881,579,579)
	outputs[272] region(2896,582,582)
	outputs[273] region(2901,583,583)
	outputs[274] region(2921,587,587)
	outputs[275] region(2926,588,588)
	outputs[276] region(2941,591,591)
	outputs[277] region(2946,592,592)
	outputs[278] region(2961,595,595)
	outputs[279] region(2966,596,596)
	outputs[280] region(2981,599,599)
	outputs[281] region(2986,600,600)
	outputs[282] region(3001,603,603)
	outputs[283] region(3006,604,604)
	outputs[284] region(3026,608,608)
	outputs[285] region(3031,609,609)
	outputs[286] region(3046,612,612)
	outputs[287] region(3051,613,613)
	outputs[288] region(3066,616,616)
	outputs[289] region(3071,617,617)
	outputs[290] region(3086,620,620)
	outputs[291] region(3091,621,621)
	outputs[292] region(3106,624,624)
	outputs[293] region(3111,625,625)
	outputs[294] region(3131,629,629)
	outputs[295] region(3136,630,630)
	outputs[296] region(3151,633,633)
	outputs[297] region(3156,634,634)
	outputs[298] region(3171,637,637)
	outputs[299] region(3176,638,638)
	outputs[300] region(3191,641,641)
	outputs[301] region(3196,642,642)
	outputs[302] region(3211,645,645)
	outputs[303] region(3216,646,646)
	outputs[304] region(3236,650,650)
	outputs[305] region(3241,651,651)
	outputs[306] region(3256,654,654)
	outputs[307] region(3261,655,655)
	outputs[308] region(3276,658,658)
	outputs[309] region(3281,659,659)
	outputs[310] region(3296,662,662)
	outputs[311] region(3301,663,663)
	outputs[312] region(3316,666,666)
	outputs[313] region(3321,667,667)
	outputs[314] region(3341,671,671)
	outputs[315] region(3346,672,672)
	outputs[316] region(3361,675,675)
	outputs[317] region(3366,676,676)
	outputs[318] region(3381,679,679)
	outputs[319] region(3386,680,680)
	outputs[320] region(3401,683,683)
	outputs[321] region(3406,684,684)
	outputs[322] region(3421,687,687)
	outputs[323] region(3426,688,688)
	outputs[324] region(3446,692,692)
	outputs[325] region(3451,693,693)
	outputs[326] region(3466,696,696)
	outputs[327] region(3471,697,697)
	outputs[328] region(3486,700,700)
	outputs[329] region(3491,701,701)
	outputs[330] region(3506,704,704)
	outputs[331] region(3511,705,705)
	outputs[332] region(3526,708,708)
	outputs[333] region(3531,709,709)
	outputs[334] region(3551,713,713)
	outputs[335] region(3556,714,714)
	outputs[336] region(3571,717,717)
	outputs[337] region(3576,718,718)
	outputs[338] region(3591,721,721)
	outputs[339] region(3596,722,722)
	outputs[340] region(3611,725,725)
	outputs[341] region(3616,726,726)
	outputs[342] region(3631,729,729)
	outputs[343] region(3636,730,730)
	outputs[344] region(3656,734,734)
	outputs[345] region(3661,735,735)
	outputs[346] region(3676,738,738)
	outputs[347] region(3681,739,739)
	outputs[348] region(3696,742,742)
	outputs[349] region(3701,743,743)
	outputs[350] region(3716,746,746)
	outputs[351] region(3721,747,747)
	outputs[352] region(3736,750,750)
	outputs[353] region(3741,751,751)
	outputs[354] region(3761,755,755)
	outputs[355] region(3766,756,756)
	outputs[356] region(3781,759,759)
	outputs[357] region(3786,760,760)
	outputs[358] region(3801,763,763)
	outputs[359] region(3806,764,764)
	outputs[360] region(3821,767,767)
	outputs[361] region(3826,768,768)
	outputs[362] region(3841,771,771)
	outputs[363] region(3846,772,772)
	outputs[364] region(3866,776,776)
	outputs[365] region(3871,777,777)
	outputs[366] region(3886,780,780)
	outputs[367] region(3891,781,781)
	outputs[368] region(3906,784,784)
	outputs[369] region(3911,785,785)
	outputs[370] region(3926,788,788)
	outputs[371] region(3931,789,789)
	outputs[372] region(3946,792,792)
	outputs[373] region(3951,793,793)
	outputs[374] region(3971,797,797)
	outputs[375] region(3976,798,798)
	outputs[376] region(3991,801,801)
	outputs[377] region(3996,802,802)
	outputs[378] region(4011,805,805)
	outputs[379] region(4016,806,806)
	outputs[380] region(4031,809,809)
	outputs[381] region(4036,810,810)
	outputs[382] region(4051,813,813)
	outputs[383] region(4056,814,814)
	outputs[384] region(4076,818,818)
	outputs[385] region(4081,819,819)
	outputs[386] region(4096,822,822)
	outputs[387] region(4101,823,823)
	outputs[388] region(4116,826,826)
	outputs[389] region(4121,827,827)
	outputs[390] region(4136,830,830)
	outputs[391] region(4141,831,831)
	outputs[392] region(4156,834,834)
	outputs[393] region(4161,835,835)
	outputs[394] region(4181,839,839)
	outputs[395] region(4186,840,840)
	outputs[396] region(4201,843,843)
	outputs[397] region(4206,844,844)
	outputs[398] region(4221,847,847)
	outputs[399] region(4226,848,848)
	outputs[400] region(4241,851,851)
	outputs[401] region(4246,852,852)
	outputs[402] region(4256,854,854)
	weights[0] region(31,9,9)
	weights[1] region(36,10,10)
	weights[2] region(51,13,13)
	weights[3] region(56,14,14)
	weights[4] region(71,17,17)
	weights[5] region(76,18,18)
	weights[6] region(81,19,19)
	weights[7] region(96,22,22)
	weights[8] region(101,23,23)
	weights[9] region(116,26,26)
	weights[10] region(121,27,27)
	weights[11] region(136,30,30)
	weights[12] region(141,31,31)
	weights[13] region(156,34,34)
	weights[14] region(161,35,35)
	weights[15] region(176,38,38)
	weights[16] region(181,39,39)
	weights[17] region(186,40,40)
	weights[18] region(201,43,43)
	weights[19] region(206,44,44)
	weights[20] region(221,47,47)
	weights[21] region(226,48,48)
	weights[22] region(241,51,51)
	weights[23] region(246,52,52)
	weights[24] region(261,55,55)
	weights[25] region(266,56,56)
	weights[26] region(281,59,59)
	weights[27] region(286,60,60)
	weights[28] region(291,61,61)
	weights[29] region(306,64,64)
	weights[30] region(311,65,65)
	weights[31] region(326,68,68)
	weights[32] region(331,69,69)
	weights[33] region(346,72,72)
	weights[34] region(351,73,73)
	weights[35] region(366,76,76)
	weights[36] region(371,77,77)
	weights[37] region(386,80,80)
	weights[38] region(391,81,81)
	weights[39] region(396,82,82)
	weights[40] region(411,85,85)
	weights[41] region(416,86,86)
	weights[42] region(431,89,89)
	weights[43] region(436,90,90)
	weights[44] region(451,93,93)
	weights[45] region(456,94,94)
	weights[46] region(471,97,97)
	weights[47] region(476,98,98)
	weights[48] region(491,101,101)
	weights[49] region(496,102,102)
	weights[50] region(501,103,103)
	weights[51] region(516,106,106)
	weights[52] region(521,107,107)
	weights[53] region(536,110,110)
	weights[54] region(541,111,111)
	weights[55] region(556,114,114)
	weights[56] region(561,115,115)
	weights[57] region(576,118,118)
	weights[58] region(581,119,119)
	weights[59] region(596,122,122)
	weights[60] region(601,123,123)
	weights[61] region(606,124,124)
	weights[62] region(621,127,127)
	weights[63] region(626,128,128)
	weights[64] region(641,131,131)
	weights[65] region(646,132,132)
	weights[66] region(661,135,135)
	weights[67] region(666,136,136)
	weights[68] region(681,139,139)
	weights[69] region(686,140,140)
	weights[70] region(701,143,143)
	weights[71] region(706,144,144)
	weights[72] region(711,145,145)
	weights[73] region(726,148,148)
	weights[74] region(731,149,149)
	weights[75] region(746,152,152)
	weights[76] region(751,153,153)
	weights[77] region(766,156,156)
	weights[78] region(771,157,157)
	weights[79] region(786,160,160)
	weights[80] region(791,161,161)
	weights[81] region(806,164,164)
	weights[82] region(811,165,165)
	weights[83] region(816,166,166)
	weights[84] region(831,169,169)
	weights[85] region(836,170,170)
	weights[86] region(851,173,173)
	weights[87] region(856,174,174)
	weights[88] region(871,177,177)
	weights[89] region(876,178,178)
	weights[90] region(891,181,181)
	weights[91] region(896,182,182)
	weights[92] region(911,185,185)
	weights[93] region(916,186,186)
	weights[94] region(921,187,187)
	weights[95] region(936,190,190)
	weights[96] region(941,191,191)
	weights[97] region(956,194,194)
	weights[98] region(961,195,195)
	weights[99] region(976,198,198)
	weights[100] region(981,199,199)
	weights[101] region(996,202,202)
	weights[102] region(1001,203,203)
	weights[103] region(1016,206,206)
	weights[104] region(1021,207,207)
	weights[105] region(1026,208,208)
	weights[106] region(1041,211,211)
	weights[107] region(1046,212,212)
	weights[108] region(1061,215,215)
	weights[109] region(1066,216,216)
	weights[110] region(1081,219,219)
	weights[111] region(1086,220,220)
	weights[112] region(1101,223,223)
	weights[113] region(1106,224,224)
	weights[114] region(1121,227,227)
	weights[115] region(1126,228,228)
	weights[116] region(1131,229,229)
	weights[117] region(1146,232,232)
	weights[118] region(1151,233,233)
	weights[119] region(1166,236,236)
	weights[120] region(1171,237,237)
	weights[121] region(1186,240,240)
	weights[122] region(1191,241,241)
	weights[123] region(1206,244,244)
	weights[124] region(1211,245,245)
	weights[125] region(1226,248,248)
	weights[126] region(1231,249,249)
	weights[127] region(1236,250,250)
	weights[128] region(1251,253,253)
	weights[129] region(1256,254,254)
	weights[130] region(1271,257,257)
	weights[131] region(1276,258,258)
	weights[132] region(1291,261,261)
	weights[133] region(1296,262,262)
	weights[134] region(1311,265,265)
	weights[135] region(1316,266,266)
	weights[136] region(1331,269,269)
	weights[137] region(1336,270,270)
	weights[138] region(1341,271,271)
	weights[139] region(1356,274,274)
	weights[140] region(1361,275,275)
	weights[141] region(1376,278,278)
	weights[142] region(1381,279,279)
	weights[143] region(1396,282,282)
	weights[144] region(1401,283,283)
	weights[145] region(1416,286,286)
	weights[146] region(1421,287,287)
	weights[147] region(1436,290,290)
	weights[148] region(1441,291,291)
	weights[149] region(1446,292,292)
	weights[150] region(1461,295,295)
	weights[151] region(1466,296,296)
	weights[152] region(1481,299,299)
	weights[153] region(1486,300,300)
	weights[154] region(1501,303,303)
	weights[155] region(1506,304,304)
	weights[156] region(1521,307,307)
	weights[157] region(1526,308,308)
	weights[158] region(1541,311,311)
	weights[159] region(1546,312,312)
	weights[160] region(1551,313,313)
	weights[161] region(1566,316,316)
	weights[162] region(1571,317,317)
	weights[163] region(1586,320,320)
	weights[164] region(1591,321,321)
	weights[165] region(1606,324,324)
	weights[166] region(1611,325,325)
	weights[167] region(1626,328,328)
	weights[168] region(1631,329,329)
	weights[169] region(1646,332,332)
	weights[170] region(1651,333,333)
	weights[171] region(1656,334,334)
	weights[172] region(1671,337,337)
	weights[173] region(1676,338,338)
	weights[174] region(1691,341,341)
	weights[175] region(1696,342,342)
	weights[176] region(1711,345,345)
	weights[177] region(1716,346,346)
	weights[178] region(1731,349,349)
	weights[179] region(1736,350,350)
	weights[180] region(1751,353,353)
	weights[181] region(1756,354,354)
	weights[182] region(1761,355,355)
	weights[183] region(1776,358,358)
	weights[184] region(1781,359,359)
	weights[185] region(1796,362,362)
	weights[186] region(1801,363,363)
	weights[187] region(1816,366,366)
	weights[188] region(1821,367,367)
	weights[189] region(1836,370,370)
	weights[190] region(1841,371,371)
	weights[191] region(1856,374,374)
	weights[192] region(1861,375,375)
	weights[193] region(1866,376,376)
	weights[194] region(1881,379,379)
	weights[195] region(1886,380,380)
	weights[196] region(1901,383,383)
	weights[197] region(1906,384,384)
	weights[198] region(1921,387,387)
	weights[199] region(1926,388,388)
	weights[200] region(1941,391,391)
	weights[201] region(1946,392,392)
	weights[202] region(1961,395,395)
	weights[203] region(1966,396,396)
	weights[204] region(1971,397,397)
	weights[205] region(1986,400,400)
	weights[206] region(1991,401,401)
	weights[207] region(2006,404,404)
	weights[208] region(2011,405,405)
	weights[209] region(2026,408,408)
	weights[210] region(2031,409,409)
	weights[211] region(2046,412,412)
	weights[212] region(2051,413,413)
	weights[213] region(2066,416,416)
	weights[214] region(2071,417,417)
	weights[215] region(2076,418,418)
	weights[216] region(2091,421,421)
	weights[217] region(2096,422,422)
	weights[218] region(2111,425,425)
	weights[219] region(2116,426,426)
	weights[220] region(2131,429,429)
	weights[221] region(2136,430,430)
	weights[222] region(2151,433,433)
	weights[223] region(2156,434,434)
	weights[224] region(2171,437,437)
	weights[225] region(2176,438,438)
	weights[226] region(2181,439,439)
	weights[227] region(2196,442,442)
	weights[228] region(2201,443,443)
	weights[229] region(2216,446,446)
	weights[230] region(2221,447,447)
	weights[231] region(2236,450,450)
	weights[232] region(2241,451,451)
	weights[233] region(2256,454,454)
	weights[234] region(2261,455,455)
	weights[235] region(2276,458,458)
	weights[236] region(2281,459,459)
	weights[237] region(2286,460,460)
	weights[238] region(2301,463,463)
	weights[239] region(2306,464,464)
	weights[240] region(2321,467,467)
	weights[241] region(2326,468,468)
	weights[242] region(2341,471,471)
	weights[243] region(2346,472,472)
	weights[244] region(2361,475,475)
	weights[245] region(2366,476,476)
	weights[246] region(2381,479,479)
	weights[247] region(2386,480,480)
	weights[248] region(2391,481,481)
	weights[249] region(2406,484,484)
	weights[250] region(2411,485,485)
	weights[251] region(2426,488,488)
	weights[252] region(2431,489,489)
	weights[253] region(2446,492,492)
	weights[254] region(2451,493,493)
	weights[255] region(2466,496,496)
	weights[256] region(2471,497,497)
	weights[257] region(2486,500,500)
	weights[258] region(2491,501,501)
	weights[259] region(2496,502,502)
	weights[260] region(2511,505,505)
	weights[261] region(2516,506,506)
	weights[262] region(2531,509,509)
	weights[263] region(2536,510,510)
	weights[264] region(2551,513,513)
	weights[265] region(2556,514,514)
	weights[266] region(2571,517,517)
	weights[267] region(2576,518,518)
	weights[268] region(2591,521,521)
	weights[269] region(2596,522,522)
	weights[270] region(2601,523,523)
	weights[271] region(2616,526,526)
	weights[272] region(2621,527,527)
	weights[273] region(2636,530,530)
	weights[274] region(2641,531,531)
	weights[275] region(2656,534,534)
	weights[276] region(2661,535,535)
	weights[277] region(2676,538,538)
	weights[278] region(2681,539,539)
	weights[279] region(2696,542,542)
	weights[280] region(2701,543,543)
	weights[281] region(2706,544,544)
	weights[282] region(2721,547,547)
	weights[283] region(2726,548,548)
	weights[284] region(2741,551,551)
	weights[285] region(2746,552,552)
	weights[286] region(2761,555,555)
	weights[287] region(2766,556,556)
	weights[288] region(2781,559,559)
	weights[289] region(2786,560,560)
	weights[290] region(2801,563,563)
	weights[291] region(2806,564,564)
	weights[292] region(2811,565,565)
	weights[293] region(2826,568,568)
	weights[294] region(2831,569,569)
	weights[295] region(2846,572,572)
	weights[296] region(2851,573,573)
	weights[297] region(2866,576,576)
	weights[298] region(2871,577,577)
	weights[299] region(2886,580,580)
	weights[300] region(2891,581,581)
	weights[301] region(2906,584,584)
	weights[302] region(2911,585,585)
	weights[303] region(2916,586,586)
	weights[304] region(2931,589,589)
	weights[305] region(2936,590,590)
	weights[306] region(2951,593,593)
	weights[307] region(2956,594,594)
	weights[308] region(2971,597,597)
	weights[309] region(2976,598,598)
	weights[310] region(2991,601,601)
	weights[311] region(2996,602,602)
	weights[312] region(3011,605,605)
	weights[313] region(3016,606,606)
	weights[314] region(3021,607,607)
	weights[315] region(3036,610,610)
	weights[316] region(3041,611,611)
	weights[317] region(3056,614,614)
	weights[318] region(3061,615,615)
	weights[319] region(3076,618,618)
	weights[320] region(3081,619,619)
	weights[321] region(3096,622,622)
	weights[322] region(3101,623,623)
	weights[323] region(3116,626,626)
	weights[324] region(3121,627,627)
	weights[325] region(3126,628,628)
	weights[326] region(3141,631,631)
	weights[327] region(3146,632,632)
	weights[328] region(3161,635,635)
	weights[329] region(3166,636,636)
	weights[330] region(3181,639,639)
	weights[331] region(3186,640,640)
	weights[332] region(3201,643,643)
	weights[333] region(3206,644,644)
	weights[334] region(3221,647,647)
	weights[335] region(3226,648,648)
	weights[336] region(3231,649,649)
	weights[337] region(3246,652,652)
	weights[338] region(3251,653,653)
	weights[339] region(3266,656,656)
	weights[340] region(3271,657,657)
	weights[341] region(3286,660,660)
	weights[342] region(3291,661,661)
	weights[343] region(3306,664,664)
	weights[344] region(3311,665,665)
	weights[345] region(3326,668,668)
	weights[346] region(3331,669,669)
	weights[347] region(3336,670,670)
	weights[348] region(3351,673,673)
	weights[349] region(3356,674,674)
	weights[350] region(3371,677,677)
	weights[351] region(3376,678,678)
	weights[352] region(3391,681,681)
	weights[353] region(3396,682,682)
	weights[354] region(3411,685,685)
	weights[355] region(3416,686,686)
	weights[356] region(3431,689,689)
	weights[357] region(3436,690,690)
	weights[358] region(3441,691,691)
	weights[359] region(3456,694,694)
	weights[360] region(3461,695,695)
	weights[361] region(3476,698,698)
	weights[362] region(3481,699,699)
	weights[363] region(3496,702,702)
	weights[364] region(3501,703,703)
	weights[365] region(3516,706,706)
	weights[366] region(3521,707,707)
	weights[367] region(3536,710,710)
	weights[368] region(3541,711,711)
	weights[369] region(3546,712,712)
	weights[370] region(3561,715,715)
	weights[371] region(3566,716,716)
	weights[372] region(3581,719,719)
	weights[373] region(3586,720,720)
	weights[374] region(3601,723,723)
	weights[375] region(3606,724,724)
	weights[376] region(3621,727,727)
	weights[377] region(3626,728,728)
	weights[378] region(3641,731,731)
	weights[379] region(3646,732,732)
	weights[380] region(3651,733,733)
	weights[381] region(3666,736,736)
	weights[382] region(3671,737,737)
	weights[383] region(3686,740,740)
	weights[384] region(3691,741,741)
	weights[385] region(3706,744,744)
	weights[386] region(3711,745,745)
	weights[387] region(3726,748,748)
	weights[388] region(3731,749,749)
	weights[389] region(3746,752,752)
	weights[390] region(3751,753,753)
	weights[391] region(3756,754,754)
	weights[392] region(3771,757,757)
	weights[393] region(3776,758,758)
	weights[394] region(3791,761,761)
	weights[395] region(3796,762,762)
	weights[396] region(3811,765,765)
	weights[397] region(3816,766,766)
	weights[398] region(3831,769,769)
	weights[399] region(3836,770,770)
	weights[400] region(3851,773,773)
	weights[401] region(3856,774,774)
	weights[402] region(3861,775,775)
	weights[403] region(3876,778,778)
	weights[404] region(3881,779,779)
	weights[405] region(3896,782,782)
	weights[406] region(3901,783,783)
	weights[407] region(3916,786,786)
	weights[408] region(3921,787,787)
	weights[409] region(3936,790,790)
	weights[410] region(3941,791,791)
	weights[411] region(3956,794,794)
	weights[412] region(3961,795,795)
	weights[413] region(3966,796,796)
	weights[414] region(3981,799,799)
	weights[415] region(3986,800,800)
	weights[416] region(4001,803,803)
	weights[417] region(4006,804,804)
	weights[418] region(4021,807,807)
	weights[419] region(4026,808,808)
	weights[420] region(4041,811,811)
	weights[421] region(4046,812,812)
	weights[422] region(4061,815,815)
	weights[423] region(4066,816,816)
	weights[424] region(4071,817,817)
	weights[425] region(4086,820,820)
	weights[426] region(4091,821,821)
	weights[427] region(4106,824,824)
	weights[428] region(4111,825,825)
	weights[429] region(4126,828,828)
	weights[430] region(4131,829,829)
	weights[431] region(4146,832,832)
	weights[432] region(4151,833,833)
	weights[433] region(4166,836,836)
	weights[434] region(4171,837,837)
	weights[435] region(4176,838,838)
	weights[436] region(4191,841,841)
	weights[437] region(4196,842,842)
	weights[438] region(4211,845,845)
	weights[439] region(4216,846,846)
	weights[440] region(4231,849,849)
	weights[441] region(4236,850,850)
	weights[442] region(4251,853,853)
operator[10]: type(Weight) guid(2000592)
	outputs[0] region(51,13,13)
operator[11]: type(Weight) guid(2000593)
	outputs[0] region(56,14,14)
operator[12]: type(Weight) guid(2000596)
	outputs[0] region(71,17,17)
operator[13]: type(Weight) guid(2000597)
	outputs[0] region(76,18,18)
operator[14]: type(Weight) guid(2000598)
	outputs[0] region(81,19,19)
operator[15]: type(Weight) guid(2000600)
	outputs[0] region(96,22,22)
operator[16]: type(Weight) guid(2000601)
	outputs[0] region(101,23,23)
operator[17]: type(Weight) guid(2000604)
	outputs[0] region(116,26,26)
operator[18]: type(Weight) guid(2000605)
	outputs[0] region(121,27,27)
operator[19]: type(Weight) guid(2000608)
	outputs[0] region(136,30,30)
operator[20]: type(Weight) guid(2000609)
	outputs[0] region(141,31,31)
operator[21]: type(Weight) guid(2000611)
	outputs[0] region(156,34,34)
operator[22]: type(Weight) guid(2000612)
	outputs[0] region(161,35,35)
operator[23]: type(Weight) guid(2000615)
	outputs[0] region(176,38,38)
operator[24]: type(Weight) guid(2000616)
	outputs[0] region(181,39,39)
operator[25]: type(Weight) guid(2000617)
	outputs[0] region(186,40,40)
operator[26]: type(Weight) guid(2000619)
	outputs[0] region(201,43,43)
operator[27]: type(Weight) guid(2000620)
	outputs[0] region(206,44,44)
operator[28]: type(Weight) guid(2000623)
	outputs[0] region(221,47,47)
operator[29]: type(Weight) guid(2000624)
	outputs[0] region(226,48,48)
operator[30]: type(Weight) guid(2000627)
	outputs[0] region(241,51,51)
operator[31]: type(Weight) guid(2000628)
	outputs[0] region(246,52,52)
operator[32]: type(Weight) guid(2000630)
	outputs[0] region(261,55,55)
operator[33]: type(Weight) guid(2000631)
	outputs[0] region(266,56,56)
operator[34]: type(Weight) guid(2000634)
	outputs[0] region(281,59,59)
operator[35]: type(Weight) guid(2000635)
	outputs[0] region(286,60,60)
operator[36]: type(Weight) guid(2000636)
	outputs[0] region(291,61,61)
operator[37]: type(Weight) guid(2000638)
	outputs[0] region(306,64,64)
operator[38]: type(Weight) guid(2000639)
	outputs[0] region(311,65,65)
operator[39]: type(Weight) guid(2000642)
	outputs[0] region(326,68,68)
operator[40]: type(Weight) guid(2000643)
	outputs[0] region(331,69,69)
operator[41]: type(Weight) guid(2000646)
	outputs[0] region(346,72,72)
operator[42]: type(Weight) guid(2000647)
	outputs[0] region(351,73,73)
operator[43]: type(Weight) guid(2000649)
	outputs[0] region(366,76,76)
operator[44]: type(Weight) guid(2000650)
	outputs[0] region(371,77,77)
operator[45]: type(Weight) guid(2000653)
	outputs[0] region(386,80,80)
operator[46]: type(Weight) guid(2000654)
	outputs[0] region(391,81,81)
operator[47]: type(Weight) guid(2000655)
	outputs[0] region(396,82,82)
operator[48]: type(Weight) guid(2000657)
	outputs[0] region(411,85,85)
operator[49]: type(Weight) guid(2000658)
	outputs[0] region(416,86,86)
operator[50]: type(Weight) guid(2000661)
	outputs[0] region(431,89,89)
operator[51]: type(Weight) guid(2000662)
	outputs[0] region(436,90,90)
operator[52]: type(Weight) guid(2000665)
	outputs[0] region(451,93,93)
operator[53]: type(Weight) guid(2000666)
	outputs[0] region(456,94,94)
operator[54]: type(Weight) guid(2000668)
	outputs[0] region(471,97,97)
operator[55]: type(Weight) guid(2000669)
	outputs[0] region(476,98,98)
operator[56]: type(Weight) guid(2000672)
	outputs[0] region(491,101,101)
operator[57]: type(Weight) guid(2000673)
	outputs[0] region(496,102,102)
operator[58]: type(Weight) guid(2000674)
	outputs[0] region(501,103,103)
operator[59]: type(Weight) guid(2000676)
	outputs[0] region(516,106,106)
operator[60]: type(Weight) guid(2000677)
	outputs[0] region(521,107,107)
operator[61]: type(Weight) guid(2000680)
	outputs[0] region(536,110,110)
operator[62]: type(Weight) guid(2000681)
	outputs[0] region(541,111,111)
operator[63]: type(Weight) guid(2000684)
	outputs[0] region(556,114,114)
operator[64]: type(Weight) guid(2000685)
	outputs[0] region(561,115,115)
operator[65]: type(Weight) guid(2000687)
	outputs[0] region(576,118,118)
operator[66]: type(Weight) guid(2000688)
	outputs[0] region(581,119,119)
operator[67]: type(Weight) guid(2000691)
	outputs[0] region(596,122,122)
operator[68]: type(Weight) guid(2000692)
	outputs[0] region(601,123,123)
operator[69]: type(Weight) guid(2000693)
	outputs[0] region(606,124,124)
operator[70]: type(Weight) guid(2000695)
	outputs[0] region(621,127,127)
operator[71]: type(Weight) guid(2000696)
	outputs[0] region(626,128,128)
operator[72]: type(Weight) guid(2000699)
	outputs[0] region(641,131,131)
operator[73]: type(Weight) guid(2000700)
	outputs[0] region(646,132,132)
operator[74]: type(Weight) guid(2000703)
	outputs[0] region(661,135,135)
operator[75]: type(Weight) guid(2000704)
	outputs[0] region(666,136,136)
operator[76]: type(Weight) guid(2000706)
	outputs[0] region(681,139,139)
operator[77]: type(Weight) guid(2000707)
	outputs[0] region(686,140,140)
operator[78]: type(Weight) guid(2000710)
	outputs[0] region(701,143,143)
operator[79]: type(Weight) guid(2000711)
	outputs[0] region(706,144,144)
operator[80]: type(Weight) guid(2000712)
	outputs[0] region(711,145,145)
operator[81]: type(Weight) guid(2000714)
	outputs[0] region(726,148,148)
operator[82]: type(Weight) guid(2000715)
	outputs[0] region(731,149,149)
operator[83]: type(Weight) guid(2000718)
	outputs[0] region(746,152,152)
operator[84]: type(Weight) guid(2000719)
	outputs[0] region(751,153,153)
operator[85]: type(Weight) guid(2000722)
	outputs[0] region(766,156,156)
operator[86]: type(Weight) guid(2000723)
	outputs[0] region(771,157,157)
operator[87]: type(Weight) guid(2000725)
	outputs[0] region(786,160,160)
operator[88]: type(Weight) guid(2000726)
	outputs[0] region(791,161,161)
operator[89]: type(Weight) guid(2000729)
	outputs[0] region(806,164,164)
operator[90]: type(Weight) guid(2000730)
	outputs[0] region(811,165,165)
operator[91]: type(Weight) guid(2000731)
	outputs[0] region(816,166,166)
operator[92]: type(Weight) guid(2000733)
	outputs[0] region(831,169,169)
operator[93]: type(Weight) guid(2000734)
	outputs[0] region(836,170,170)
operator[94]: type(Weight) guid(2000737)
	outputs[0] region(851,173,173)
operator[95]: type(Weight) guid(2000738)
	outputs[0] region(856,174,174)
operator[96]: type(Weight) guid(2000741)
	outputs[0] region(871,177,177)
operator[97]: type(Weight) guid(2000742)
	outputs[0] region(876,178,178)
operator[98]: type(Weight) guid(2000744)
	outputs[0] region(891,181,181)
operator[99]: type(Weight) guid(2000745)
	outputs[0] region(896,182,182)
operator[100]: type(Weight) guid(2000748)
	outputs[0] region(911,185,185)
operator[101]: type(Weight) guid(2000749)
	outputs[0] region(916,186,186)
operator[102]: type(Weight) guid(2000750)
	outputs[0] region(921,187,187)
operator[103]: type(Weight) guid(2000752)
	outputs[0] region(936,190,190)
operator[104]: type(Weight) guid(2000753)
	outputs[0] region(941,191,191)
operator[105]: type(Weight) guid(2000756)
	outputs[0] region(956,194,194)
operator[106]: type(Weight) guid(2000757)
	outputs[0] region(961,195,195)
operator[107]: type(Weight) guid(2000760)
	outputs[0] region(976,198,198)
operator[108]: type(Weight) guid(2000761)
	outputs[0] region(981,199,199)
operator[109]: type(Weight) guid(2000763)
	outputs[0] region(996,202,202)
operator[110]: type(Weight) guid(2000764)
	outputs[0] region(1001,203,203)
operator[111]: type(Weight) guid(2000767)
	outputs[0] region(1016,206,206)
operator[112]: type(Weight) guid(2000768)
	outputs[0] region(1021,207,207)
operator[113]: type(Weight) guid(2000769)
	outputs[0] region(1026,208,208)
operator[114]: type(Weight) guid(2000771)
	outputs[0] region(1041,211,211)
operator[115]: type(Weight) guid(2000772)
	outputs[0] region(1046,212,212)
operator[116]: type(Weight) guid(2000775)
	outputs[0] region(1061,215,215)
operator[117]: type(Weight) guid(2000776)
	outputs[0] region(1066,216,216)
operator[118]: type(Weight) guid(2000779)
	outputs[0] region(1081,219,219)
operator[119]: type(Weight) guid(2000780)
	outputs[0] region(1086,220,220)
operator[120]: type(Weight) guid(2000782)
	outputs[0] region(1101,223,223)
operator[121]: type(Weight) guid(2000783)
	outputs[0] region(1106,224,224)
operator[122]: type(Weight) guid(2000786)
	outputs[0] region(1121,227,227)
operator[123]: type(Weight) guid(2000787)
	outputs[0] region(1126,228,228)
operator[124]: type(Weight) guid(2000788)
	outputs[0] region(1131,229,229)
operator[125]: type(Weight) guid(2000790)
	outputs[0] region(1146,232,232)
operator[126]: type(Weight) guid(2000791)
	outputs[0] region(1151,233,233)
operator[127]: type(Weight) guid(2000794)
	outputs[0] region(1166,236,236)
operator[128]: type(Weight) guid(2000795)
	outputs[0] region(1171,237,237)
operator[129]: type(Weight) guid(2000798)
	outputs[0] region(1186,240,240)
operator[130]: type(Weight) guid(2000799)
	outputs[0] region(1191,241,241)
operator[131]: type(Weight) guid(2000801)
	outputs[0] region(1206,244,244)
operator[132]: type(Weight) guid(2000802)
	outputs[0] region(1211,245,245)
operator[133]: type(Weight) guid(2000805)
	outputs[0] region(1226,248,248)
operator[134]: type(Weight) guid(2000806)
	outputs[0] region(1231,249,249)
operator[135]: type(Weight) guid(2000807)
	outputs[0] region(1236,250,250)
operator[136]: type(Weight) guid(2000809)
	outputs[0] region(1251,253,253)
operator[137]: type(Weight) guid(2000810)
	outputs[0] region(1256,254,254)
operator[138]: type(Weight) guid(2000813)
	outputs[0] region(1271,257,257)
operator[139]: type(Weight) guid(2000814)
	outputs[0] region(1276,258,258)
operator[140]: type(Weight) guid(2000817)
	outputs[0] region(1291,261,261)
operator[141]: type(Weight) guid(2000818)
	outputs[0] region(1296,262,262)
operator[142]: type(Weight) guid(2000820)
	outputs[0] region(1311,265,265)
operator[143]: type(Weight) guid(2000821)
	outputs[0] region(1316,266,266)
operator[144]: type(Weight) guid(2000824)
	outputs[0] region(1331,269,269)
operator[145]: type(Weight) guid(2000825)
	outputs[0] region(1336,270,270)
operator[146]: type(Weight) guid(2000826)
	outputs[0] region(1341,271,271)
operator[147]: type(Weight) guid(2000828)
	outputs[0] region(1356,274,274)
operator[148]: type(Weight) guid(2000829)
	outputs[0] region(1361,275,275)
operator[149]: type(Weight) guid(2000832)
	outputs[0] region(1376,278,278)
operator[150]: type(Weight) guid(2000833)
	outputs[0] region(1381,279,279)
operator[151]: type(Weight) guid(2000836)
	outputs[0] region(1396,282,282)
operator[152]: type(Weight) guid(2000837)
	outputs[0] region(1401,283,283)
operator[153]: type(Weight) guid(2000839)
	outputs[0] region(1416,286,286)
operator[154]: type(Weight) guid(2000840)
	outputs[0] region(1421,287,287)
operator[155]: type(Weight) guid(2000843)
	outputs[0] region(1436,290,290)
operator[156]: type(Weight) guid(2000844)
	outputs[0] region(1441,291,291)
operator[157]: type(Weight) guid(2000845)
	outputs[0] region(1446,292,292)
operator[158]: type(Weight) guid(2000847)
	outputs[0] region(1461,295,295)
operator[159]: type(Weight) guid(2000848)
	outputs[0] region(1466,296,296)
operator[160]: type(Weight) guid(2000851)
	outputs[0] region(1481,299,299)
operator[161]: type(Weight) guid(2000852)
	outputs[0] region(1486,300,300)
operator[162]: type(Weight) guid(2000855)
	outputs[0] region(1501,303,303)
operator[163]: type(Weight) guid(2000856)
	outputs[0] region(1506,304,304)
operator[164]: type(Weight) guid(2000858)
	outputs[0] region(1521,307,307)
operator[165]: type(Weight) guid(2000859)
	outputs[0] region(1526,308,308)
operator[166]: type(Weight) guid(2000862)
	outputs[0] region(1541,311,311)
operator[167]: type(Weight) guid(2000863)
	outputs[0] region(1546,312,312)
operator[168]: type(Weight) guid(2000864)
	outputs[0] region(1551,313,313)
operator[169]: type(Weight) guid(2000866)
	outputs[0] region(1566,316,316)
operator[170]: type(Weight) guid(2000867)
	outputs[0] region(1571,317,317)
operator[171]: type(Weight) guid(2000870)
	outputs[0] region(1586,320,320)
operator[172]: type(Weight) guid(2000871)
	outputs[0] region(1591,321,321)
operator[173]: type(Weight) guid(2000874)
	outputs[0] region(1606,324,324)
operator[174]: type(Weight) guid(2000875)
	outputs[0] region(1611,325,325)
operator[175]: type(Weight) guid(2000877)
	outputs[0] region(1626,328,328)
operator[176]: type(Weight) guid(2000878)
	outputs[0] region(1631,329,329)
operator[177]: type(Weight) guid(2000881)
	outputs[0] region(1646,332,332)
operator[178]: type(Weight) guid(2000882)
	outputs[0] region(1651,333,333)
operator[179]: type(Weight) guid(2000883)
	outputs[0] region(1656,334,334)
operator[180]: type(Weight) guid(2000885)
	outputs[0] region(1671,337,337)
operator[181]: type(Weight) guid(2000886)
	outputs[0] region(1676,338,338)
operator[182]: type(Weight) guid(2000889)
	outputs[0] region(1691,341,341)
operator[183]: type(Weight) guid(2000890)
	outputs[0] region(1696,342,342)
operator[184]: type(Weight) guid(2000893)
	outputs[0] region(1711,345,345)
operator[185]: type(Weight) guid(2000894)
	outputs[0] region(1716,346,346)
operator[186]: type(Weight) guid(2000896)
	outputs[0] region(1731,349,349)
operator[187]: type(Weight) guid(2000897)
	outputs[0] region(1736,350,350)
operator[188]: type(Weight) guid(2000900)
	outputs[0] region(1751,353,353)
operator[189]: type(Weight) guid(2000901)
	outputs[0] region(1756,354,354)
operator[190]: type(Weight) guid(2000902)
	outputs[0] region(1761,355,355)
operator[191]: type(Weight) guid(2000904)
	outputs[0] region(1776,358,358)
operator[192]: type(Weight) guid(2000905)
	outputs[0] region(1781,359,359)
operator[193]: type(Weight) guid(2000908)
	outputs[0] region(1796,362,362)
operator[194]: type(Weight) guid(2000909)
	outputs[0] region(1801,363,363)
operator[195]: type(Weight) guid(2000912)
	outputs[0] region(1816,366,366)
operator[196]: type(Weight) guid(2000913)
	outputs[0] region(1821,367,367)
operator[197]: type(Weight) guid(2000915)
	outputs[0] region(1836,370,370)
operator[198]: type(Weight) guid(2000916)
	outputs[0] region(1841,371,371)
operator[199]: type(Weight) guid(2000919)
	outputs[0] region(1856,374,374)
operator[200]: type(Weight) guid(2000920)
	outputs[0] region(1861,375,375)
operator[201]: type(Weight) guid(2000921)
	outputs[0] region(1866,376,376)
operator[202]: type(Weight) guid(2000923)
	outputs[0] region(1881,379,379)
operator[203]: type(Weight) guid(2000924)
	outputs[0] region(1886,380,380)
operator[204]: type(Weight) guid(2000927)
	outputs[0] region(1901,383,383)
operator[205]: type(Weight) guid(2000928)
	outputs[0] region(1906,384,384)
operator[206]: type(Weight) guid(2000931)
	outputs[0] region(1921,387,387)
operator[207]: type(Weight) guid(2000932)
	outputs[0] region(1926,388,388)
operator[208]: type(Weight) guid(2000934)
	outputs[0] region(1941,391,391)
operator[209]: type(Weight) guid(2000935)
	outputs[0] region(1946,392,392)
operator[210]: type(Weight) guid(2000938)
	outputs[0] region(1961,395,395)
operator[211]: type(Weight) guid(2000939)
	outputs[0] region(1966,396,396)
operator[212]: type(Weight) guid(2000940)
	outputs[0] region(1971,397,397)
operator[213]: type(Weight) guid(2000942)
	outputs[0] region(1986,400,400)
operator[214]: type(Weight) guid(2000943)
	outputs[0] region(1991,401,401)
operator[215]: type(Weight) guid(2000946)
	outputs[0] region(2006,404,404)
operator[216]: type(Weight) guid(2000947)
	outputs[0] region(2011,405,405)
operator[217]: type(Weight) guid(2000950)
	outputs[0] region(2026,408,408)
operator[218]: type(Weight) guid(2000951)
	outputs[0] region(2031,409,409)
operator[219]: type(Weight) guid(2000953)
	outputs[0] region(2046,412,412)
operator[220]: type(Weight) guid(2000954)
	outputs[0] region(2051,413,413)
operator[221]: type(Weight) guid(2000957)
	outputs[0] region(2066,416,416)
operator[222]: type(Weight) guid(2000958)
	outputs[0] region(2071,417,417)
operator[223]: type(Weight) guid(2000959)
	outputs[0] region(2076,418,418)
operator[224]: type(Weight) guid(2000961)
	outputs[0] region(2091,421,421)
operator[225]: type(Weight) guid(2000962)
	outputs[0] region(2096,422,422)
operator[226]: type(Weight) guid(2000965)
	outputs[0] region(2111,425,425)
operator[227]: type(Weight) guid(2000966)
	outputs[0] region(2116,426,426)
operator[228]: type(Weight) guid(2000969)
	outputs[0] region(2131,429,429)
operator[229]: type(Weight) guid(2000970)
	outputs[0] region(2136,430,430)
operator[230]: type(Weight) guid(2000972)
	outputs[0] region(2151,433,433)
operator[231]: type(Weight) guid(2000973)
	outputs[0] region(2156,434,434)
operator[232]: type(Weight) guid(2000976)
	outputs[0] region(2171,437,437)
operator[233]: type(Weight) guid(2000977)
	outputs[0] region(2176,438,438)
operator[234]: type(Weight) guid(2000978)
	outputs[0] region(2181,439,439)
operator[235]: type(Weight) guid(2000980)
	outputs[0] region(2196,442,442)
operator[236]: type(Weight) guid(2000981)
	outputs[0] region(2201,443,443)
operator[237]: type(Weight) guid(2000984)
	outputs[0] region(2216,446,446)
operator[238]: type(Weight) guid(2000985)
	outputs[0] region(2221,447,447)
operator[239]: type(Weight) guid(2000988)
	outputs[0] region(2236,450,450)
operator[240]: type(Weight) guid(2000989)
	outputs[0] region(2241,451,451)
operator[241]: type(Weight) guid(2000991)
	outputs[0] region(2256,454,454)
operator[242]: type(Weight) guid(2000992)
	outputs[0] region(2261,455,455)
operator[243]: type(Weight) guid(2000995)
	outputs[0] region(2276,458,458)
operator[244]: type(Weight) guid(2000996)
	outputs[0] region(2281,459,459)
operator[245]: type(Weight) guid(2000997)
	outputs[0] region(2286,460,460)
operator[246]: type(Weight) guid(2000999)
	outputs[0] region(2301,463,463)
operator[247]: type(Weight) guid(2001000)
	outputs[0] region(2306,464,464)
operator[248]: type(Weight) guid(2001003)
	outputs[0] region(2321,467,467)
operator[249]: type(Weight) guid(2001004)
	outputs[0] region(2326,468,468)
operator[250]: type(Weight) guid(2001007)
	outputs[0] region(2341,471,471)
operator[251]: type(Weight) guid(2001008)
	outputs[0] region(2346,472,472)
operator[252]: type(Weight) guid(2001010)
	outputs[0] region(2361,475,475)
operator[253]: type(Weight) guid(2001011)
	outputs[0] region(2366,476,476)
operator[254]: type(Weight) guid(2001014)
	outputs[0] region(2381,479,479)
operator[255]: type(Weight) guid(2001015)
	outputs[0] region(2386,480,480)
operator[256]: type(Weight) guid(2001016)
	outputs[0] region(2391,481,481)
operator[257]: type(Weight) guid(2001018)
	outputs[0] region(2406,484,484)
operator[258]: type(Weight) guid(2001019)
	outputs[0] region(2411,485,485)
operator[259]: type(Weight) guid(2001022)
	outputs[0] region(2426,488,488)
operator[260]: type(Weight) guid(2001023)
	outputs[0] region(2431,489,489)
operator[261]: type(Weight) guid(2001026)
	outputs[0] region(2446,492,492)
operator[262]: type(Weight) guid(2001027)
	outputs[0] region(2451,493,493)
operator[263]: type(Weight) guid(2001029)
	outputs[0] region(2466,496,496)
operator[264]: type(Weight) guid(2001030)
	outputs[0] region(2471,497,497)
operator[265]: type(Weight) guid(2001033)
	outputs[0] region(2486,500,500)
operator[266]: type(Weight) guid(2001034)
	outputs[0] region(2491,501,501)
operator[267]: type(Weight) guid(2001035)
	outputs[0] region(2496,502,502)
operator[268]: type(Weight) guid(2001037)
	outputs[0] region(2511,505,505)
operator[269]: type(Weight) guid(2001038)
	outputs[0] region(2516,506,506)
operator[270]: type(Weight) guid(2001041)
	outputs[0] region(2531,509,509)
operator[271]: type(Weight) guid(2001042)
	outputs[0] region(2536,510,510)
operator[272]: type(Weight) guid(2001045)
	outputs[0] region(2551,513,513)
operator[273]: type(Weight) guid(2001046)
	outputs[0] region(2556,514,514)
operator[274]: type(Weight) guid(2001048)
	outputs[0] region(2571,517,517)
operator[275]: type(Weight) guid(2001049)
	outputs[0] region(2576,518,518)
operator[276]: type(Weight) guid(2001052)
	outputs[0] region(2591,521,521)
operator[277]: type(Weight) guid(2001053)
	outputs[0] region(2596,522,522)
operator[278]: type(Weight) guid(2001054)
	outputs[0] region(2601,523,523)
operator[279]: type(Weight) guid(2001056)
	outputs[0] region(2616,526,526)
operator[280]: type(Weight) guid(2001057)
	outputs[0] region(2621,527,527)
operator[281]: type(Weight) guid(2001060)
	outputs[0] region(2636,530,530)
operator[282]: type(Weight) guid(2001061)
	outputs[0] region(2641,531,531)
operator[283]: type(Weight) guid(2001064)
	outputs[0] region(2656,534,534)
operator[284]: type(Weight) guid(2001065)
	outputs[0] region(2661,535,535)
operator[285]: type(Weight) guid(2001067)
	outputs[0] region(2676,538,538)
operator[286]: type(Weight) guid(2001068)
	outputs[0] region(2681,539,539)
operator[287]: type(Weight) guid(2001071)
	outputs[0] region(2696,542,542)
operator[288]: type(Weight) guid(2001072)
	outputs[0] region(2701,543,543)
operator[289]: type(Weight) guid(2001073)
	outputs[0] region(2706,544,544)
operator[290]: type(Weight) guid(2001075)
	outputs[0] region(2721,547,547)
operator[291]: type(Weight) guid(2001076)
	outputs[0] region(2726,548,548)
operator[292]: type(Weight) guid(2001079)
	outputs[0] region(2741,551,551)
operator[293]: type(Weight) guid(2001080)
	outputs[0] region(2746,552,552)
operator[294]: type(Weight) guid(2001083)
	outputs[0] region(2761,555,555)
operator[295]: type(Weight) guid(2001084)
	outputs[0] region(2766,556,556)
operator[296]: type(Weight) guid(2001086)
	outputs[0] region(2781,559,559)
operator[297]: type(Weight) guid(2001087)
	outputs[0] region(2786,560,560)
operator[298]: type(Weight) guid(2001090)
	outputs[0] region(2801,563,563)
operator[299]: type(Weight) guid(2001091)
	outputs[0] region(2806,564,564)
operator[300]: type(Weight) guid(2001092)
	outputs[0] region(2811,565,565)
operator[301]: type(Weight) guid(2001094)
	outputs[0] region(2826,568,568)
operator[302]: type(Weight) guid(2001095)
	outputs[0] region(2831,569,569)
operator[303]: type(Weight) guid(2001098)
	outputs[0] region(2846,572,572)
operator[304]: type(Weight) guid(2001099)
	outputs[0] region(2851,573,573)
operator[305]: type(Weight) guid(2001102)
	outputs[0] region(2866,576,576)
operator[306]: type(Weight) guid(2001103)
	outputs[0] region(2871,577,577)
operator[307]: type(Weight) guid(2001105)
	outputs[0] region(2886,580,580)
operator[308]: type(Weight) guid(2001106)
	outputs[0] region(2891,581,581)
operator[309]: type(Weight) guid(2001109)
	outputs[0] region(2906,584,584)
operator[310]: type(Weight) guid(2001110)
	outputs[0] region(2911,585,585)
operator[311]: type(Weight) guid(2001111)
	outputs[0] region(2916,586,586)
operator[312]: type(Weight) guid(2001113)
	outputs[0] region(2931,589,589)
operator[313]: type(Weight) guid(2001114)
	outputs[0] region(2936,590,590)
operator[314]: type(Weight) guid(2001117)
	outputs[0] region(2951,593,593)
operator[315]: type(Weight) guid(2001118)
	outputs[0] region(2956,594,594)
operator[316]: type(Weight) guid(2001121)
	outputs[0] region(2971,597,597)
operator[317]: type(Weight) guid(2001122)
	outputs[0] region(2976,598,598)
operator[318]: type(Weight) guid(2001124)
	outputs[0] region(2991,601,601)
operator[319]: type(Weight) guid(2001125)
	outputs[0] region(2996,602,602)
operator[320]: type(Weight) guid(2001128)
	outputs[0] region(3011,605,605)
operator[321]: type(Weight) guid(2001129)
	outputs[0] region(3016,606,606)
operator[322]: type(Weight) guid(2001130)
	outputs[0] region(3021,607,607)
operator[323]: type(Weight) guid(2001132)
	outputs[0] region(3036,610,610)
operator[324]: type(Weight) guid(2001133)
	outputs[0] region(3041,611,611)
operator[325]: type(Weight) guid(2001136)
	outputs[0] region(3056,614,614)
operator[326]: type(Weight) guid(2001137)
	outputs[0] region(3061,615,615)
operator[327]: type(Weight) guid(2001140)
	outputs[0] region(3076,618,618)
operator[328]: type(Weight) guid(2001141)
	outputs[0] region(3081,619,619)
operator[329]: type(Weight) guid(2001143)
	outputs[0] region(3096,622,622)
operator[330]: type(Weight) guid(2001144)
	outputs[0] region(3101,623,623)
operator[331]: type(Weight) guid(2001147)
	outputs[0] region(3116,626,626)
operator[332]: type(Weight) guid(2001148)
	outputs[0] region(3121,627,627)
operator[333]: type(Weight) guid(2001149)
	outputs[0] region(3126,628,628)
operator[334]: type(Weight) guid(2001151)
	outputs[0] region(3141,631,631)
operator[335]: type(Weight) guid(2001152)
	outputs[0] region(3146,632,632)
operator[336]: type(Weight) guid(2001155)
	outputs[0] region(3161,635,635)
operator[337]: type(Weight) guid(2001156)
	outputs[0] region(3166,636,636)
operator[338]: type(Weight) guid(2001159)
	outputs[0] region(3181,639,639)
operator[339]: type(Weight) guid(2001160)
	outputs[0] region(3186,640,640)
operator[340]: type(Weight) guid(2001162)
	outputs[0] region(3201,643,643)
operator[341]: type(Weight) guid(2001163)
	outputs[0] region(3206,644,644)
operator[342]: type(Weight) guid(2001166)
	outputs[0] region(3221,647,647)
operator[343]: type(Weight) guid(2001167)
	outputs[0] region(3226,648,648)
operator[344]: type(Weight) guid(2001168)
	outputs[0] region(3231,649,649)
operator[345]: type(Weight) guid(2001170)
	outputs[0] region(3246,652,652)
operator[346]: type(Weight) guid(2001171)
	outputs[0] region(3251,653,653)
operator[347]: type(Weight) guid(2001174)
	outputs[0] region(3266,656,656)
operator[348]: type(Weight) guid(2001175)
	outputs[0] region(3271,657,657)
operator[349]: type(Weight) guid(2001178)
	outputs[0] region(3286,660,660)
operator[350]: type(Weight) guid(2001179)
	outputs[0] region(3291,661,661)
operator[351]: type(Weight) guid(2001181)
	outputs[0] region(3306,664,664)
operator[352]: type(Weight) guid(2001182)
	outputs[0] region(3311,665,665)
operator[353]: type(Weight) guid(2001185)
	outputs[0] region(3326,668,668)
operator[354]: type(Weight) guid(2001186)
	outputs[0] region(3331,669,669)
operator[355]: type(Weight) guid(2001187)
	outputs[0] region(3336,670,670)
operator[356]: type(Weight) guid(2001189)
	outputs[0] region(3351,673,673)
operator[357]: type(Weight) guid(2001190)
	outputs[0] region(3356,674,674)
operator[358]: type(Weight) guid(2001193)
	outputs[0] region(3371,677,677)
operator[359]: type(Weight) guid(2001194)
	outputs[0] region(3376,678,678)
operator[360]: type(Weight) guid(2001197)
	outputs[0] region(3391,681,681)
operator[361]: type(Weight) guid(2001198)
	outputs[0] region(3396,682,682)
operator[362]: type(Weight) guid(2001200)
	outputs[0] region(3411,685,685)
operator[363]: type(Weight) guid(2001201)
	outputs[0] region(3416,686,686)
operator[364]: type(Weight) guid(2001204)
	outputs[0] region(3431,689,689)
operator[365]: type(Weight) guid(2001205)
	outputs[0] region(3436,690,690)
operator[366]: type(Weight) guid(2001206)
	outputs[0] region(3441,691,691)
operator[367]: type(Weight) guid(2001208)
	outputs[0] region(3456,694,694)
operator[368]: type(Weight) guid(2001209)
	outputs[0] region(3461,695,695)
operator[369]: type(Weight) guid(2001212)
	outputs[0] region(3476,698,698)
operator[370]: type(Weight) guid(2001213)
	outputs[0] region(3481,699,699)
operator[371]: type(Weight) guid(2001216)
	outputs[0] region(3496,702,702)
operator[372]: type(Weight) guid(2001217)
	outputs[0] region(3501,703,703)
operator[373]: type(Weight) guid(2001219)
	outputs[0] region(3516,706,706)
operator[374]: type(Weight) guid(2001220)
	outputs[0] region(3521,707,707)
operator[375]: type(Weight) guid(2001223)
	outputs[0] region(3536,710,710)
operator[376]: type(Weight) guid(2001224)
	outputs[0] region(3541,711,711)
operator[377]: type(Weight) guid(2001225)
	outputs[0] region(3546,712,712)
operator[378]: type(Weight) guid(2001227)
	outputs[0] region(3561,715,715)
operator[379]: type(Weight) guid(2001228)
	outputs[0] region(3566,716,716)
operator[380]: type(Weight) guid(2001231)
	outputs[0] region(3581,719,719)
operator[381]: type(Weight) guid(2001232)
	outputs[0] region(3586,720,720)
operator[382]: type(Weight) guid(2001235)
	outputs[0] region(3601,723,723)
operator[383]: type(Weight) guid(2001236)
	outputs[0] region(3606,724,724)
operator[384]: type(Weight) guid(2001238)
	outputs[0] region(3621,727,727)
operator[385]: type(Weight) guid(2001239)
	outputs[0] region(3626,728,728)
operator[386]: type(Weight) guid(2001242)
	outputs[0] region(3641,731,731)
operator[387]: type(Weight) guid(2001243)
	outputs[0] region(3646,732,732)
operator[388]: type(Weight) guid(2001244)
	outputs[0] region(3651,733,733)
operator[389]: type(Weight) guid(2001246)
	outputs[0] region(3666,736,736)
operator[390]: type(Weight) guid(2001247)
	outputs[0] region(3671,737,737)
operator[391]: type(Weight) guid(2001250)
	outputs[0] region(3686,740,740)
operator[392]: type(Weight) guid(2001251)
	outputs[0] region(3691,741,741)
operator[393]: type(Weight) guid(2001254)
	outputs[0] region(3706,744,744)
operator[394]: type(Weight) guid(2001255)
	outputs[0] region(3711,745,745)
operator[395]: type(Weight) guid(2001257)
	outputs[0] region(3726,748,748)
operator[396]: type(Weight) guid(2001258)
	outputs[0] region(3731,749,749)
operator[397]: type(Weight) guid(2001261)
	outputs[0] region(3746,752,752)
operator[398]: type(Weight) guid(2001262)
	outputs[0] region(3751,753,753)
operator[399]: type(Weight) guid(2001263)
	outputs[0] region(3756,754,754)
operator[400]: type(Weight) guid(2001265)
	outputs[0] region(3771,757,757)
operator[401]: type(Weight) guid(2001266)
	outputs[0] region(3776,758,758)
operator[402]: type(Weight) guid(2001269)
	outputs[0] region(3791,761,761)
operator[403]: type(Weight) guid(2001270)
	outputs[0] region(3796,762,762)
operator[404]: type(Weight) guid(2001273)
	outputs[0] region(3811,765,765)
operator[405]: type(Weight) guid(2001274)
	outputs[0] region(3816,766,766)
operator[406]: type(Weight) guid(2001276)
	outputs[0] region(3831,769,769)
operator[407]: type(Weight) guid(2001277)
	outputs[0] region(3836,770,770)
operator[408]: type(Weight) guid(2001280)
	outputs[0] region(3851,773,773)
operator[409]: type(Weight) guid(2001281)
	outputs[0] region(3856,774,774)
operator[410]: type(Weight) guid(2001282)
	outputs[0] region(3861,775,775)
operator[411]: type(Weight) guid(2001284)
	outputs[0] region(3876,778,778)
operator[412]: type(Weight) guid(2001285)
	outputs[0] region(3881,779,779)
operator[413]: type(Weight) guid(2001288)
	outputs[0] region(3896,782,782)
operator[414]: type(Weight) guid(2001289)
	outputs[0] region(3901,783,783)
operator[415]: type(Weight) guid(2001292)
	outputs[0] region(3916,786,786)
operator[416]: type(Weight) guid(2001293)
	outputs[0] region(3921,787,787)
operator[417]: type(Weight) guid(2001295)
	outputs[0] region(3936,790,790)
operator[418]: type(Weight) guid(2001296)
	outputs[0] region(3941,791,791)
operator[419]: type(Weight) guid(2001299)
	outputs[0] region(3956,794,794)
operator[420]: type(Weight) guid(2001300)
	outputs[0] region(3961,795,795)
operator[421]: type(Weight) guid(2001301)
	outputs[0] region(3966,796,796)
operator[422]: type(Weight) guid(2001303)
	outputs[0] region(3981,799,799)
operator[423]: type(Weight) guid(2001304)
	outputs[0] region(3986,800,800)
operator[424]: type(Weight) guid(2001307)
	outputs[0] region(4001,803,803)
operator[425]: type(Weight) guid(2001308)
	outputs[0] region(4006,804,804)
operator[426]: type(Weight) guid(2001311)
	outputs[0] region(4021,807,807)
operator[427]: type(Weight) guid(2001312)
	outputs[0] region(4026,808,808)
operator[428]: type(Weight) guid(2001314)
	outputs[0] region(4041,811,811)
operator[429]: type(Weight) guid(2001315)
	outputs[0] region(4046,812,812)
operator[430]: type(Weight) guid(2001318)
	outputs[0] region(4061,815,815)
operator[431]: type(Weight) guid(2001319)
	outputs[0] region(4066,816,816)
operator[432]: type(Weight) guid(2001320)
	outputs[0] region(4071,817,817)
operator[433]: type(Weight) guid(2001322)
	outputs[0] region(4086,820,820)
operator[434]: type(Weight) guid(2001323)
	outputs[0] region(4091,821,821)
operator[435]: type(Weight) guid(2001326)
	outputs[0] region(4106,824,824)
operator[436]: type(Weight) guid(2001327)
	outputs[0] region(4111,825,825)
operator[437]: type(Weight) guid(2001330)
	outputs[0] region(4126,828,828)
operator[438]: type(Weight) guid(2001331)
	outputs[0] region(4131,829,829)
operator[439]: type(Weight) guid(2001333)
	outputs[0] region(4146,832,832)
operator[440]: type(Weight) guid(2001334)
	outputs[0] region(4151,833,833)
operator[441]: type(Weight) guid(2001337)
	outputs[0] region(4166,836,836)
operator[442]: type(Weight) guid(2001338)
	outputs[0] region(4171,837,837)
operator[443]: type(Weight) guid(2001339)
	outputs[0] region(4176,838,838)
operator[444]: type(Weight) guid(2001341)
	outputs[0] region(4191,841,841)
operator[445]: type(Weight) guid(2001342)
	outputs[0] region(4196,842,842)
operator[446]: type(Weight) guid(2001345)
	outputs[0] region(4211,845,845)
operator[447]: type(Weight) guid(2001346)
	outputs[0] region(4216,846,846)
operator[448]: type(Weight) guid(2001349)
	outputs[0] region(4231,849,849)
operator[449]: type(Weight) guid(2001350)
	outputs[0] region(4236,850,850)
operator[450]: type(Weight) guid(2001352)
	outputs[0] region(4251,853,853)
operator[451]: type(Combine) guid(2001353)
	inputs[0] region(4256,854,854)
	outputs[0] region(4261,855,855)
operator[452]: type(ArgMax) guid(2001354)
	inputs[0] region(4261,855,855)
	outputs[0] region(4263,856,856)
operator[0]: type(0)
	outputs[0] region(8,1,1)
operator[1]: type(0)
	outputs[0] region(10,2,2)
operator[2]: type(1)
	outputs[0] region(12,3,3)
operator[3]: type(78)
	inputs[0] region(8,1,1)
	inputs[1] region(10,2,2)
	outputs[0] region(14,4,4)
	outputs[1] region(18,6,6)
operator[4]: type(1)
	outputs[0] region(16,5,5)
operator[5]: type(98)
	inputs[0] region(14,4,4)
	outputs[0] region(21,7,7)
operator[6]: type(98)
	inputs[0] region(18,6,6)
	outputs[0] region(26,8,8)
operator[7]: type(1)
	outputs[0] region(31,9,9)
operator[8]: type(1)
	outputs[0] region(36,10,10)
operator[9]: type(78)
	inputs[0] region(21,7,7)
	inputs[1] region(26,8,8)
	outputs[0] region(41,11,11)
	outputs[1] region(46,12,12)
	outputs[2] region(61,15,15)
	outputs[3] region(66,16,16)
	outputs[4] region(86,20,20)
	outputs[5] region(91,21,21)
	outputs[6] region(106,24,24)
	outputs[7] region(111,25,25)
	outputs[8] region(126,28,28)
	outputs[9] region(131,29,29)
	outputs[10] region(146,32,32)
	outputs[11] region(151,33,33)
	outputs[12] region(166,36,36)
	outputs[13] region(171,37,37)
	outputs[14] region(191,41,41)
	outputs[15] region(196,42,42)
	outputs[16] region(211,45,45)
	outputs[17] region(216,46,46)
	outputs[18] region(231,49,49)
	outputs[19] region(236,50,50)
	outputs[20] region(251,53,53)
	outputs[21] region(256,54,54)
	outputs[22] region(271,57,57)
	outputs[23] region(276,58,58)
	outputs[24] region(296,62,62)
	outputs[25] region(301,63,63)
	outputs[26] region(316,66,66)
	outputs[27] region(321,67,67)
	outputs[28] region(336,70,70)
	outputs[29] region(341,71,71)
	outputs[30] region(356,74,74)
	outputs[31] region(361,75,75)
	outputs[32] region(376,78,78)
	outputs[33] region(381,79,79)
	outputs[34] region(401,83,83)
	outputs[35] region(406,84,84)
	outputs[36] region(421,87,87)
	outputs[37] region(426,88,88)
	outputs[38] region(441,91,91)
	outputs[39] region(446,92,92)
	outputs[40] region(461,95,95)
	outputs[41] region(466,96,96)
	outputs[42] region(481,99,99)
	outputs[43] region(486,100,100)
	outputs[44] region(506,104,104)
	outputs[45] region(511,105,105)
	outputs[46] region(526,108,108)
	outputs[47] region(531,109,109)
	outputs[48] region(546,112,112)
	outputs[49] region(551,113,113)
	outputs[50] region(566,116,116)
	outputs[51] region(571,117,117)
	outputs[52] region(586,120,120)
	outputs[53] region(591,121,121)
	outputs[54] region(611,125,125)
	outputs[55] region(616,126,126)
	outputs[56] region(631,129,129)
	outputs[57] region(636,130,130)
	outputs[58] region(651,133,133)
	outputs[59] region(656,134,134)
	outputs[60] region(671,137,137)
	outputs[61] region(676,138,138)
	outputs[62] region(691,141,141)
	outputs[63] region(696,142,142)
	outputs[64] region(716,146,146)
	outputs[65] region(721,147,147)
	outputs[66] region(736,150,150)
	outputs[67] region(741,151,151)
	outputs[68] region(756,154,154)
	outputs[69] region(761,155,155)
	outputs[70] region(776,158,158)
	outputs[71] region(781,159,159)
	outputs[72] region(796,162,162)
	outputs[73] region(801,163,163)
	outputs[74] region(821,167,167)
	outputs[75] region(826,168,168)
	outputs[76] region(841,171,171)
	outputs[77] region(846,172,172)
	outputs[78] region(861,175,175)
	outputs[79] region(866,176,176)
	outputs[80] region(881,179,179)
	outputs[81] region(886,180,180)
	outputs[82] region(901,183,183)
	outputs[83] region(906,184,184)
	outputs[84] region(926,188,188)
	outputs[85] region(931,189,189)
	outputs[86] region(946,192,192)
	outputs[87] region(951,193,193)
	outputs[88] region(966,196,196)
	outputs[89] region(971,197,197)
	outputs[90] region(986,200,200)
	outputs[91] region(991,201,201)
	outputs[92] region(1006,204,204)
	outputs[93] region(1011,205,205)
	outputs[94] region(1031,209,209)
	outputs[95] region(1036,210,210)
	outputs[96] region(1051,213,213)
	outputs[97] region(1056,214,214)
	outputs[98] region(1071,217,217)
	outputs[99] region(1076,218,218)
	outputs[100] region(1091,221,221)
	outputs[101] region(1096,222,222)
	outputs[102] region(1111,225,225)
	outputs[103] region(1116,226,226)
	outputs[104] region(1136,230,230)
	outputs[105] region(1141,231,231)
	outputs[106] region(1156,234,234)
	outputs[107] region(1161,235,235)
	outputs[108] region(1176,238,238)
	outputs[109] region(1181,239,239)
	outputs[110] region(1196,242,242)
	outputs[111] region(1201,243,243)
	outputs[112] region(1216,246,246)
	outputs[113] region(1221,247,247)
	outputs[114] region(1241,251,251)
	outputs[115] region(1246,252,252)
	outputs[116] region(1261,255,255)
	outputs[117] region(1266,256,256)
	outputs[118] region(1281,259,259)
	outputs[119] region(1286,260,260)
	outputs[120] region(1301,263,263)
	outputs[121] region(1306,264,264)
	outputs[122] region(1321,267,267)
	outputs[123] region(1326,268,268)
	outputs[124] region(1346,272,272)
	outputs[125] region(1351,273,273)
	outputs[126] region(1366,276,276)
	outputs[127] region(1371,277,277)
	outputs[128] region(1386,280,280)
	outputs[129] region(1391,281,281)
	outputs[130] region(1406,284,284)
	outputs[131] region(1411,285,285)
	outputs[132] region(1426,288,288)
	outputs[133] region(1431,289,289)
	outputs[134] region(1451,293,293)
	outputs[135] region(1456,294,294)
	outputs[136] region(1471,297,297)
	outputs[137] region(1476,298,298)
	outputs[138] region(1491,301,301)
	outputs[139] region(1496,302,302)
	outputs[140] region(1511,305,305)
	outputs[141] region(1516,306,306)
	outputs[142] region(1531,309,309)
	outputs[143] region(1536,310,310)
	outputs[144] region(1556,314,314)
	outputs[145] region(1561,315,315)
	outputs[146] region(1576,318,318)
	outputs[147] region(1581,319,319)
	outputs[148] region(1596,322,322)
	outputs[149] region(1601,323,323)
	outputs[150] region(1616,326,326)
	outputs[151] region(1621,327,327)
	outputs[152] region(1636,330,330)
	outputs[153] region(1641,331,331)
	outputs[154] region(1661,335,335)
	outputs[155] region(1666,336,336)
	outputs[156] region(1681,339,339)
	outputs[157] region(1686,340,340)
	outputs[158] region(1701,343,343)
	outputs[159] region(1706,344,344)
	outputs[160] region(1721,347,347)
	outputs[161] region(1726,348,348)
	outputs[162] region(1741,351,351)
	outputs[163] region(1746,352,352)
	outputs[164] region(1766,356,356)
	outputs[165] region(1771,357,357)
	outputs[166] region(1786,360,360)
	outputs[167] region(1791,361,361)
	outputs[168] region(1806,364,364)
	outputs[169] region(1811,365,365)
	outputs[170] region(1826,368,368)
	outputs[171] region(1831,369,369)
	outputs[172] region(1846,372,372)
	outputs[173] region(1851,373,373)
	outputs[174] region(1871,377,377)
	outputs[175] region(1876,378,378)
	outputs[176] region(1891,381,381)
	outputs[177] region(1896,382,382)
	outputs[178] region(1911,385,385)
	outputs[179] region(1916,386,386)
	outputs[180] region(1931,389,389)
	outputs[181] region(1936,390,390)
	outputs[182] region(1951,393,393)
	outputs[183] region(1956,394,394)
	outputs[184] region(1976,398,398)
	outputs[185] region(1981,399,399)
	outputs[186] region(1996,402,402)
	outputs[187] region(2001,403,403)
	outputs[188] region(2016,406,406)
	outputs[189] region(2021,407,407)
	outputs[190] region(2036,410,410)
	outputs[191] region(2041,411,411)
	outputs[192] region(2056,414,414)
	outputs[193] region(2061,415,415)
	outputs[194] region(2081,419,419)
	outputs[195] region(2086,420,420)
	outputs[196] region(2101,423,423)
	outputs[197] region(2106,424,424)
	outputs[198] region(2121,427,427)
	outputs[199] region(2126,428,428)
	outputs[200] region(2141,431,431)
	outputs[201] region(2146,432,432)
	outputs[202] region(2161,435,435)
	outputs[203] region(2166,436,436)
	outputs[204] region(2186,440,440)
	outputs[205] region(2191,441,441)
	outputs[206] region(2206,444,444)
	outputs[207] region(2211,445,445)
	outputs[208] region(2226,448,448)
	outputs[209] region(2231,449,449)
	outputs[210] region(2246,452,452)
	outputs[211] region(2251,453,453)
	outputs[212] region(2266,456,456)
	outputs[213] region(2271,457,457)
	outputs[214] region(2291,461,461)
	outputs[215] region(2296,462,462)
	outputs[216] region(2311,465,465)
	outputs[217] region(2316,466,466)
	outputs[218] region(2331,469,469)
	outputs[219] region(2336,470,470)
	outputs[220] region(2351,473,473)
	outputs[221] region(2356,474,474)
	outputs[222] region(2371,477,477)
	outputs[223] region(2376,478,478)
	outputs[224] region(2396,482,482)
	outputs[225] region(2401,483,483)
	outputs[226] region(2416,486,486)
	outputs[227] region(2421,487,487)
	outputs[228] region(2436,490,490)
	outputs[229] region(2441,491,491)
	outputs[230] region(2456,494,494)
	outputs[231] region(2461,495,495)
	outputs[232] region(2476,498,498)
	outputs[233] region(2481,499,499)
	outputs[234] region(2501,503,503)
	outputs[235] region(2506,504,504)
	outputs[236] region(2521,507,507)
	outputs[237] region(2526,508,508)
	outputs[238] region(2541,511,511)
	outputs[239] region(2546,512,512)
	outputs[240] region(2561,515,515)
	outputs[241] region(2566,516,516)
	outputs[242] region(2581,519,519)
	outputs[243] region(2586,520,520)
	outputs[244] region(2606,524,524)
	outputs[245] region(2611,525,525)
	outputs[246] region(2626,528,528)
	outputs[247] region(2631,529,529)
	outputs[248] region(2646,532,532)
	outputs[249] region(2651,533,533)
	outputs[250] region(2666,536,536)
	outputs[251] region(2671,537,537)
	outputs[252] region(2686,540,540)
	outputs[253] region(2691,541,541)
	outputs[254] region(2711,545,545)
	outputs[255] region(2716,546,546)
	outputs[256] region(2731,549,549)
	outputs[257] region(2736,550,550)
	outputs[258] region(2751,553,553)
	outputs[259] region(2756,554,554)
	outputs[260] region(2771,557,557)
	outputs[261] region(2776,558,558)
	outputs[262] region(2791,561,561)
	outputs[263] region(2796,562,562)
	outputs[264] region(2816,566,566)
	outputs[265] region(2821,567,567)
	outputs[266] region(2836,570,570)
	outputs[267] region(2841,571,571)
	outputs[268] region(2856,574,574)
	outputs[269] region(2861,575,575)
	outputs[270] region(2876,578,578)
	outputs[271] region(2881,579,579)
	outputs[272] region(2896,582,582)
	outputs[273] region(2901,583,583)
	outputs[274] region(2921,587,587)
	outputs[275] region(2926,588,588)
	outputs[276] region(2941,591,591)
	outputs[277] region(2946,592,592)
	outputs[278] region(2961,595,595)
	outputs[279] region(2966,596,596)
	outputs[280] region(2981,599,599)
	outputs[281] region(2986,600,600)
	outputs[282] region(3001,603,603)
	outputs[283] region(3006,604,604)
	outputs[284] region(3026,608,608)
	outputs[285] region(3031,609,609)
	outputs[286] region(3046,612,612)
	outputs[287] region(3051,613,613)
	outputs[288] region(3066,616,616)
	outputs[289] region(3071,617,617)
	outputs[290] region(3086,620,620)
	outputs[291] region(3091,621,621)
	outputs[292] region(3106,624,624)
	outputs[293] region(3111,625,625)
	outputs[294] region(3131,629,629)
	outputs[295] region(3136,630,630)
	outputs[296] region(3151,633,633)
	outputs[297] region(3156,634,634)
	outputs[298] region(3171,637,637)
	outputs[299] region(3176,638,638)
	outputs[300] region(3191,641,641)
	outputs[301] region(3196,642,642)
	outputs[302] region(3211,645,645)
	outputs[303] region(3216,646,646)
	outputs[304] region(3236,650,650)
	outputs[305] region(3241,651,651)
	outputs[306] region(3256,654,654)
	outputs[307] region(3261,655,655)
	outputs[308] region(3276,658,658)
	outputs[309] region(3281,659,659)
	outputs[310] region(3296,662,662)
	outputs[311] region(3301,663,663)
	outputs[312] region(3316,666,666)
	outputs[313] region(3321,667,667)
	outputs[314] region(3341,671,671)
	outputs[315] region(3346,672,672)
	outputs[316] region(3361,675,675)
	outputs[317] region(3366,676,676)
	outputs[318] region(3381,679,679)
	outputs[319] region(3386,680,680)
	outputs[320] region(3401,683,683)
	outputs[321] region(3406,684,684)
	outputs[322] region(3421,687,687)
	outputs[323] region(3426,688,688)
	outputs[324] region(3446,692,692)
	outputs[325] region(3451,693,693)
	outputs[326] region(3466,696,696)
	outputs[327] region(3471,697,697)
	outputs[328] region(3486,700,700)
	outputs[329] region(3491,701,701)
	outputs[330] region(3506,704,704)
	outputs[331] region(3511,705,705)
	outputs[332] region(3526,708,708)
	outputs[333] region(3531,709,709)
	outputs[334] region(3551,713,713)
	outputs[335] region(3556,714,714)
	outputs[336] region(3571,717,717)
	outputs[337] region(3576,718,718)
	outputs[338] region(3591,721,721)
	outputs[339] region(3596,722,722)
	outputs[340] region(3611,725,725)
	outputs[341] region(3616,726,726)
	outputs[342] region(3631,729,729)
	outputs[343] region(3636,730,730)
	outputs[344] region(3656,734,734)
	outputs[345] region(3661,735,735)
	outputs[346] region(3676,738,738)
	outputs[347] region(3681,739,739)
	outputs[348] region(3696,742,742)
	outputs[349] region(3701,743,743)
	outputs[350] region(3716,746,746)
	outputs[351] region(3721,747,747)
	outputs[352] region(3736,750,750)
	outputs[353] region(3741,751,751)
	outputs[354] region(3761,755,755)
	outputs[355] region(3766,756,756)
	outputs[356] region(3781,759,759)
	outputs[357] region(3786,760,760)
	outputs[358] region(3801,763,763)
	outputs[359] region(3806,764,764)
	outputs[360] region(3821,767,767)
	outputs[361] region(3826,768,768)
	outputs[362] region(3841,771,771)
	outputs[363] region(3846,772,772)
	outputs[364] region(3866,776,776)
	outputs[365] region(3871,777,777)
	outputs[366] region(3886,780,780)
	outputs[367] region(3891,781,781)
	outputs[368] region(3906,784,784)
	outputs[369] region(3911,785,785)
	outputs[370] region(3926,788,788)
	outputs[371] region(3931,789,789)
	outputs[372] region(3946,792,792)
	outputs[373] region(3951,793,793)
	outputs[374] region(3971,797,797)
	outputs[375] region(3976,798,798)
	outputs[376] region(3991,801,801)
	outputs[377] region(3996,802,802)
	outputs[378] region(4011,805,805)
	outputs[379] region(4016,806,806)
	outputs[380] region(4031,809,809)
	outputs[381] region(4036,810,810)
	outputs[382] region(4051,813,813)
	outputs[383] region(4056,814,814)
	outputs[384] region(4076,818,818)
	outputs[385] region(4081,819,819)
	outputs[386] region(4096,822,822)
	outputs[387] region(4101,823,823)
	outputs[388] region(4116,826,826)
	outputs[389] region(4121,827,827)
	outputs[390] region(4136,830,830)
	outputs[391] region(4141,831,831)
	outputs[392] region(4156,834,834)
	outputs[393] region(4161,835,835)
	outputs[394] region(4181,839,839)
	outputs[395] region(4186,840,840)
	outputs[396] region(4201,843,843)
	outputs[397] region(4206,844,844)
	outputs[398] region(4221,847,847)
	outputs[399] region(4226,848,848)
	outputs[400] region(4241,851,851)
	outputs[401] region(4246,852,852)
	outputs[402] region(4256,854,854)
operator[10]: type(1)
	outputs[0] region(51,13,13)
operator[11]: type(1)
	outputs[0] region(56,14,14)
operator[12]: type(1)
	outputs[0] region(71,17,17)
operator[13]: type(1)
	outputs[0] region(76,18,18)
operator[14]: type(1)
	outputs[0] region(81,19,19)
operator[15]: type(1)
	outputs[0] region(96,22,22)
operator[16]: type(1)
	outputs[0] region(101,23,23)
operator[17]: type(1)
	outputs[0] region(116,26,26)
operator[18]: type(1)
	outputs[0] region(121,27,27)
operator[19]: type(1)
	outputs[0] region(136,30,30)
operator[20]: type(1)
	outputs[0] region(141,31,31)
operator[21]: type(1)
	outputs[0] region(156,34,34)
operator[22]: type(1)
	outputs[0] region(161,35,35)
operator[23]: type(1)
	outputs[0] region(176,38,38)
operator[24]: type(1)
	outputs[0] region(181,39,39)
operator[25]: type(1)
	outputs[0] region(186,40,40)
operator[26]: type(1)
	outputs[0] region(201,43,43)
operator[27]: type(1)
	outputs[0] region(206,44,44)
operator[28]: type(1)
	outputs[0] region(221,47,47)
operator[29]: type(1)
	outputs[0] region(226,48,48)
operator[30]: type(1)
	outputs[0] region(241,51,51)
operator[31]: type(1)
	outputs[0] region(246,52,52)
operator[32]: type(1)
	outputs[0] region(261,55,55)
operator[33]: type(1)
	outputs[0] region(266,56,56)
operator[34]: type(1)
	outputs[0] region(281,59,59)
operator[35]: type(1)
	outputs[0] region(286,60,60)
operator[36]: type(1)
	outputs[0] region(291,61,61)
operator[37]: type(1)
	outputs[0] region(306,64,64)
operator[38]: type(1)
	outputs[0] region(311,65,65)
operator[39]: type(1)
	outputs[0] region(326,68,68)
operator[40]: type(1)
	outputs[0] region(331,69,69)
operator[41]: type(1)
	outputs[0] region(346,72,72)
operator[42]: type(1)
	outputs[0] region(351,73,73)
operator[43]: type(1)
	outputs[0] region(366,76,76)
operator[44]: type(1)
	outputs[0] region(371,77,77)
operator[45]: type(1)
	outputs[0] region(386,80,80)
operator[46]: type(1)
	outputs[0] region(391,81,81)
operator[47]: type(1)
	outputs[0] region(396,82,82)
operator[48]: type(1)
	outputs[0] region(411,85,85)
operator[49]: type(1)
	outputs[0] region(416,86,86)
operator[50]: type(1)
	outputs[0] region(431,89,89)
operator[51]: type(1)
	outputs[0] region(436,90,90)
operator[52]: type(1)
	outputs[0] region(451,93,93)
operator[53]: type(1)
	outputs[0] region(456,94,94)
operator[54]: type(1)
	outputs[0] region(471,97,97)
operator[55]: type(1)
	outputs[0] region(476,98,98)
operator[56]: type(1)
	outputs[0] region(491,101,101)
operator[57]: type(1)
	outputs[0] region(496,102,102)
operator[58]: type(1)
	outputs[0] region(501,103,103)
operator[59]: type(1)
	outputs[0] region(516,106,106)
operator[60]: type(1)
	outputs[0] region(521,107,107)
operator[61]: type(1)
	outputs[0] region(536,110,110)
operator[62]: type(1)
	outputs[0] region(541,111,111)
operator[63]: type(1)
	outputs[0] region(556,114,114)
operator[64]: type(1)
	outputs[0] region(561,115,115)
operator[65]: type(1)
	outputs[0] region(576,118,118)
operator[66]: type(1)
	outputs[0] region(581,119,119)
operator[67]: type(1)
	outputs[0] region(596,122,122)
operator[68]: type(1)
	outputs[0] region(601,123,123)
operator[69]: type(1)
	outputs[0] region(606,124,124)
operator[70]: type(1)
	outputs[0] region(621,127,127)
operator[71]: type(1)
	outputs[0] region(626,128,128)
operator[72]: type(1)
	outputs[0] region(641,131,131)
operator[73]: type(1)
	outputs[0] region(646,132,132)
operator[74]: type(1)
	outputs[0] region(661,135,135)
operator[75]: type(1)
	outputs[0] region(666,136,136)
operator[76]: type(1)
	outputs[0] region(681,139,139)
operator[77]: type(1)
	outputs[0] region(686,140,140)
operator[78]: type(1)
	outputs[0] region(701,143,143)
operator[79]: type(1)
	outputs[0] region(706,144,144)
operator[80]: type(1)
	outputs[0] region(711,145,145)
operator[81]: type(1)
	outputs[0] region(726,148,148)
operator[82]: type(1)
	outputs[0] region(731,149,149)
operator[83]: type(1)
	outputs[0] region(746,152,152)
operator[84]: type(1)
	outputs[0] region(751,153,153)
operator[85]: type(1)
	outputs[0] region(766,156,156)
operator[86]: type(1)
	outputs[0] region(771,157,157)
operator[87]: type(1)
	outputs[0] region(786,160,160)
operator[88]: type(1)
	outputs[0] region(791,161,161)
operator[89]: type(1)
	outputs[0] region(806,164,164)
operator[90]: type(1)
	outputs[0] region(811,165,165)
operator[91]: type(1)
	outputs[0] region(816,166,166)
operator[92]: type(1)
	outputs[0] region(831,169,169)
operator[93]: type(1)
	outputs[0] region(836,170,170)
operator[94]: type(1)
	outputs[0] region(851,173,173)
operator[95]: type(1)
	outputs[0] region(856,174,174)
operator[96]: type(1)
	outputs[0] region(871,177,177)
operator[97]: type(1)
	outputs[0] region(876,178,178)
operator[98]: type(1)
	outputs[0] region(891,181,181)
operator[99]: type(1)
	outputs[0] region(896,182,182)
operator[100]: type(1)
	outputs[0] region(911,185,185)
operator[101]: type(1)
	outputs[0] region(916,186,186)
operator[102]: type(1)
	outputs[0] region(921,187,187)
operator[103]: type(1)
	outputs[0] region(936,190,190)
operator[104]: type(1)
	outputs[0] region(941,191,191)
operator[105]: type(1)
	outputs[0] region(956,194,194)
operator[106]: type(1)
	outputs[0] region(961,195,195)
operator[107]: type(1)
	outputs[0] region(976,198,198)
operator[108]: type(1)
	outputs[0] region(981,199,199)
operator[109]: type(1)
	outputs[0] region(996,202,202)
operator[110]: type(1)
	outputs[0] region(1001,203,203)
operator[111]: type(1)
	outputs[0] region(1016,206,206)
operator[112]: type(1)
	outputs[0] region(1021,207,207)
operator[113]: type(1)
	outputs[0] region(1026,208,208)
operator[114]: type(1)
	outputs[0] region(1041,211,211)
operator[115]: type(1)
	outputs[0] region(1046,212,212)
operator[116]: type(1)
	outputs[0] region(1061,215,215)
operator[117]: type(1)
	outputs[0] region(1066,216,216)
operator[118]: type(1)
	outputs[0] region(1081,219,219)
operator[119]: type(1)
	outputs[0] region(1086,220,220)
operator[120]: type(1)
	outputs[0] region(1101,223,223)
operator[121]: type(1)
	outputs[0] region(1106,224,224)
operator[122]: type(1)
	outputs[0] region(1121,227,227)
operator[123]: type(1)
	outputs[0] region(1126,228,228)
operator[124]: type(1)
	outputs[0] region(1131,229,229)
operator[125]: type(1)
	outputs[0] region(1146,232,232)
operator[126]: type(1)
	outputs[0] region(1151,233,233)
operator[127]: type(1)
	outputs[0] region(1166,236,236)
operator[128]: type(1)
	outputs[0] region(1171,237,237)
operator[129]: type(1)
	outputs[0] region(1186,240,240)
operator[130]: type(1)
	outputs[0] region(1191,241,241)
operator[131]: type(1)
	outputs[0] region(1206,244,244)
operator[132]: type(1)
	outputs[0] region(1211,245,245)
operator[133]: type(1)
	outputs[0] region(1226,248,248)
operator[134]: type(1)
	outputs[0] region(1231,249,249)
operator[135]: type(1)
	outputs[0] region(1236,250,250)
operator[136]: type(1)
	outputs[0] region(1251,253,253)
operator[137]: type(1)
	outputs[0] region(1256,254,254)
operator[138]: type(1)
	outputs[0] region(1271,257,257)
operator[139]: type(1)
	outputs[0] region(1276,258,258)
operator[140]: type(1)
	outputs[0] region(1291,261,261)
operator[141]: type(1)
	outputs[0] region(1296,262,262)
operator[142]: type(1)
	outputs[0] region(1311,265,265)
operator[143]: type(1)
	outputs[0] region(1316,266,266)
operator[144]: type(1)
	outputs[0] region(1331,269,269)
operator[145]: type(1)
	outputs[0] region(1336,270,270)
operator[146]: type(1)
	outputs[0] region(1341,271,271)
operator[147]: type(1)
	outputs[0] region(1356,274,274)
operator[148]: type(1)
	outputs[0] region(1361,275,275)
operator[149]: type(1)
	outputs[0] region(1376,278,278)
operator[150]: type(1)
	outputs[0] region(1381,279,279)
operator[151]: type(1)
	outputs[0] region(1396,282,282)
operator[152]: type(1)
	outputs[0] region(1401,283,283)
operator[153]: type(1)
	outputs[0] region(1416,286,286)
operator[154]: type(1)
	outputs[0] region(1421,287,287)
operator[155]: type(1)
	outputs[0] region(1436,290,290)
operator[156]: type(1)
	outputs[0] region(1441,291,291)
operator[157]: type(1)
	outputs[0] region(1446,292,292)
operator[158]: type(1)
	outputs[0] region(1461,295,295)
operator[159]: type(1)
	outputs[0] region(1466,296,296)
operator[160]: type(1)
	outputs[0] region(1481,299,299)
operator[161]: type(1)
	outputs[0] region(1486,300,300)
operator[162]: type(1)
	outputs[0] region(1501,303,303)
operator[163]: type(1)
	outputs[0] region(1506,304,304)
operator[164]: type(1)
	outputs[0] region(1521,307,307)
operator[165]: type(1)
	outputs[0] region(1526,308,308)
operator[166]: type(1)
	outputs[0] region(1541,311,311)
operator[167]: type(1)
	outputs[0] region(1546,312,312)
operator[168]: type(1)
	outputs[0] region(1551,313,313)
operator[169]: type(1)
	outputs[0] region(1566,316,316)
operator[170]: type(1)
	outputs[0] region(1571,317,317)
operator[171]: type(1)
	outputs[0] region(1586,320,320)
operator[172]: type(1)
	outputs[0] region(1591,321,321)
operator[173]: type(1)
	outputs[0] region(1606,324,324)
operator[174]: type(1)
	outputs[0] region(1611,325,325)
operator[175]: type(1)
	outputs[0] region(1626,328,328)
operator[176]: type(1)
	outputs[0] region(1631,329,329)
operator[177]: type(1)
	outputs[0] region(1646,332,332)
operator[178]: type(1)
	outputs[0] region(1651,333,333)
operator[179]: type(1)
	outputs[0] region(1656,334,334)
operator[180]: type(1)
	outputs[0] region(1671,337,337)
operator[181]: type(1)
	outputs[0] region(1676,338,338)
operator[182]: type(1)
	outputs[0] region(1691,341,341)
operator[183]: type(1)
	outputs[0] region(1696,342,342)
operator[184]: type(1)
	outputs[0] region(1711,345,345)
operator[185]: type(1)
	outputs[0] region(1716,346,346)
operator[186]: type(1)
	outputs[0] region(1731,349,349)
operator[187]: type(1)
	outputs[0] region(1736,350,350)
operator[188]: type(1)
	outputs[0] region(1751,353,353)
operator[189]: type(1)
	outputs[0] region(1756,354,354)
operator[190]: type(1)
	outputs[0] region(1761,355,355)
operator[191]: type(1)
	outputs[0] region(1776,358,358)
operator[192]: type(1)
	outputs[0] region(1781,359,359)
operator[193]: type(1)
	outputs[0] region(1796,362,362)
operator[194]: type(1)
	outputs[0] region(1801,363,363)
operator[195]: type(1)
	outputs[0] region(1816,366,366)
operator[196]: type(1)
	outputs[0] region(1821,367,367)
operator[197]: type(1)
	outputs[0] region(1836,370,370)
operator[198]: type(1)
	outputs[0] region(1841,371,371)
operator[199]: type(1)
	outputs[0] region(1856,374,374)
operator[200]: type(1)
	outputs[0] region(1861,375,375)
operator[201]: type(1)
	outputs[0] region(1866,376,376)
operator[202]: type(1)
	outputs[0] region(1881,379,379)
operator[203]: type(1)
	outputs[0] region(1886,380,380)
operator[204]: type(1)
	outputs[0] region(1901,383,383)
operator[205]: type(1)
	outputs[0] region(1906,384,384)
operator[206]: type(1)
	outputs[0] region(1921,387,387)
operator[207]: type(1)
	outputs[0] region(1926,388,388)
operator[208]: type(1)
	outputs[0] region(1941,391,391)
operator[209]: type(1)
	outputs[0] region(1946,392,392)
operator[210]: type(1)
	outputs[0] region(1961,395,395)
operator[211]: type(1)
	outputs[0] region(1966,396,396)
operator[212]: type(1)
	outputs[0] region(1971,397,397)
operator[213]: type(1)
	outputs[0] region(1986,400,400)
operator[214]: type(1)
	outputs[0] region(1991,401,401)
operator[215]: type(1)
	outputs[0] region(2006,404,404)
operator[216]: type(1)
	outputs[0] region(2011,405,405)
operator[217]: type(1)
	outputs[0] region(2026,408,408)
operator[218]: type(1)
	outputs[0] region(2031,409,409)
operator[219]: type(1)
	outputs[0] region(2046,412,412)
operator[220]: type(1)
	outputs[0] region(2051,413,413)
operator[221]: type(1)
	outputs[0] region(2066,416,416)
operator[222]: type(1)
	outputs[0] region(2071,417,417)
operator[223]: type(1)
	outputs[0] region(2076,418,418)
operator[224]: type(1)
	outputs[0] region(2091,421,421)
operator[225]: type(1)
	outputs[0] region(2096,422,422)
operator[226]: type(1)
	outputs[0] region(2111,425,425)
operator[227]: type(1)
	outputs[0] region(2116,426,426)
operator[228]: type(1)
	outputs[0] region(2131,429,429)
operator[229]: type(1)
	outputs[0] region(2136,430,430)
operator[230]: type(1)
	outputs[0] region(2151,433,433)
operator[231]: type(1)
	outputs[0] region(2156,434,434)
operator[232]: type(1)
	outputs[0] region(2171,437,437)
operator[233]: type(1)
	outputs[0] region(2176,438,438)
operator[234]: type(1)
	outputs[0] region(2181,439,439)
operator[235]: type(1)
	outputs[0] region(2196,442,442)
operator[236]: type(1)
	outputs[0] region(2201,443,443)
operator[237]: type(1)
	outputs[0] region(2216,446,446)
operator[238]: type(1)
	outputs[0] region(2221,447,447)
operator[239]: type(1)
	outputs[0] region(2236,450,450)
operator[240]: type(1)
	outputs[0] region(2241,451,451)
operator[241]: type(1)
	outputs[0] region(2256,454,454)
operator[242]: type(1)
	outputs[0] region(2261,455,455)
operator[243]: type(1)
	outputs[0] region(2276,458,458)
operator[244]: type(1)
	outputs[0] region(2281,459,459)
operator[245]: type(1)
	outputs[0] region(2286,460,460)
operator[246]: type(1)
	outputs[0] region(2301,463,463)
operator[247]: type(1)
	outputs[0] region(2306,464,464)
operator[248]: type(1)
	outputs[0] region(2321,467,467)
operator[249]: type(1)
	outputs[0] region(2326,468,468)
operator[250]: type(1)
	outputs[0] region(2341,471,471)
operator[251]: type(1)
	outputs[0] region(2346,472,472)
operator[252]: type(1)
	outputs[0] region(2361,475,475)
operator[253]: type(1)
	outputs[0] region(2366,476,476)
operator[254]: type(1)
	outputs[0] region(2381,479,479)
operator[255]: type(1)
	outputs[0] region(2386,480,480)
operator[256]: type(1)
	outputs[0] region(2391,481,481)
operator[257]: type(1)
	outputs[0] region(2406,484,484)
operator[258]: type(1)
	outputs[0] region(2411,485,485)
operator[259]: type(1)
	outputs[0] region(2426,488,488)
operator[260]: type(1)
	outputs[0] region(2431,489,489)
operator[261]: type(1)
	outputs[0] region(2446,492,492)
operator[262]: type(1)
	outputs[0] region(2451,493,493)
operator[263]: type(1)
	outputs[0] region(2466,496,496)
operator[264]: type(1)
	outputs[0] region(2471,497,497)
operator[265]: type(1)
	outputs[0] region(2486,500,500)
operator[266]: type(1)
	outputs[0] region(2491,501,501)
operator[267]: type(1)
	outputs[0] region(2496,502,502)
operator[268]: type(1)
	outputs[0] region(2511,505,505)
operator[269]: type(1)
	outputs[0] region(2516,506,506)
operator[270]: type(1)
	outputs[0] region(2531,509,509)
operator[271]: type(1)
	outputs[0] region(2536,510,510)
operator[272]: type(1)
	outputs[0] region(2551,513,513)
operator[273]: type(1)
	outputs[0] region(2556,514,514)
operator[274]: type(1)
	outputs[0] region(2571,517,517)
operator[275]: type(1)
	outputs[0] region(2576,518,518)
operator[276]: type(1)
	outputs[0] region(2591,521,521)
operator[277]: type(1)
	outputs[0] region(2596,522,522)
operator[278]: type(1)
	outputs[0] region(2601,523,523)
operator[279]: type(1)
	outputs[0] region(2616,526,526)
operator[280]: type(1)
	outputs[0] region(2621,527,527)
operator[281]: type(1)
	outputs[0] region(2636,530,530)
operator[282]: type(1)
	outputs[0] region(2641,531,531)
operator[283]: type(1)
	outputs[0] region(2656,534,534)
operator[284]: type(1)
	outputs[0] region(2661,535,535)
operator[285]: type(1)
	outputs[0] region(2676,538,538)
operator[286]: type(1)
	outputs[0] region(2681,539,539)
operator[287]: type(1)
	outputs[0] region(2696,542,542)
operator[288]: type(1)
	outputs[0] region(2701,543,543)
operator[289]: type(1)
	outputs[0] region(2706,544,544)
operator[290]: type(1)
	outputs[0] region(2721,547,547)
operator[291]: type(1)
	outputs[0] region(2726,548,548)
operator[292]: type(1)
	outputs[0] region(2741,551,551)
operator[293]: type(1)
	outputs[0] region(2746,552,552)
operator[294]: type(1)
	outputs[0] region(2761,555,555)
operator[295]: type(1)
	outputs[0] region(2766,556,556)
operator[296]: type(1)
	outputs[0] region(2781,559,559)
operator[297]: type(1)
	outputs[0] region(2786,560,560)
operator[298]: type(1)
	outputs[0] region(2801,563,563)
operator[299]: type(1)
	outputs[0] region(2806,564,564)
operator[300]: type(1)
	outputs[0] region(2811,565,565)
operator[301]: type(1)
	outputs[0] region(2826,568,568)
operator[302]: type(1)
	outputs[0] region(2831,569,569)
operator[303]: type(1)
	outputs[0] region(2846,572,572)
operator[304]: type(1)
	outputs[0] region(2851,573,573)
operator[305]: type(1)
	outputs[0] region(2866,576,576)
operator[306]: type(1)
	outputs[0] region(2871,577,577)
operator[307]: type(1)
	outputs[0] region(2886,580,580)
operator[308]: type(1)
	outputs[0] region(2891,581,581)
operator[309]: type(1)
	outputs[0] region(2906,584,584)
operator[310]: type(1)
	outputs[0] region(2911,585,585)
operator[311]: type(1)
	outputs[0] region(2916,586,586)
operator[312]: type(1)
	outputs[0] region(2931,589,589)
operator[313]: type(1)
	outputs[0] region(2936,590,590)
operator[314]: type(1)
	outputs[0] region(2951,593,593)
operator[315]: type(1)
	outputs[0] region(2956,594,594)
operator[316]: type(1)
	outputs[0] region(2971,597,597)
operator[317]: type(1)
	outputs[0] region(2976,598,598)
operator[318]: type(1)
	outputs[0] region(2991,601,601)
operator[319]: type(1)
	outputs[0] region(2996,602,602)
operator[320]: type(1)
	outputs[0] region(3011,605,605)
operator[321]: type(1)
	outputs[0] region(3016,606,606)
operator[322]: type(1)
	outputs[0] region(3021,607,607)
operator[323]: type(1)
	outputs[0] region(3036,610,610)
operator[324]: type(1)
	outputs[0] region(3041,611,611)
operator[325]: type(1)
	outputs[0] region(3056,614,614)
operator[326]: type(1)
	outputs[0] region(3061,615,615)
operator[327]: type(1)
	outputs[0] region(3076,618,618)
operator[328]: type(1)
	outputs[0] region(3081,619,619)
operator[329]: type(1)
	outputs[0] region(3096,622,622)
operator[330]: type(1)
	outputs[0] region(3101,623,623)
operator[331]: type(1)
	outputs[0] region(3116,626,626)
operator[332]: type(1)
	outputs[0] region(3121,627,627)
operator[333]: type(1)
	outputs[0] region(3126,628,628)
operator[334]: type(1)
	outputs[0] region(3141,631,631)
operator[335]: type(1)
	outputs[0] region(3146,632,632)
operator[336]: type(1)
	outputs[0] region(3161,635,635)
operator[337]: type(1)
	outputs[0] region(3166,636,636)
operator[338]: type(1)
	outputs[0] region(3181,639,639)
operator[339]: type(1)
	outputs[0] region(3186,640,640)
operator[340]: type(1)
	outputs[0] region(3201,643,643)
operator[341]: type(1)
	outputs[0] region(3206,644,644)
operator[342]: type(1)
	outputs[0] region(3221,647,647)
operator[343]: type(1)
	outputs[0] region(3226,648,648)
operator[344]: type(1)
	outputs[0] region(3231,649,649)
operator[345]: type(1)
	outputs[0] region(3246,652,652)
operator[346]: type(1)
	outputs[0] region(3251,653,653)
operator[347]: type(1)
	outputs[0] region(3266,656,656)
operator[348]: type(1)
	outputs[0] region(3271,657,657)
operator[349]: type(1)
	outputs[0] region(3286,660,660)
operator[350]: type(1)
	outputs[0] region(3291,661,661)
operator[351]: type(1)
	outputs[0] region(3306,664,664)
operator[352]: type(1)
	outputs[0] region(3311,665,665)
operator[353]: type(1)
	outputs[0] region(3326,668,668)
operator[354]: type(1)
	outputs[0] region(3331,669,669)
operator[355]: type(1)
	outputs[0] region(3336,670,670)
operator[356]: type(1)
	outputs[0] region(3351,673,673)
operator[357]: type(1)
	outputs[0] region(3356,674,674)
operator[358]: type(1)
	outputs[0] region(3371,677,677)
operator[359]: type(1)
	outputs[0] region(3376,678,678)
operator[360]: type(1)
	outputs[0] region(3391,681,681)
operator[361]: type(1)
	outputs[0] region(3396,682,682)
operator[362]: type(1)
	outputs[0] region(3411,685,685)
operator[363]: type(1)
	outputs[0] region(3416,686,686)
operator[364]: type(1)
	outputs[0] region(3431,689,689)
operator[365]: type(1)
	outputs[0] region(3436,690,690)
operator[366]: type(1)
	outputs[0] region(3441,691,691)
operator[367]: type(1)
	outputs[0] region(3456,694,694)
operator[368]: type(1)
	outputs[0] region(3461,695,695)
operator[369]: type(1)
	outputs[0] region(3476,698,698)
operator[370]: type(1)
	outputs[0] region(3481,699,699)
operator[371]: type(1)
	outputs[0] region(3496,702,702)
operator[372]: type(1)
	outputs[0] region(3501,703,703)
operator[373]: type(1)
	outputs[0] region(3516,706,706)
operator[374]: type(1)
	outputs[0] region(3521,707,707)
operator[375]: type(1)
	outputs[0] region(3536,710,710)
operator[376]: type(1)
	outputs[0] region(3541,711,711)
operator[377]: type(1)
	outputs[0] region(3546,712,712)
operator[378]: type(1)
	outputs[0] region(3561,715,715)
operator[379]: type(1)
	outputs[0] region(3566,716,716)
operator[380]: type(1)
	outputs[0] region(3581,719,719)
operator[381]: type(1)
	outputs[0] region(3586,720,720)
operator[382]: type(1)
	outputs[0] region(3601,723,723)
operator[383]: type(1)
	outputs[0] region(3606,724,724)
operator[384]: type(1)
	outputs[0] region(3621,727,727)
operator[385]: type(1)
	outputs[0] region(3626,728,728)
operator[386]: type(1)
	outputs[0] region(3641,731,731)
operator[387]: type(1)
	outputs[0] region(3646,732,732)
operator[388]: type(1)
	outputs[0] region(3651,733,733)
operator[389]: type(1)
	outputs[0] region(3666,736,736)
operator[390]: type(1)
	outputs[0] region(3671,737,737)
operator[391]: type(1)
	outputs[0] region(3686,740,740)
operator[392]: type(1)
	outputs[0] region(3691,741,741)
operator[393]: type(1)
	outputs[0] region(3706,744,744)
operator[394]: type(1)
	outputs[0] region(3711,745,745)
operator[395]: type(1)
	outputs[0] region(3726,748,748)
operator[396]: type(1)
	outputs[0] region(3731,749,749)
operator[397]: type(1)
	outputs[0] region(3746,752,752)
operator[398]: type(1)
	outputs[0] region(3751,753,753)
operator[399]: type(1)
	outputs[0] region(3756,754,754)
operator[400]: type(1)
	outputs[0] region(3771,757,757)
operator[401]: type(1)
	outputs[0] region(3776,758,758)
operator[402]: type(1)
	outputs[0] region(3791,761,761)
operator[403]: type(1)
	outputs[0] region(3796,762,762)
operator[404]: type(1)
	outputs[0] region(3811,765,765)
operator[405]: type(1)
	outputs[0] region(3816,766,766)
operator[406]: type(1)
	outputs[0] region(3831,769,769)
operator[407]: type(1)
	outputs[0] region(3836,770,770)
operator[408]: type(1)
	outputs[0] region(3851,773,773)
operator[409]: type(1)
	outputs[0] region(3856,774,774)
operator[410]: type(1)
	outputs[0] region(3861,775,775)
operator[411]: type(1)
	outputs[0] region(3876,778,778)
operator[412]: type(1)
	outputs[0] region(3881,779,779)
operator[413]: type(1)
	outputs[0] region(3896,782,782)
operator[414]: type(1)
	outputs[0] region(3901,783,783)
operator[415]: type(1)
	outputs[0] region(3916,786,786)
operator[416]: type(1)
	outputs[0] region(3921,787,787)
operator[417]: type(1)
	outputs[0] region(3936,790,790)
operator[418]: type(1)
	outputs[0] region(3941,791,791)
operator[419]: type(1)
	outputs[0] region(3956,794,794)
operator[420]: type(1)
	outputs[0] region(3961,795,795)
operator[421]: type(1)
	outputs[0] region(3966,796,796)
operator[422]: type(1)
	outputs[0] region(3981,799,799)
operator[423]: type(1)
	outputs[0] region(3986,800,800)
operator[424]: type(1)
	outputs[0] region(4001,803,803)
operator[425]: type(1)
	outputs[0] region(4006,804,804)
operator[426]: type(1)
	outputs[0] region(4021,807,807)
operator[427]: type(1)
	outputs[0] region(4026,808,808)
operator[428]: type(1)
	outputs[0] region(4041,811,811)
operator[429]: type(1)
	outputs[0] region(4046,812,812)
operator[430]: type(1)
	outputs[0] region(4061,815,815)
operator[431]: type(1)
	outputs[0] region(4066,816,816)
operator[432]: type(1)
	outputs[0] region(4071,817,817)
operator[433]: type(1)
	outputs[0] region(4086,820,820)
operator[434]: type(1)
	outputs[0] region(4091,821,821)
operator[435]: type(1)
	outputs[0] region(4106,824,824)
operator[436]: type(1)
	outputs[0] region(4111,825,825)
operator[437]: type(1)
	outputs[0] region(4126,828,828)
operator[438]: type(1)
	outputs[0] region(4131,829,829)
operator[439]: type(1)
	outputs[0] region(4146,832,832)
operator[440]: type(1)
	outputs[0] region(4151,833,833)
operator[441]: type(1)
	outputs[0] region(4166,836,836)
operator[442]: type(1)
	outputs[0] region(4171,837,837)
operator[443]: type(1)
	outputs[0] region(4176,838,838)
operator[444]: type(1)
	outputs[0] region(4191,841,841)
operator[445]: type(1)
	outputs[0] region(4196,842,842)
operator[446]: type(1)
	outputs[0] region(4211,845,845)
operator[447]: type(1)
	outputs[0] region(4216,846,846)
operator[448]: type(1)
	outputs[0] region(4231,849,849)
operator[449]: type(1)
	outputs[0] region(4236,850,850)
operator[450]: type(1)
	outputs[0] region(4251,853,853)
operator[451]: type(97)
	inputs[0] region(4256,854,854)
	outputs[0] region(4261,855,855)
operator[452]: type(91)
	inputs[0] region(4261,855,855)
	outputs[0] region(4263,856,856)
Loading weight file embed_tokens_weight
Loading weight file embed_positions_weight
Loading weight file layers_0_attention_layer_norm_weight
Loading weight file layers_0_attention_layer_norm_bias
Loading weight file layers_0_attention_wq_weight
Loading weight file layers_0_attention_wk_weight
Loading weight file layers_0_attention_wv_weight
Loading weight file layers_0_attention_wo_weight
Loading weight file layers_0_attention_wq_bias
Loading weight file layers_0_attention_wk_bias
Loading weight file layers_0_attention_wv_bias
Loading weight file layers_0_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_0_add_bias_residual_layer_norm_weight
Loading weight file layers_0_add_bias_residual_layer_norm_bias
Loading weight file layers_0_fc1_weight
Loading weight file layers_0_fc1_bias
Loading weight file layers_0_fc2_weight
Loading weight file layers_0_fc2_bias
Loading weight file layers_1_attention_layer_norm_weight
Loading weight file layers_1_attention_layer_norm_bias
Loading weight file layers_1_attention_wq_weight
Loading weight file layers_1_attention_wk_weight
Loading weight file layers_1_attention_wv_weight
Loading weight file layers_1_attention_wo_weight
Loading weight file layers_1_attention_wq_bias
Loading weight file layers_1_attention_wk_bias
Loading weight file layers_1_attention_wv_bias
Loading weight file layers_1_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_1_add_bias_residual_layer_norm_weight
Loading weight file layers_1_add_bias_residual_layer_norm_bias
Loading weight file layers_1_fc1_weight
Loading weight file layers_1_fc1_bias
Loading weight file layers_1_fc2_weight
Loading weight file layers_1_fc2_bias
Loading weight file layers_2_attention_layer_norm_weight
Loading weight file layers_2_attention_layer_norm_bias
Loading weight file layers_2_attention_wq_weight
Loading weight file layers_2_attention_wk_weight
Loading weight file layers_2_attention_wv_weight
Loading weight file layers_2_attention_wo_weight
Loading weight file layers_2_attention_wq_bias
Loading weight file layers_2_attention_wk_bias
Loading weight file layers_2_attention_wv_bias
Loading weight file layers_2_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_2_add_bias_residual_layer_norm_weight
Loading weight file layers_2_add_bias_residual_layer_norm_bias
Loading weight file layers_2_fc1_weight
Loading weight file layers_2_fc1_bias
Loading weight file layers_2_fc2_weight
Loading weight file layers_2_fc2_bias
Loading weight file layers_3_attention_layer_norm_weight
Loading weight file layers_3_attention_layer_norm_bias
Loading weight file layers_3_attention_wq_weight
Loading weight file layers_3_attention_wk_weight
Loading weight file layers_3_attention_wv_weight
Loading weight file layers_3_attention_wo_weight
Loading weight file layers_3_attention_wq_bias
Loading weight file layers_3_attention_wk_bias
Loading weight file layers_3_attention_wv_bias
Loading weight file layers_3_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_3_add_bias_residual_layer_norm_weight
Loading weight file layers_3_add_bias_residual_layer_norm_bias
Loading weight file layers_3_fc1_weight
Loading weight file layers_3_fc1_bias
Loading weight file layers_3_fc2_weight
Loading weight file layers_3_fc2_bias
Loading weight file layers_4_attention_layer_norm_weight
Loading weight file layers_4_attention_layer_norm_bias
Loading weight file layers_4_attention_wq_weight
Loading weight file layers_4_attention_wk_weight
Loading weight file layers_4_attention_wv_weight
Loading weight file layers_4_attention_wo_weight
Loading weight file layers_4_attention_wq_bias
Loading weight file layers_4_attention_wk_bias
Loading weight file layers_4_attention_wv_bias
Loading weight file layers_4_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_4_add_bias_residual_layer_norm_weight
Loading weight file layers_4_add_bias_residual_layer_norm_bias
Loading weight file layers_4_fc1_weight
Loading weight file layers_4_fc1_bias
Loading weight file layers_4_fc2_weight
Loading weight file layers_4_fc2_bias
Loading weight file layers_5_attention_layer_norm_weight
Loading weight file layers_5_attention_layer_norm_bias
Loading weight file layers_5_attention_wq_weight
Loading weight file layers_5_attention_wk_weight
Loading weight file layers_5_attention_wv_weight
Loading weight file layers_5_attention_wo_weight
Loading weight file layers_5_attention_wq_bias
Loading weight file layers_5_attention_wk_bias
Loading weight file layers_5_attention_wv_bias
Loading weight file layers_5_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_5_add_bias_residual_layer_norm_weight
Loading weight file layers_5_add_bias_residual_layer_norm_bias
Loading weight file layers_5_fc1_weight
Loading weight file layers_5_fc1_bias
Loading weight file layers_5_fc2_weight
Loading weight file layers_5_fc2_bias
Loading weight file layers_6_attention_layer_norm_weight
Loading weight file layers_6_attention_layer_norm_bias
Loading weight file layers_6_attention_wq_weight
Loading weight file layers_6_attention_wk_weight
Loading weight file layers_6_attention_wv_weight
Loading weight file layers_6_attention_wo_weight
Loading weight file layers_6_attention_wq_bias
Loading weight file layers_6_attention_wk_bias
Loading weight file layers_6_attention_wv_bias
Loading weight file layers_6_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_6_add_bias_residual_layer_norm_weight
Loading weight file layers_6_add_bias_residual_layer_norm_bias
Loading weight file layers_6_fc1_weight
Loading weight file layers_6_fc1_bias
Loading weight file layers_6_fc2_weight
Loading weight file layers_6_fc2_bias
Loading weight file layers_7_attention_layer_norm_weight
Loading weight file layers_7_attention_layer_norm_bias
Loading weight file layers_7_attention_wq_weight
Loading weight file layers_7_attention_wk_weight
Loading weight file layers_7_attention_wv_weight
Loading weight file layers_7_attention_wo_weight
Loading weight file layers_7_attention_wq_bias
Loading weight file layers_7_attention_wk_bias
Loading weight file layers_7_attention_wv_bias
Loading weight file layers_7_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_7_add_bias_residual_layer_norm_weight
Loading weight file layers_7_add_bias_residual_layer_norm_bias
Loading weight file layers_7_fc1_weight
Loading weight file layers_7_fc1_bias
Loading weight file layers_7_fc2_weight
Loading weight file layers_7_fc2_bias
Loading weight file layers_8_attention_layer_norm_weight
Loading weight file layers_8_attention_layer_norm_bias
Loading weight file layers_8_attention_wq_weight
Loading weight file layers_8_attention_wk_weight
Loading weight file layers_8_attention_wv_weight
Loading weight file layers_8_attention_wo_weight
Loading weight file layers_8_attention_wq_bias
Loading weight file layers_8_attention_wk_bias
Loading weight file layers_8_attention_wv_bias
Loading weight file layers_8_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_8_add_bias_residual_layer_norm_weight
Loading weight file layers_8_add_bias_residual_layer_norm_bias
Loading weight file layers_8_fc1_weight
Loading weight file layers_8_fc1_bias
Loading weight file layers_8_fc2_weight
Loading weight file layers_8_fc2_bias
Loading weight file layers_9_attention_layer_norm_weight
Loading weight file layers_9_attention_layer_norm_bias
Loading weight file layers_9_attention_wq_weight
Loading weight file layers_9_attention_wk_weight
Loading weight file layers_9_attention_wv_weight
Loading weight file layers_9_attention_wo_weight
Loading weight file layers_9_attention_wq_bias
Loading weight file layers_9_attention_wk_bias
Loading weight file layers_9_attention_wv_bias
Loading weight file layers_9_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_9_add_bias_residual_layer_norm_weight
Loading weight file layers_9_add_bias_residual_layer_norm_bias
Loading weight file layers_9_fc1_weight
Loading weight file layers_9_fc1_bias
Loading weight file layers_9_fc2_weight
Loading weight file layers_9_fc2_bias
Loading weight file layers_10_attention_layer_norm_weight
Loading weight file layers_10_attention_layer_norm_bias
Loading weight file layers_10_attention_wq_weight
Loading weight file layers_10_attention_wk_weight
Loading weight file layers_10_attention_wv_weight
Loading weight file layers_10_attention_wo_weight
Loading weight file layers_10_attention_wq_bias
Loading weight file layers_10_attention_wk_bias
Loading weight file layers_10_attention_wv_bias
Loading weight file layers_10_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_10_add_bias_residual_layer_norm_weight
Loading weight file layers_10_add_bias_residual_layer_norm_bias
Loading weight file layers_10_fc1_weight
Loading weight file layers_10_fc1_bias
Loading weight file layers_10_fc2_weight
Loading weight file layers_10_fc2_bias
Loading weight file layers_11_attention_layer_norm_weight
Loading weight file layers_11_attention_layer_norm_bias
Loading weight file layers_11_attention_wq_weight
Loading weight file layers_11_attention_wk_weight
Loading weight file layers_11_attention_wv_weight
Loading weight file layers_11_attention_wo_weight
Loading weight file layers_11_attention_wq_bias
Loading weight file layers_11_attention_wk_bias
Loading weight file layers_11_attention_wv_bias
Loading weight file layers_11_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_11_add_bias_residual_layer_norm_weight
Loading weight file layers_11_add_bias_residual_layer_norm_bias
Loading weight file layers_11_fc1_weight
Loading weight file layers_11_fc1_bias
Loading weight file layers_11_fc2_weight
Loading weight file layers_11_fc2_bias
Loading weight file layers_12_attention_layer_norm_weight
Loading weight file layers_12_attention_layer_norm_bias
Loading weight file layers_12_attention_wq_weight
Loading weight file layers_12_attention_wk_weight
Loading weight file layers_12_attention_wv_weight
Loading weight file layers_12_attention_wo_weight
Loading weight file layers_12_attention_wq_bias
Loading weight file layers_12_attention_wk_bias
Loading weight file layers_12_attention_wv_bias
Loading weight file layers_12_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_12_add_bias_residual_layer_norm_weight
Loading weight file layers_12_add_bias_residual_layer_norm_bias
Loading weight file layers_12_fc1_weight
Loading weight file layers_12_fc1_bias
Loading weight file layers_12_fc2_weight
Loading weight file layers_12_fc2_bias
Loading weight file layers_13_attention_layer_norm_weight
Loading weight file layers_13_attention_layer_norm_bias
Loading weight file layers_13_attention_wq_weight
Loading weight file layers_13_attention_wk_weight
Loading weight file layers_13_attention_wv_weight
Loading weight file layers_13_attention_wo_weight
Loading weight file layers_13_attention_wq_bias
Loading weight file layers_13_attention_wk_bias
Loading weight file layers_13_attention_wv_bias
Loading weight file layers_13_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_13_add_bias_residual_layer_norm_weight
Loading weight file layers_13_add_bias_residual_layer_norm_bias
Loading weight file layers_13_fc1_weight
Loading weight file layers_13_fc1_bias
Loading weight file layers_13_fc2_weight
Loading weight file layers_13_fc2_bias
Loading weight file layers_14_attention_layer_norm_weight
Loading weight file layers_14_attention_layer_norm_bias
Loading weight file layers_14_attention_wq_weight
Loading weight file layers_14_attention_wk_weight
Loading weight file layers_14_attention_wv_weight
Loading weight file layers_14_attention_wo_weight
Loading weight file layers_14_attention_wq_bias
Loading weight file layers_14_attention_wk_bias
Loading weight file layers_14_attention_wv_bias
Loading weight file layers_14_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_14_add_bias_residual_layer_norm_weight
Loading weight file layers_14_add_bias_residual_layer_norm_bias
Loading weight file layers_14_fc1_weight
Loading weight file layers_14_fc1_bias
Loading weight file layers_14_fc2_weight
Loading weight file layers_14_fc2_bias
Loading weight file layers_15_attention_layer_norm_weight
Loading weight file layers_15_attention_layer_norm_bias
Loading weight file layers_15_attention_wq_weight
Loading weight file layers_15_attention_wk_weight
Loading weight file layers_15_attention_wv_weight
Loading weight file layers_15_attention_wo_weight
Loading weight file layers_15_attention_wq_bias
Loading weight file layers_15_attention_wk_bias
Loading weight file layers_15_attention_wv_bias
Loading weight file layers_15_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_15_add_bias_residual_layer_norm_weight
Loading weight file layers_15_add_bias_residual_layer_norm_bias
Loading weight file layers_15_fc1_weight
Loading weight file layers_15_fc1_bias
Loading weight file layers_15_fc2_weight
Loading weight file layers_15_fc2_bias
Loading weight file layers_16_attention_layer_norm_weight
Loading weight file layers_16_attention_layer_norm_bias
Loading weight file layers_16_attention_wq_weight
Loading weight file layers_16_attention_wk_weight
Loading weight file layers_16_attention_wv_weight
Loading weight file layers_16_attention_wo_weight
Loading weight file layers_16_attention_wq_bias
Loading weight file layers_16_attention_wk_bias
Loading weight file layers_16_attention_wv_bias
Loading weight file layers_16_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_16_add_bias_residual_layer_norm_weight
Loading weight file layers_16_add_bias_residual_layer_norm_bias
Loading weight file layers_16_fc1_weight
Loading weight file layers_16_fc1_bias
Loading weight file layers_16_fc2_weight
Loading weight file layers_16_fc2_bias
Loading weight file layers_17_attention_layer_norm_weight
Loading weight file layers_17_attention_layer_norm_bias
Loading weight file layers_17_attention_wq_weight
Loading weight file layers_17_attention_wk_weight
Loading weight file layers_17_attention_wv_weight
Loading weight file layers_17_attention_wo_weight
Loading weight file layers_17_attention_wq_bias
Loading weight file layers_17_attention_wk_bias
Loading weight file layers_17_attention_wv_bias
Loading weight file layers_17_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_17_add_bias_residual_layer_norm_weight
Loading weight file layers_17_add_bias_residual_layer_norm_bias
Loading weight file layers_17_fc1_weight
Loading weight file layers_17_fc1_bias
Loading weight file layers_17_fc2_weight
Loading weight file layers_17_fc2_bias
Loading weight file layers_18_attention_layer_norm_weight
Loading weight file layers_18_attention_layer_norm_bias
Loading weight file layers_18_attention_wq_weight
Loading weight file layers_18_attention_wk_weight
Loading weight file layers_18_attention_wv_weight
Loading weight file layers_18_attention_wo_weight
Loading weight file layers_18_attention_wq_bias
Loading weight file layers_18_attention_wk_bias
Loading weight file layers_18_attention_wv_bias
Loading weight file layers_18_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_18_add_bias_residual_layer_norm_weight
Loading weight file layers_18_add_bias_residual_layer_norm_bias
Loading weight file layers_18_fc1_weight
Loading weight file layers_18_fc1_bias
Loading weight file layers_18_fc2_weight
Loading weight file layers_18_fc2_bias
Loading weight file layers_19_attention_layer_norm_weight
Loading weight file layers_19_attention_layer_norm_bias
Loading weight file layers_19_attention_wq_weight
Loading weight file layers_19_attention_wk_weight
Loading weight file layers_19_attention_wv_weight
Loading weight file layers_19_attention_wo_weight
Loading weight file layers_19_attention_wq_bias
Loading weight file layers_19_attention_wk_bias
Loading weight file layers_19_attention_wv_bias
Loading weight file layers_19_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_19_add_bias_residual_layer_norm_weight
Loading weight file layers_19_add_bias_residual_layer_norm_bias
Loading weight file layers_19_fc1_weight
Loading weight file layers_19_fc1_bias
Loading weight file layers_19_fc2_weight
Loading weight file layers_19_fc2_bias
Loading weight file layers_20_attention_layer_norm_weight
Loading weight file layers_20_attention_layer_norm_bias
Loading weight file layers_20_attention_wq_weight
Loading weight file layers_20_attention_wk_weight
Loading weight file layers_20_attention_wv_weight
Loading weight file layers_20_attention_wo_weight
Loading weight file layers_20_attention_wq_bias
Loading weight file layers_20_attention_wk_bias
Loading weight file layers_20_attention_wv_bias
Loading weight file layers_20_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_20_add_bias_residual_layer_norm_weight
Loading weight file layers_20_add_bias_residual_layer_norm_bias
Loading weight file layers_20_fc1_weight
Loading weight file layers_20_fc1_bias
Loading weight file layers_20_fc2_weight
Loading weight file layers_20_fc2_bias
Loading weight file layers_21_attention_layer_norm_weight
Loading weight file layers_21_attention_layer_norm_bias
Loading weight file layers_21_attention_wq_weight
Loading weight file layers_21_attention_wk_weight
Loading weight file layers_21_attention_wv_weight
Loading weight file layers_21_attention_wo_weight
Loading weight file layers_21_attention_wq_bias
Loading weight file layers_21_attention_wk_bias
Loading weight file layers_21_attention_wv_bias
Loading weight file layers_21_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_21_add_bias_residual_layer_norm_weight
Loading weight file layers_21_add_bias_residual_layer_norm_bias
Loading weight file layers_21_fc1_weight
Loading weight file layers_21_fc1_bias
Loading weight file layers_21_fc2_weight
Loading weight file layers_21_fc2_bias
Loading weight file layers_22_attention_layer_norm_weight
Loading weight file layers_22_attention_layer_norm_bias
Loading weight file layers_22_attention_wq_weight
Loading weight file layers_22_attention_wk_weight
Loading weight file layers_22_attention_wv_weight
Loading weight file layers_22_attention_wo_weight
Loading weight file layers_22_attention_wq_bias
Loading weight file layers_22_attention_wk_bias
Loading weight file layers_22_attention_wv_bias
Loading weight file layers_22_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_22_add_bias_residual_layer_norm_weight
Loading weight file layers_22_add_bias_residual_layer_norm_bias
Loading weight file layers_22_fc1_weight
Loading weight file layers_22_fc1_bias
Loading weight file layers_22_fc2_weight
Loading weight file layers_22_fc2_bias
Loading weight file layers_23_attention_layer_norm_weight
Loading weight file layers_23_attention_layer_norm_bias
Loading weight file layers_23_attention_wq_weight
Loading weight file layers_23_attention_wk_weight
Loading weight file layers_23_attention_wv_weight
Loading weight file layers_23_attention_wo_weight
Loading weight file layers_23_attention_wq_bias
Loading weight file layers_23_attention_wk_bias
Loading weight file layers_23_attention_wv_bias
Loading weight file layers_23_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_23_add_bias_residual_layer_norm_weight
Loading weight file layers_23_add_bias_residual_layer_norm_bias
Loading weight file layers_23_fc1_weight
Loading weight file layers_23_fc1_bias
Loading weight file layers_23_fc2_weight
Loading weight file layers_23_fc2_bias
Loading weight file layers_24_attention_layer_norm_weight
Loading weight file layers_24_attention_layer_norm_bias
Loading weight file layers_24_attention_wq_weight
Loading weight file layers_24_attention_wk_weight
Loading weight file layers_24_attention_wv_weight
Loading weight file layers_24_attention_wo_weight
Loading weight file layers_24_attention_wq_bias
Loading weight file layers_24_attention_wk_bias
Loading weight file layers_24_attention_wv_bias
Loading weight file layers_24_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_24_add_bias_residual_layer_norm_weight
Loading weight file layers_24_add_bias_residual_layer_norm_bias
Loading weight file layers_24_fc1_weight
Loading weight file layers_24_fc1_bias
Loading weight file layers_24_fc2_weight
Loading weight file layers_24_fc2_bias
Loading weight file layers_25_attention_layer_norm_weight
Loading weight file layers_25_attention_layer_norm_bias
Loading weight file layers_25_attention_wq_weight
Loading weight file layers_25_attention_wk_weight
Loading weight file layers_25_attention_wv_weight
Loading weight file layers_25_attention_wo_weight
Loading weight file layers_25_attention_wq_bias
Loading weight file layers_25_attention_wk_bias
Loading weight file layers_25_attention_wv_bias
Loading weight file layers_25_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_25_add_bias_residual_layer_norm_weight
Loading weight file layers_25_add_bias_residual_layer_norm_bias
Loading weight file layers_25_fc1_weight
Loading weight file layers_25_fc1_bias
Loading weight file layers_25_fc2_weight
Loading weight file layers_25_fc2_bias
Loading weight file layers_26_attention_layer_norm_weight
Loading weight file layers_26_attention_layer_norm_bias
Loading weight file layers_26_attention_wq_weight
Loading weight file layers_26_attention_wk_weight
Loading weight file layers_26_attention_wv_weight
Loading weight file layers_26_attention_wo_weight
Loading weight file layers_26_attention_wq_bias
Loading weight file layers_26_attention_wk_bias
Loading weight file layers_26_attention_wv_bias
Loading weight file layers_26_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_26_add_bias_residual_layer_norm_weight
Loading weight file layers_26_add_bias_residual_layer_norm_bias
Loading weight file layers_26_fc1_weight
Loading weight file layers_26_fc1_bias
Loading weight file layers_26_fc2_weight
Loading weight file layers_26_fc2_bias
Loading weight file layers_27_attention_layer_norm_weight
Loading weight file layers_27_attention_layer_norm_bias
Loading weight file layers_27_attention_wq_weight
Loading weight file layers_27_attention_wk_weight
Loading weight file layers_27_attention_wv_weight
Loading weight file layers_27_attention_wo_weight
Loading weight file layers_27_attention_wq_bias
Loading weight file layers_27_attention_wk_bias
Loading weight file layers_27_attention_wv_bias
Loading weight file layers_27_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_27_add_bias_residual_layer_norm_weight
Loading weight file layers_27_add_bias_residual_layer_norm_bias
Loading weight file layers_27_fc1_weight
Loading weight file layers_27_fc1_bias
Loading weight file layers_27_fc2_weight
Loading weight file layers_27_fc2_bias
Loading weight file layers_28_attention_layer_norm_weight
Loading weight file layers_28_attention_layer_norm_bias
Loading weight file layers_28_attention_wq_weight
Loading weight file layers_28_attention_wk_weight
Loading weight file layers_28_attention_wv_weight
Loading weight file layers_28_attention_wo_weight
Loading weight file layers_28_attention_wq_bias
Loading weight file layers_28_attention_wk_bias
Loading weight file layers_28_attention_wv_bias
Loading weight file layers_28_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_28_add_bias_residual_layer_norm_weight
Loading weight file layers_28_add_bias_residual_layer_norm_bias
Loading weight file layers_28_fc1_weight
Loading weight file layers_28_fc1_bias
Loading weight file layers_28_fc2_weight
Loading weight file layers_28_fc2_bias
Loading weight file layers_29_attention_layer_norm_weight
Loading weight file layers_29_attention_layer_norm_bias
Loading weight file layers_29_attention_wq_weight
Loading weight file layers_29_attention_wk_weight
Loading weight file layers_29_attention_wv_weight
Loading weight file layers_29_attention_wo_weight
Loading weight file layers_29_attention_wq_bias
Loading weight file layers_29_attention_wk_bias
Loading weight file layers_29_attention_wv_bias
Loading weight file layers_29_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_29_add_bias_residual_layer_norm_weight
Loading weight file layers_29_add_bias_residual_layer_norm_bias
Loading weight file layers_29_fc1_weight
Loading weight file layers_29_fc1_bias
Loading weight file layers_29_fc2_weight
Loading weight file layers_29_fc2_bias
Loading weight file layers_30_attention_layer_norm_weight
Loading weight file layers_30_attention_layer_norm_bias
Loading weight file layers_30_attention_wq_weight
Loading weight file layers_30_attention_wk_weight
Loading weight file layers_30_attention_wv_weight
Loading weight file layers_30_attention_wo_weight
Loading weight file layers_30_attention_wq_bias
Loading weight file layers_30_attention_wk_bias
Loading weight file layers_30_attention_wv_bias
Loading weight file layers_30_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_30_add_bias_residual_layer_norm_weight
Loading weight file layers_30_add_bias_residual_layer_norm_bias
Loading weight file layers_30_fc1_weight
Loading weight file layers_30_fc1_bias
Loading weight file layers_30_fc2_weight
Loading weight file layers_30_fc2_bias
Loading weight file layers_31_attention_layer_norm_weight
Loading weight file layers_31_attention_layer_norm_bias
Loading weight file layers_31_attention_wq_weight
Loading weight file layers_31_attention_wk_weight
Loading weight file layers_31_attention_wv_weight
Loading weight file layers_31_attention_wo_weight
Loading weight file layers_31_attention_wq_bias
Loading weight file layers_31_attention_wk_bias
Loading weight file layers_31_attention_wv_bias
Loading weight file layers_31_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_31_add_bias_residual_layer_norm_weight
Loading weight file layers_31_add_bias_residual_layer_norm_bias
Loading weight file layers_31_fc1_weight
Loading weight file layers_31_fc1_bias
Loading weight file layers_31_fc2_weight
Loading weight file layers_31_fc2_bias
Loading weight file layers_32_attention_layer_norm_weight
Loading weight file layers_32_attention_layer_norm_bias
Loading weight file layers_32_attention_wq_weight
Loading weight file layers_32_attention_wk_weight
Loading weight file layers_32_attention_wv_weight
Loading weight file layers_32_attention_wo_weight
Loading weight file layers_32_attention_wq_bias
Loading weight file layers_32_attention_wk_bias
Loading weight file layers_32_attention_wv_bias
Loading weight file layers_32_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_32_add_bias_residual_layer_norm_weight
Loading weight file layers_32_add_bias_residual_layer_norm_bias
Loading weight file layers_32_fc1_weight
Loading weight file layers_32_fc1_bias
Loading weight file layers_32_fc2_weight
Loading weight file layers_32_fc2_bias
Loading weight file layers_33_attention_layer_norm_weight
Loading weight file layers_33_attention_layer_norm_bias
Loading weight file layers_33_attention_wq_weight
Loading weight file layers_33_attention_wk_weight
Loading weight file layers_33_attention_wv_weight
Loading weight file layers_33_attention_wo_weight
Loading weight file layers_33_attention_wq_bias
Loading weight file layers_33_attention_wk_bias
Loading weight file layers_33_attention_wv_bias
Loading weight file layers_33_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_33_add_bias_residual_layer_norm_weight
Loading weight file layers_33_add_bias_residual_layer_norm_bias
Loading weight file layers_33_fc1_weight
Loading weight file layers_33_fc1_bias
Loading weight file layers_33_fc2_weight
Loading weight file layers_33_fc2_bias
Loading weight file layers_34_attention_layer_norm_weight
Loading weight file layers_34_attention_layer_norm_bias
Loading weight file layers_34_attention_wq_weight
Loading weight file layers_34_attention_wk_weight
Loading weight file layers_34_attention_wv_weight
Loading weight file layers_34_attention_wo_weight
Loading weight file layers_34_attention_wq_bias
Loading weight file layers_34_attention_wk_bias
Loading weight file layers_34_attention_wv_bias
Loading weight file layers_34_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_34_add_bias_residual_layer_norm_weight
Loading weight file layers_34_add_bias_residual_layer_norm_bias
Loading weight file layers_34_fc1_weight
Loading weight file layers_34_fc1_bias
Loading weight file layers_34_fc2_weight
Loading weight file layers_34_fc2_bias
Loading weight file layers_35_attention_layer_norm_weight
Loading weight file layers_35_attention_layer_norm_bias
Loading weight file layers_35_attention_wq_weight
Loading weight file layers_35_attention_wk_weight
Loading weight file layers_35_attention_wv_weight
Loading weight file layers_35_attention_wo_weight
Loading weight file layers_35_attention_wq_bias
Loading weight file layers_35_attention_wk_bias
Loading weight file layers_35_attention_wv_bias
Loading weight file layers_35_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_35_add_bias_residual_layer_norm_weight
Loading weight file layers_35_add_bias_residual_layer_norm_bias
Loading weight file layers_35_fc1_weight
Loading weight file layers_35_fc1_bias
Loading weight file layers_35_fc2_weight
Loading weight file layers_35_fc2_bias
Loading weight file layers_36_attention_layer_norm_weight
Loading weight file layers_36_attention_layer_norm_bias
Loading weight file layers_36_attention_wq_weight
Loading weight file layers_36_attention_wk_weight
Loading weight file layers_36_attention_wv_weight
Loading weight file layers_36_attention_wo_weight
Loading weight file layers_36_attention_wq_bias
Loading weight file layers_36_attention_wk_bias
Loading weight file layers_36_attention_wv_bias
Loading weight file layers_36_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_36_add_bias_residual_layer_norm_weight
Loading weight file layers_36_add_bias_residual_layer_norm_bias
Loading weight file layers_36_fc1_weight
Loading weight file layers_36_fc1_bias
Loading weight file layers_36_fc2_weight
Loading weight file layers_36_fc2_bias
Loading weight file layers_37_attention_layer_norm_weight
Loading weight file layers_37_attention_layer_norm_bias
Loading weight file layers_37_attention_wq_weight
Loading weight file layers_37_attention_wk_weight
Loading weight file layers_37_attention_wv_weight
Loading weight file layers_37_attention_wo_weight
Loading weight file layers_37_attention_wq_bias
Loading weight file layers_37_attention_wk_bias
Loading weight file layers_37_attention_wv_bias
Loading weight file layers_37_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_37_add_bias_residual_layer_norm_weight
Loading weight file layers_37_add_bias_residual_layer_norm_bias
Loading weight file layers_37_fc1_weight
Loading weight file layers_37_fc1_bias
Loading weight file layers_37_fc2_weight
Loading weight file layers_37_fc2_bias
Loading weight file layers_38_attention_layer_norm_weight
Loading weight file layers_38_attention_layer_norm_bias
Loading weight file layers_38_attention_wq_weight
Loading weight file layers_38_attention_wk_weight
Loading weight file layers_38_attention_wv_weight
Loading weight file layers_38_attention_wo_weight
Loading weight file layers_38_attention_wq_bias
Loading weight file layers_38_attention_wk_bias
Loading weight file layers_38_attention_wv_bias
Loading weight file layers_38_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_38_add_bias_residual_layer_norm_weight
Loading weight file layers_38_add_bias_residual_layer_norm_bias
Loading weight file layers_38_fc1_weight
Loading weight file layers_38_fc1_bias
Loading weight file layers_38_fc2_weight
Loading weight file layers_38_fc2_bias
Loading weight file layers_39_attention_layer_norm_weight
Loading weight file layers_39_attention_layer_norm_bias
Loading weight file layers_39_attention_wq_weight
Loading weight file layers_39_attention_wk_weight
Loading weight file layers_39_attention_wv_weight
Loading weight file layers_39_attention_wo_weight
Loading weight file layers_39_attention_wq_bias
Loading weight file layers_39_attention_wk_bias
Loading weight file layers_39_attention_wv_bias
Loading weight file layers_39_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_39_add_bias_residual_layer_norm_weight
Loading weight file layers_39_add_bias_residual_layer_norm_bias
Loading weight file layers_39_fc1_weight
Loading weight file layers_39_fc1_bias
Loading weight file layers_39_fc2_weight
Loading weight file layers_39_fc2_bias
Loading weight file final_layer_norm_weight
Loading weight file final_layer_norm_bias
Loading weight file embed_tokens_weight_lm_head
------finished loading weights----------
[0 - 7f442c744000]   60.802276 {3}{spec_infer}: LLM create_opt_model finished!
[0 - 7f442c744000]   60.805200 {3}{opt}: These are OPT model config:
OPT Config:
	do_layer_norm_before: 1
	dropout: 0.1
	enable_bias: 1
	ffn_dim: 3072
	hidden_size: 768
	layer_norm_elementwise_affine: 1
	max_position_embeddings: 2048
	num_attention_heads: 12
	num_hidden_layers: 12
	vocab_size: 50272
	word_embed_proj_dim: 768
	max_beam_width: 1
	max_beam_depth: 8
------start compile ----------
spec create operator: layers_0_attention_1000005
spec create operator: layers_1_attention_1000011
spec create operator: layers_2_attention_1000017
spec create operator: layers_3_attention_1000023
spec create operator: layers_4_attention_1000029
spec create operator: layers_5_attention_1000035
spec create operator: layers_6_attention_1000041
spec create operator: layers_7_attention_1000047
spec create operator: layers_8_attention_1000053
spec create operator: layers_9_attention_1000059
spec create operator: layers_10_attention_1000065
spec create operator: layers_11_attention_1000071
num_nodes = 1 num_gpus_per_node = 4
optimal_views.size = 80
views.size() = 80
Deserialized Views...
node[5000117]: type(Dense_5000117) view(1 1 0)  inEdge(node(5000116) idx(1))
node[5000116]: type(AddBiasResidualLayerNorm_5000116) view(1 1 0)  inEdge(node(5000114) idx(0)) inEdge(node(5000115) idx(0))
node[5000115]: type(SpecIncMultiHeadSelfAttention_5000115) view(1 1 0)  inEdge(node(5000114) idx(1))
node[5000114]: type(ResidualLayerNorm_5000114) view(1 1 0)  inEdge(node(5000113) idx(0)) inEdge(node(5000110) idx(0))
node[5000113]: type(Dense_5000113) view(1 1 0)  inEdge(node(5000112) idx(0))
node[5000112]: type(ReLU_5000112) view(1 1 0)  inEdge(node(5000111) idx(0))
node[5000111]: type(Dense_5000111) view(1 1 0)  inEdge(node(5000110) idx(1))
node[5000110]: type(AddBiasResidualLayerNorm_5000110) view(1 1 0)  inEdge(node(5000108) idx(0)) inEdge(node(5000109) idx(0))
node[5000109]: type(SpecIncMultiHeadSelfAttention_5000109) view(1 1 0)  inEdge(node(5000108) idx(1))
node[5000088]: type(ReLU_5000088) view(1 1 0)  inEdge(node(5000087) idx(0))
node[5000147]: type(Dense_5000147) view(1 1 0)  inEdge(node(5000146) idx(1))
node[5000089]: type(Dense_5000089) view(1 1 0)  inEdge(node(5000088) idx(0))
node[5000148]: type(ReLU_5000148) view(1 1 0)  inEdge(node(5000147) idx(0))
node[5000090]: type(ResidualLayerNorm_5000090) view(1 1 0)  inEdge(node(5000089) idx(0)) inEdge(node(5000086) idx(0))
node[5000149]: type(Dense_5000149) view(1 1 0)  inEdge(node(5000148) idx(0))
node[5000091]: type(SpecIncMultiHeadSelfAttention_5000091) view(1 1 0)  inEdge(node(5000090) idx(1))
node[5000150]: type(ResidualLayerNorm_5000150) view(1 1 0)  inEdge(node(5000149) idx(0)) inEdge(node(5000146) idx(0))
node[5000092]: type(AddBiasResidualLayerNorm_5000092) view(1 1 0)  inEdge(node(5000090) idx(0)) inEdge(node(5000091) idx(0))
node[5000151]: type(SpecIncMultiHeadSelfAttention_5000151) view(1 1 0)  inEdge(node(5000150) idx(1))
node[5000093]: type(Dense_5000093) view(1 1 0)  inEdge(node(5000092) idx(1))
node[5000152]: type(AddBiasResidualLayerNorm_5000152) view(1 1 0)  inEdge(node(5000150) idx(0)) inEdge(node(5000151) idx(0))
node[5000139]: type(SpecIncMultiHeadSelfAttention_5000139) view(1 1 0)  inEdge(node(5000138) idx(1))
node[5000080]: type(Input_5000080) view(1 1 0) 
node[5000118]: type(ReLU_5000118) view(1 1 0)  inEdge(node(5000117) idx(0))
node[5000119]: type(Dense_5000119) view(1 1 0)  inEdge(node(5000118) idx(0))
node[5000120]: type(ResidualLayerNorm_5000120) view(1 1 0)  inEdge(node(5000119) idx(0)) inEdge(node(5000116) idx(0))
node[5000121]: type(SpecIncMultiHeadSelfAttention_5000121) view(1 1 0)  inEdge(node(5000120) idx(1))
node[5000122]: type(AddBiasResidualLayerNorm_5000122) view(1 1 0)  inEdge(node(5000120) idx(0)) inEdge(node(5000121) idx(0))
node[5000123]: type(Dense_5000123) view(1 1 0)  inEdge(node(5000122) idx(1))
node[5000124]: type(ReLU_5000124) view(1 1 0)  inEdge(node(5000123) idx(0))
node[5000125]: type(Dense_5000125) view(1 1 0)  inEdge(node(5000124) idx(0))
node[5000138]: type(ResidualLayerNorm_5000138) view(1 1 0)  inEdge(node(5000137) idx(0)) inEdge(node(5000134) idx(0))
node[5000108]: type(ResidualLayerNorm_5000108) view(1 1 0)  inEdge(node(5000107) idx(0)) inEdge(node(5000104) idx(0))
node[5000137]: type(Dense_5000137) view(1 1 0)  inEdge(node(5000136) idx(0))
node[5000107]: type(Dense_5000107) view(1 1 0)  inEdge(node(5000106) idx(0))
node[5000136]: type(ReLU_5000136) view(1 1 0)  inEdge(node(5000135) idx(0))
node[5000106]: type(ReLU_5000106) view(1 1 0)  inEdge(node(5000105) idx(0))
node[5000135]: type(Dense_5000135) view(1 1 0)  inEdge(node(5000134) idx(1))
node[5000105]: type(Dense_5000105) view(1 1 0)  inEdge(node(5000104) idx(1))
node[5000134]: type(AddBiasResidualLayerNorm_5000134) view(1 1 0)  inEdge(node(5000132) idx(0)) inEdge(node(5000133) idx(0))
node[5000104]: type(AddBiasResidualLayerNorm_5000104) view(1 1 0)  inEdge(node(5000102) idx(0)) inEdge(node(5000103) idx(0))
node[5000133]: type(SpecIncMultiHeadSelfAttention_5000133) view(1 1 0)  inEdge(node(5000132) idx(1))
node[5000103]: type(SpecIncMultiHeadSelfAttention_5000103) view(1 1 0)  inEdge(node(5000102) idx(1))
node[5000132]: type(ResidualLayerNorm_5000132) view(1 1 0)  inEdge(node(5000131) idx(0)) inEdge(node(5000128) idx(0))
node[5000102]: type(ResidualLayerNorm_5000102) view(1 1 0)  inEdge(node(5000101) idx(0)) inEdge(node(5000098) idx(0))
node[5000131]: type(Dense_5000131) view(1 1 0)  inEdge(node(5000130) idx(0))
node[5000130]: type(ReLU_5000130) view(1 1 0)  inEdge(node(5000129) idx(0))
node[5000129]: type(Dense_5000129) view(1 1 0)  inEdge(node(5000128) idx(1))
node[5000128]: type(AddBiasResidualLayerNorm_5000128) view(1 1 0)  inEdge(node(5000126) idx(0)) inEdge(node(5000127) idx(0))
node[5000127]: type(SpecIncMultiHeadSelfAttention_5000127) view(1 1 0)  inEdge(node(5000126) idx(1))
node[5000126]: type(ResidualLayerNorm_5000126) view(1 1 0)  inEdge(node(5000125) idx(0)) inEdge(node(5000122) idx(0))
node[5000140]: type(AddBiasResidualLayerNorm_5000140) view(1 1 0)  inEdge(node(5000138) idx(0)) inEdge(node(5000139) idx(0))
node[5000081]: type(Input_5000081) view(1 1 0) 
node[5000141]: type(Dense_5000141) view(1 1 0)  inEdge(node(5000140) idx(1))
node[5000082]: type(Embedding_5000082) view(1 1 0)  inEdge(node(5000080) idx(0))
node[5000142]: type(ReLU_5000142) view(1 1 0)  inEdge(node(5000141) idx(0))
node[5000083]: type(Embedding_5000083) view(1 1 0)  inEdge(node(5000081) idx(0))
node[5000143]: type(Dense_5000143) view(1 1 0)  inEdge(node(5000142) idx(0))
node[5000084]: type(ResidualLayerNorm_5000084) view(1 1 0)  inEdge(node(5000083) idx(0)) inEdge(node(5000082) idx(0))
node[5000144]: type(ResidualLayerNorm_5000144) view(1 1 0)  inEdge(node(5000143) idx(0)) inEdge(node(5000140) idx(0))
node[5000085]: type(SpecIncMultiHeadSelfAttention_5000085) view(1 1 0)  inEdge(node(5000084) idx(1))
node[5000145]: type(SpecIncMultiHeadSelfAttention_5000145) view(1 1 0)  inEdge(node(5000144) idx(1))
node[5000086]: type(AddBiasResidualLayerNorm_5000086) view(1 1 0)  inEdge(node(5000084) idx(0)) inEdge(node(5000085) idx(0))
node[5000146]: type(AddBiasResidualLayerNorm_5000146) view(1 1 0)  inEdge(node(5000144) idx(0)) inEdge(node(5000145) idx(0))
node[5000087]: type(Dense_5000087) view(1 1 0)  inEdge(node(5000086) idx(1))
node[5000101]: type(Dense_5000101) view(1 1 0)  inEdge(node(5000100) idx(0))
node[5000159]: type(ArgMax_5000159) view(1 1 0)  inEdge(node(5000158) idx(0))
node[5000100]: type(ReLU_5000100) view(1 1 0)  inEdge(node(5000099) idx(0))
node[5000158]: type(Softmax_5000158) view(1 1 0)  inEdge(node(5000157) idx(0))
node[5000099]: type(Dense_5000099) view(1 1 0)  inEdge(node(5000098) idx(1))
node[5000157]: type(Dense_5000157) view(1 1 0)  inEdge(node(5000156) idx(1))
node[5000098]: type(AddBiasResidualLayerNorm_5000098) view(1 1 0)  inEdge(node(5000096) idx(0)) inEdge(node(5000097) idx(0))
node[5000156]: type(ResidualLayerNorm_5000156) view(1 1 0)  inEdge(node(5000155) idx(0)) inEdge(node(5000152) idx(0))
node[5000097]: type(SpecIncMultiHeadSelfAttention_5000097) view(1 1 0)  inEdge(node(5000096) idx(1))
node[5000155]: type(Dense_5000155) view(1 1 0)  inEdge(node(5000154) idx(0))
node[5000096]: type(ResidualLayerNorm_5000096) view(1 1 0)  inEdge(node(5000095) idx(0)) inEdge(node(5000092) idx(0))
node[5000154]: type(ReLU_5000154) view(1 1 0)  inEdge(node(5000153) idx(0))
node[5000095]: type(Dense_5000095) view(1 1 0)  inEdge(node(5000094) idx(0))
node[5000153]: type(Dense_5000153) view(1 1 0)  inEdge(node(5000152) idx(1))
node[5000094]: type(ReLU_5000094) view(1 1 0)  inEdge(node(5000093) idx(0))
digraph taskgraph {
  node0 [label="{ ResidualLayerNorm_5000138 }",shape=record];
  node1 -> node0;
  node2 -> node0;
  node2 [label="{ Dense_5000137 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node3 -> node2;
  node3 [label="{ ReLU_5000136 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node4 -> node3;
  node4 [label="{ Dense_5000135 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node1 -> node4;
  node1 [label="{ AddBiasResidualLayerNorm_5000134 }",shape=record];
  node5 -> node1;
  node6 -> node1;
  node5 [label="{ SpecIncMultiHeadSelfAttention_5000133 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node6 -> node5;
  node6 [label="{ ResidualLayerNorm_5000132 }",shape=record];
  node7 -> node6;
  node8 -> node6;
  node8 [label="{ Dense_5000131 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node9 -> node8;
  node9 [label="{ ReLU_5000130 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node10 -> node9;
  node10 [label="{ Dense_5000129 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node7 -> node10;
  node7 [label="{ AddBiasResidualLayerNorm_5000128 }",shape=record];
  node11 -> node7;
  node12 -> node7;
  node11 [label="{ SpecIncMultiHeadSelfAttention_5000127 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node12 -> node11;
  node12 [label="{ ResidualLayerNorm_5000126 }",shape=record];
  node13 -> node12;
  node14 -> node12;
  node14 [label="{ Dense_5000125 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node15 -> node14;
  node15 [label="{ ReLU_5000124 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node16 -> node15;
  node16 [label="{ Dense_5000123 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node13 -> node16;
  node13 [label="{ AddBiasResidualLayerNorm_5000122 }",shape=record];
  node17 -> node13;
  node18 -> node13;
  node17 [label="{ SpecIncMultiHeadSelfAttention_5000121 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node18 -> node17;
  node18 [label="{ ResidualLayerNorm_5000120 }",shape=record];
  node19 -> node18;
  node20 -> node18;
  node20 [label="{ Dense_5000119 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node21 -> node20;
  node21 [label="{ ReLU_5000118 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node22 -> node21;
  node23 [label="{ ResidualLayerNorm_5000102 }",shape=record];
  node24 -> node23;
  node25 -> node23;
  node26 [label="{ SpecIncMultiHeadSelfAttention_5000103 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node23 -> node26;
  node27 [label="{ AddBiasResidualLayerNorm_5000104 }",shape=record];
  node26 -> node27;
  node23 -> node27;
  node28 [label="{ Dense_5000105 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node27 -> node28;
  node29 [label="{ ReLU_5000106 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node28 -> node29;
  node30 [label="{ Dense_5000107 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node29 -> node30;
  node31 [label="{ ResidualLayerNorm_5000108 }",shape=record];
  node27 -> node31;
  node30 -> node31;
  node32 [label="{ SpecIncMultiHeadSelfAttention_5000139 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node0 -> node32;
  node33 [label="{ Input_5000080 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node34 [label="{ AddBiasResidualLayerNorm_5000140 }",shape=record];
  node32 -> node34;
  node0 -> node34;
  node35 [label="{ Input_5000081 | { shape([ 1/1 256/1 1/1 ]) } }",shape=record];
  node36 [label="{ Dense_5000141 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node34 -> node36;
  node37 [label="{ Embedding_5000082 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node33 -> node37;
  node38 [label="{ ReLU_5000142 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node36 -> node38;
  node39 [label="{ Embedding_5000083 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node35 -> node39;
  node40 [label="{ Dense_5000143 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node38 -> node40;
  node41 [label="{ ResidualLayerNorm_5000084 }",shape=record];
  node37 -> node41;
  node39 -> node41;
  node42 [label="{ ResidualLayerNorm_5000144 }",shape=record];
  node34 -> node42;
  node40 -> node42;
  node43 [label="{ SpecIncMultiHeadSelfAttention_5000085 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node41 -> node43;
  node44 [label="{ SpecIncMultiHeadSelfAttention_5000145 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node42 -> node44;
  node45 [label="{ AddBiasResidualLayerNorm_5000086 }",shape=record];
  node43 -> node45;
  node41 -> node45;
  node46 [label="{ AddBiasResidualLayerNorm_5000146 }",shape=record];
  node44 -> node46;
  node42 -> node46;
  node47 [label="{ Dense_5000087 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node45 -> node47;
  node25 [label="{ Dense_5000101 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node48 -> node25;
  node49 [label="{ ArgMax_5000159 }",shape=record];
  node50 -> node49;
  node48 [label="{ ReLU_5000100 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node51 -> node48;
  node50 [label="{ Softmax_5000158 | { 50272/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node52 -> node50;
  node51 [label="{ Dense_5000099 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node24 -> node51;
  node52 [label="{ Dense_5000157 | { 50272/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node53 -> node52;
  node24 [label="{ AddBiasResidualLayerNorm_5000098 }",shape=record];
  node54 -> node24;
  node55 -> node24;
  node53 [label="{ ResidualLayerNorm_5000156 }",shape=record];
  node56 -> node53;
  node57 -> node53;
  node54 [label="{ SpecIncMultiHeadSelfAttention_5000097 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node55 -> node54;
  node57 [label="{ Dense_5000155 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node58 -> node57;
  node55 [label="{ ResidualLayerNorm_5000096 }",shape=record];
  node59 -> node55;
  node60 -> node55;
  node58 [label="{ ReLU_5000154 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node61 -> node58;
  node60 [label="{ Dense_5000095 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node62 -> node60;
  node61 [label="{ Dense_5000153 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node56 -> node61;
  node62 [label="{ ReLU_5000094 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node63 -> node62;
  node56 [label="{ AddBiasResidualLayerNorm_5000152 }",shape=record];
  node64 -> node56;
  node65 -> node56;
  node63 [label="{ Dense_5000093 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node59 -> node63;
  node64 [label="{ SpecIncMultiHeadSelfAttention_5000151 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node65 -> node64;
  node59 [label="{ AddBiasResidualLayerNorm_5000092 }",shape=record];
  node66 -> node59;
  node67 -> node59;
  node65 [label="{ ResidualLayerNorm_5000150 }",shape=record];
  node46 -> node65;
  node68 -> node65;
  node66 [label="{ SpecIncMultiHeadSelfAttention_5000091 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node67 -> node66;
  node68 [label="{ Dense_5000149 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node69 -> node68;
  node67 [label="{ ResidualLayerNorm_5000090 }",shape=record];
  node45 -> node67;
  node70 -> node67;
  node69 [label="{ ReLU_5000148 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node71 -> node69;
  node70 [label="{ Dense_5000089 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node72 -> node70;
  node71 [label="{ Dense_5000147 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node46 -> node71;
  node72 [label="{ ReLU_5000088 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node47 -> node72;
  node73 [label="{ SpecIncMultiHeadSelfAttention_5000109 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node31 -> node73;
  node74 [label="{ AddBiasResidualLayerNorm_5000110 }",shape=record];
  node73 -> node74;
  node31 -> node74;
  node75 [label="{ Dense_5000111 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node74 -> node75;
  node76 [label="{ ReLU_5000112 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node75 -> node76;
  node77 [label="{ Dense_5000113 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node76 -> node77;
  node78 [label="{ ResidualLayerNorm_5000114 }",shape=record];
  node74 -> node78;
  node77 -> node78;
  node79 [label="{ SpecIncMultiHeadSelfAttention_5000115 | { 768/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node78 -> node79;
  node19 [label="{ AddBiasResidualLayerNorm_5000116 }",shape=record];
  node79 -> node19;
  node78 -> node19;
  node22 [label="{ Dense_5000117 | { 3072/1 | 1/1 | 256/1 | 1/1 } }",shape=record];
  node19 -> node22;
}
ndim(1) dims[1 0 0 0]
operator[0]: type(Input) guid(2000160)
	outputs[0] region(4276,857,1268)
operator[1]: type(Input) guid(2000161)
	outputs[0] region(4278,858,1269)
operator[2]: type(Weight) guid(2000163)
	outputs[0] region(4280,859,1270)
operator[3]: type(FusedOp) guid(2000377)
	inputs[0] region(4276,857,1268)
	inputs[1] region(4278,858,1269)
	outputs[0] region(4282,860,1271)
	outputs[1] region(4286,862,1273)
	outputs[2] region(4292,865,1276)
	outputs[3] region(4294,866,1277)
	outputs[4] region(4300,869,1280)
	outputs[5] region(4308,873,1284)
	outputs[6] region(4310,874,1285)
	outputs[7] region(4316,877,1288)
	outputs[8] region(4318,878,1289)
	outputs[9] region(4324,881,1292)
	outputs[10] region(4330,884,1295)
	outputs[11] region(4332,885,1296)
	outputs[12] region(4338,888,1299)
	outputs[13] region(4346,892,1303)
	outputs[14] region(4348,893,1304)
	outputs[15] region(4354,896,1307)
	outputs[16] region(4356,897,1308)
	outputs[17] region(4362,900,1311)
	outputs[18] region(4368,903,1314)
	outputs[19] region(4370,904,1315)
	outputs[20] region(4376,907,1318)
	outputs[21] region(4384,911,1322)
	outputs[22] region(4386,912,1323)
	outputs[23] region(4392,915,1326)
	outputs[24] region(4394,916,1327)
	outputs[25] region(4400,919,1330)
	outputs[26] region(4406,922,1333)
	outputs[27] region(4408,923,1334)
	outputs[28] region(4414,926,1337)
	outputs[29] region(4422,930,1341)
	outputs[30] region(4424,931,1342)
	outputs[31] region(4430,934,1345)
	outputs[32] region(4432,935,1346)
	outputs[33] region(4438,938,1349)
	outputs[34] region(4444,941,1352)
	outputs[35] region(4446,942,1353)
	outputs[36] region(4452,945,1356)
	outputs[37] region(4460,949,1360)
	outputs[38] region(4462,950,1361)
	outputs[39] region(4468,953,1364)
	outputs[40] region(4470,954,1365)
	outputs[41] region(4476,957,1368)
	outputs[42] region(4482,960,1371)
	outputs[43] region(4484,961,1372)
	outputs[44] region(4490,964,1375)
	outputs[45] region(4498,968,1379)
	outputs[46] region(4500,969,1380)
	outputs[47] region(4506,972,1383)
	outputs[48] region(4508,973,1384)
	outputs[49] region(4514,976,1387)
	outputs[50] region(4520,979,1390)
	outputs[51] region(4522,980,1391)
	outputs[52] region(4528,983,1394)
	outputs[53] region(4536,987,1398)
	outputs[54] region(4538,988,1399)
	outputs[55] region(4544,991,1402)
	outputs[56] region(4546,992,1403)
	outputs[57] region(4552,995,1406)
	outputs[58] region(4558,998,1409)
	outputs[59] region(4560,999,1410)
	outputs[60] region(4566,1002,1413)
	outputs[61] region(4574,1006,1417)
	outputs[62] region(4576,1007,1418)
	outputs[63] region(4582,1010,1421)
	outputs[64] region(4584,1011,1422)
	outputs[65] region(4590,1014,1425)
	outputs[66] region(4596,1017,1428)
	outputs[67] region(4598,1018,1429)
	outputs[68] region(4604,1021,1432)
	outputs[69] region(4612,1025,1436)
	outputs[70] region(4614,1026,1437)
	outputs[71] region(4620,1029,1440)
	outputs[72] region(4622,1030,1441)
	outputs[73] region(4628,1033,1444)
	outputs[74] region(4634,1036,1447)
	outputs[75] region(4636,1037,1448)
	outputs[76] region(4642,1040,1451)
	outputs[77] region(4650,1044,1455)
	outputs[78] region(4652,1045,1456)
	outputs[79] region(4658,1048,1459)
	outputs[80] region(4660,1049,1460)
	outputs[81] region(4666,1052,1463)
	outputs[82] region(4672,1055,1466)
	outputs[83] region(4674,1056,1467)
	outputs[84] region(4680,1059,1470)
	outputs[85] region(4688,1063,1474)
	outputs[86] region(4690,1064,1475)
	outputs[87] region(4696,1067,1478)
	outputs[88] region(4698,1068,1479)
	outputs[89] region(4704,1071,1482)
	outputs[90] region(4710,1074,1485)
	outputs[91] region(4712,1075,1486)
	outputs[92] region(4718,1078,1489)
	outputs[93] region(4726,1082,1493)
	outputs[94] region(4728,1083,1494)
	outputs[95] region(4734,1086,1497)
	outputs[96] region(4736,1087,1498)
	outputs[97] region(4742,1090,1501)
	outputs[98] region(4748,1093,1504)
	outputs[99] region(4750,1094,1505)
	outputs[100] region(4754,1096,1507)
	outputs[101] region(4756,1097,1508)
	weights[0] region(4280,859,1270)
	weights[1] region(4284,861,1272)
	weights[2] region(4288,863,1274)
	weights[3] region(4290,864,1275)
	weights[4] region(4296,867,1278)
	weights[5] region(4298,868,1279)
	weights[6] region(4302,870,1281)
	weights[7] region(4304,871,1282)
	weights[8] region(4306,872,1283)
	weights[9] region(4312,875,1286)
	weights[10] region(4314,876,1287)
	weights[11] region(4320,879,1290)
	weights[12] region(4322,880,1291)
	weights[13] region(4326,882,1293)
	weights[14] region(4328,883,1294)
	weights[15] region(4334,886,1297)
	weights[16] region(4336,887,1298)
	weights[17] region(4340,889,1300)
	weights[18] region(4342,890,1301)
	weights[19] region(4344,891,1302)
	weights[20] region(4350,894,1305)
	weights[21] region(4352,895,1306)
	weights[22] region(4358,898,1309)
	weights[23] region(4360,899,1310)
	weights[24] region(4364,901,1312)
	weights[25] region(4366,902,1313)
	weights[26] region(4372,905,1316)
	weights[27] region(4374,906,1317)
	weights[28] region(4378,908,1319)
	weights[29] region(4380,909,1320)
	weights[30] region(4382,910,1321)
	weights[31] region(4388,913,1324)
	weights[32] region(4390,914,1325)
	weights[33] region(4396,917,1328)
	weights[34] region(4398,918,1329)
	weights[35] region(4402,920,1331)
	weights[36] region(4404,921,1332)
	weights[37] region(4410,924,1335)
	weights[38] region(4412,925,1336)
	weights[39] region(4416,927,1338)
	weights[40] region(4418,928,1339)
	weights[41] region(4420,929,1340)
	weights[42] region(4426,932,1343)
	weights[43] region(4428,933,1344)
	weights[44] region(4434,936,1347)
	weights[45] region(4436,937,1348)
	weights[46] region(4440,939,1350)
	weights[47] region(4442,940,1351)
	weights[48] region(4448,943,1354)
	weights[49] region(4450,944,1355)
	weights[50] region(4454,946,1357)
	weights[51] region(4456,947,1358)
	weights[52] region(4458,948,1359)
	weights[53] region(4464,951,1362)
	weights[54] region(4466,952,1363)
	weights[55] region(4472,955,1366)
	weights[56] region(4474,956,1367)
	weights[57] region(4478,958,1369)
	weights[58] region(4480,959,1370)
	weights[59] region(4486,962,1373)
	weights[60] region(4488,963,1374)
	weights[61] region(4492,965,1376)
	weights[62] region(4494,966,1377)
	weights[63] region(4496,967,1378)
	weights[64] region(4502,970,1381)
	weights[65] region(4504,971,1382)
	weights[66] region(4510,974,1385)
	weights[67] region(4512,975,1386)
	weights[68] region(4516,977,1388)
	weights[69] region(4518,978,1389)
	weights[70] region(4524,981,1392)
	weights[71] region(4526,982,1393)
	weights[72] region(4530,984,1395)
	weights[73] region(4532,985,1396)
	weights[74] region(4534,986,1397)
	weights[75] region(4540,989,1400)
	weights[76] region(4542,990,1401)
	weights[77] region(4548,993,1404)
	weights[78] region(4550,994,1405)
	weights[79] region(4554,996,1407)
	weights[80] region(4556,997,1408)
	weights[81] region(4562,1000,1411)
	weights[82] region(4564,1001,1412)
	weights[83] region(4568,1003,1414)
	weights[84] region(4570,1004,1415)
	weights[85] region(4572,1005,1416)
	weights[86] region(4578,1008,1419)
	weights[87] region(4580,1009,1420)
	weights[88] region(4586,1012,1423)
	weights[89] region(4588,1013,1424)
	weights[90] region(4592,1015,1426)
	weights[91] region(4594,1016,1427)
	weights[92] region(4600,1019,1430)
	weights[93] region(4602,1020,1431)
	weights[94] region(4606,1022,1433)
	weights[95] region(4608,1023,1434)
	weights[96] region(4610,1024,1435)
	weights[97] region(4616,1027,1438)
	weights[98] region(4618,1028,1439)
	weights[99] region(4624,1031,1442)
	weights[100] region(4626,1032,1443)
	weights[101] region(4630,1034,1445)
	weights[102] region(4632,1035,1446)
	weights[103] region(4638,1038,1449)
	weights[104] region(4640,1039,1450)
	weights[105] region(4644,1041,1452)
	weights[106] region(4646,1042,1453)
	weights[107] region(4648,1043,1454)
	weights[108] region(4654,1046,1457)
	weights[109] region(4656,1047,1458)
	weights[110] region(4662,1050,1461)
	weights[111] region(4664,1051,1462)
	weights[112] region(4668,1053,1464)
	weights[113] region(4670,1054,1465)
	weights[114] region(4676,1057,1468)
	weights[115] region(4678,1058,1469)
	weights[116] region(4682,1060,1471)
	weights[117] region(4684,1061,1472)
	weights[118] region(4686,1062,1473)
	weights[119] region(4692,1065,1476)
	weights[120] region(4694,1066,1477)
	weights[121] region(4700,1069,1480)
	weights[122] region(4702,1070,1481)
	weights[123] region(4706,1072,1483)
	weights[124] region(4708,1073,1484)
	weights[125] region(4714,1076,1487)
	weights[126] region(4716,1077,1488)
	weights[127] region(4720,1079,1490)
	weights[128] region(4722,1080,1491)
	weights[129] region(4724,1081,1492)
	weights[130] region(4730,1084,1495)
	weights[131] region(4732,1085,1496)
	weights[132] region(4738,1088,1499)
	weights[133] region(4740,1089,1500)
	weights[134] region(4744,1091,1502)
	weights[135] region(4746,1092,1503)
	weights[136] region(4752,1095,1506)
operator[4]: type(Weight) guid(2000165)
	outputs[0] region(4284,861,1272)
operator[5]: type(Weight) guid(2000167)
	outputs[0] region(4288,863,1274)
operator[6]: type(Weight) guid(2000168)
	outputs[0] region(4290,864,1275)
operator[7]: type(Weight) guid(2000170)
	outputs[0] region(4296,867,1278)
operator[8]: type(Weight) guid(2000171)
	outputs[0] region(4298,868,1279)
operator[9]: type(Weight) guid(2000173)
	outputs[0] region(4302,870,1281)
operator[10]: type(Weight) guid(2000174)
	outputs[0] region(4304,871,1282)
operator[11]: type(Weight) guid(2000175)
	outputs[0] region(4306,872,1283)
operator[12]: type(Weight) guid(2000177)
	outputs[0] region(4312,875,1286)
operator[13]: type(Weight) guid(2000178)
	outputs[0] region(4314,876,1287)
operator[14]: type(Weight) guid(2000181)
	outputs[0] region(4320,879,1290)
operator[15]: type(Weight) guid(2000182)
	outputs[0] region(4322,880,1291)
operator[16]: type(Weight) guid(2000184)
	outputs[0] region(4326,882,1293)
operator[17]: type(Weight) guid(2000185)
	outputs[0] region(4328,883,1294)
operator[18]: type(Weight) guid(2000187)
	outputs[0] region(4334,886,1297)
operator[19]: type(Weight) guid(2000188)
	outputs[0] region(4336,887,1298)
operator[20]: type(Weight) guid(2000190)
	outputs[0] region(4340,889,1300)
operator[21]: type(Weight) guid(2000191)
	outputs[0] region(4342,890,1301)
operator[22]: type(Weight) guid(2000192)
	outputs[0] region(4344,891,1302)
operator[23]: type(Weight) guid(2000194)
	outputs[0] region(4350,894,1305)
operator[24]: type(Weight) guid(2000195)
	outputs[0] region(4352,895,1306)
operator[25]: type(Weight) guid(2000198)
	outputs[0] region(4358,898,1309)
operator[26]: type(Weight) guid(2000199)
	outputs[0] region(4360,899,1310)
operator[27]: type(Weight) guid(2000201)
	outputs[0] region(4364,901,1312)
operator[28]: type(Weight) guid(2000202)
	outputs[0] region(4366,902,1313)
operator[29]: type(Weight) guid(2000204)
	outputs[0] region(4372,905,1316)
operator[30]: type(Weight) guid(2000205)
	outputs[0] region(4374,906,1317)
operator[31]: type(Weight) guid(2000207)
	outputs[0] region(4378,908,1319)
operator[32]: type(Weight) guid(2000208)
	outputs[0] region(4380,909,1320)
operator[33]: type(Weight) guid(2000209)
	outputs[0] region(4382,910,1321)
operator[34]: type(Weight) guid(2000211)
	outputs[0] region(4388,913,1324)
operator[35]: type(Weight) guid(2000212)
	outputs[0] region(4390,914,1325)
operator[36]: type(Weight) guid(2000215)
	outputs[0] region(4396,917,1328)
operator[37]: type(Weight) guid(2000216)
	outputs[0] region(4398,918,1329)
operator[38]: type(Weight) guid(2000218)
	outputs[0] region(4402,920,1331)
operator[39]: type(Weight) guid(2000219)
	outputs[0] region(4404,921,1332)
operator[40]: type(Weight) guid(2000221)
	outputs[0] region(4410,924,1335)
operator[41]: type(Weight) guid(2000222)
	outputs[0] region(4412,925,1336)
operator[42]: type(Weight) guid(2000224)
	outputs[0] region(4416,927,1338)
operator[43]: type(Weight) guid(2000225)
	outputs[0] region(4418,928,1339)
operator[44]: type(Weight) guid(2000226)
	outputs[0] region(4420,929,1340)
operator[45]: type(Weight) guid(2000228)
	outputs[0] region(4426,932,1343)
operator[46]: type(Weight) guid(2000229)
	outputs[0] region(4428,933,1344)
operator[47]: type(Weight) guid(2000232)
	outputs[0] region(4434,936,1347)
operator[48]: type(Weight) guid(2000233)
	outputs[0] region(4436,937,1348)
operator[49]: type(Weight) guid(2000235)
	outputs[0] region(4440,939,1350)
operator[50]: type(Weight) guid(2000236)
	outputs[0] region(4442,940,1351)
operator[51]: type(Weight) guid(2000238)
	outputs[0] region(4448,943,1354)
operator[52]: type(Weight) guid(2000239)
	outputs[0] region(4450,944,1355)
operator[53]: type(Weight) guid(2000241)
	outputs[0] region(4454,946,1357)
operator[54]: type(Weight) guid(2000242)
	outputs[0] region(4456,947,1358)
operator[55]: type(Weight) guid(2000243)
	outputs[0] region(4458,948,1359)
operator[56]: type(Weight) guid(2000245)
	outputs[0] region(4464,951,1362)
operator[57]: type(Weight) guid(2000246)
	outputs[0] region(4466,952,1363)
operator[58]: type(Weight) guid(2000249)
	outputs[0] region(4472,955,1366)
operator[59]: type(Weight) guid(2000250)
	outputs[0] region(4474,956,1367)
operator[60]: type(Weight) guid(2000252)
	outputs[0] region(4478,958,1369)
operator[61]: type(Weight) guid(2000253)
	outputs[0] region(4480,959,1370)
operator[62]: type(Weight) guid(2000255)
	outputs[0] region(4486,962,1373)
operator[63]: type(Weight) guid(2000256)
	outputs[0] region(4488,963,1374)
operator[64]: type(Weight) guid(2000258)
	outputs[0] region(4492,965,1376)
operator[65]: type(Weight) guid(2000259)
	outputs[0] region(4494,966,1377)
operator[66]: type(Weight) guid(2000260)
	outputs[0] region(4496,967,1378)
operator[67]: type(Weight) guid(2000262)
	outputs[0] region(4502,970,1381)
operator[68]: type(Weight) guid(2000263)
	outputs[0] region(4504,971,1382)
operator[69]: type(Weight) guid(2000266)
	outputs[0] region(4510,974,1385)
operator[70]: type(Weight) guid(2000267)
	outputs[0] region(4512,975,1386)
operator[71]: type(Weight) guid(2000269)
	outputs[0] region(4516,977,1388)
operator[72]: type(Weight) guid(2000270)
	outputs[0] region(4518,978,1389)
operator[73]: type(Weight) guid(2000272)
	outputs[0] region(4524,981,1392)
operator[74]: type(Weight) guid(2000273)
	outputs[0] region(4526,982,1393)
operator[75]: type(Weight) guid(2000275)
	outputs[0] region(4530,984,1395)
operator[76]: type(Weight) guid(2000276)
	outputs[0] region(4532,985,1396)
operator[77]: type(Weight) guid(2000277)
	outputs[0] region(4534,986,1397)
operator[78]: type(Weight) guid(2000279)
	outputs[0] region(4540,989,1400)
operator[79]: type(Weight) guid(2000280)
	outputs[0] region(4542,990,1401)
operator[80]: type(Weight) guid(2000283)
	outputs[0] region(4548,993,1404)
operator[81]: type(Weight) guid(2000284)
	outputs[0] region(4550,994,1405)
operator[82]: type(Weight) guid(2000286)
	outputs[0] region(4554,996,1407)
operator[83]: type(Weight) guid(2000287)
	outputs[0] region(4556,997,1408)
operator[84]: type(Weight) guid(2000289)
	outputs[0] region(4562,1000,1411)
operator[85]: type(Weight) guid(2000290)
	outputs[0] region(4564,1001,1412)
operator[86]: type(Weight) guid(2000292)
	outputs[0] region(4568,1003,1414)
operator[87]: type(Weight) guid(2000293)
	outputs[0] region(4570,1004,1415)
operator[88]: type(Weight) guid(2000294)
	outputs[0] region(4572,1005,1416)
operator[89]: type(Weight) guid(2000296)
	outputs[0] region(4578,1008,1419)
operator[90]: type(Weight) guid(2000297)
	outputs[0] region(4580,1009,1420)
operator[91]: type(Weight) guid(2000300)
	outputs[0] region(4586,1012,1423)
operator[92]: type(Weight) guid(2000301)
	outputs[0] region(4588,1013,1424)
operator[93]: type(Weight) guid(2000303)
	outputs[0] region(4592,1015,1426)
operator[94]: type(Weight) guid(2000304)
	outputs[0] region(4594,1016,1427)
operator[95]: type(Weight) guid(2000306)
	outputs[0] region(4600,1019,1430)
operator[96]: type(Weight) guid(2000307)
	outputs[0] region(4602,1020,1431)
operator[97]: type(Weight) guid(2000309)
	outputs[0] region(4606,1022,1433)
operator[98]: type(Weight) guid(2000310)
	outputs[0] region(4608,1023,1434)
operator[99]: type(Weight) guid(2000311)
	outputs[0] region(4610,1024,1435)
operator[100]: type(Weight) guid(2000313)
	outputs[0] region(4616,1027,1438)
operator[101]: type(Weight) guid(2000314)
	outputs[0] region(4618,1028,1439)
operator[102]: type(Weight) guid(2000317)
	outputs[0] region(4624,1031,1442)
operator[103]: type(Weight) guid(2000318)
	outputs[0] region(4626,1032,1443)
operator[104]: type(Weight) guid(2000320)
	outputs[0] region(4630,1034,1445)
operator[105]: type(Weight) guid(2000321)
	outputs[0] region(4632,1035,1446)
operator[106]: type(Weight) guid(2000323)
	outputs[0] region(4638,1038,1449)
operator[107]: type(Weight) guid(2000324)
	outputs[0] region(4640,1039,1450)
operator[108]: type(Weight) guid(2000326)
	outputs[0] region(4644,1041,1452)
operator[109]: type(Weight) guid(2000327)
	outputs[0] region(4646,1042,1453)
operator[110]: type(Weight) guid(2000328)
	outputs[0] region(4648,1043,1454)
operator[111]: type(Weight) guid(2000330)
	outputs[0] region(4654,1046,1457)
operator[112]: type(Weight) guid(2000331)
	outputs[0] region(4656,1047,1458)
operator[113]: type(Weight) guid(2000334)
	outputs[0] region(4662,1050,1461)
operator[114]: type(Weight) guid(2000335)
	outputs[0] region(4664,1051,1462)
operator[115]: type(Weight) guid(2000337)
	outputs[0] region(4668,1053,1464)
operator[116]: type(Weight) guid(2000338)
	outputs[0] region(4670,1054,1465)
operator[117]: type(Weight) guid(2000340)
	outputs[0] region(4676,1057,1468)
operator[118]: type(Weight) guid(2000341)
	outputs[0] region(4678,1058,1469)
operator[119]: type(Weight) guid(2000343)
	outputs[0] region(4682,1060,1471)
operator[120]: type(Weight) guid(2000344)
	outputs[0] region(4684,1061,1472)
operator[121]: type(Weight) guid(2000345)
	outputs[0] region(4686,1062,1473)
operator[122]: type(Weight) guid(2000347)
	outputs[0] region(4692,1065,1476)
operator[123]: type(Weight) guid(2000348)
	outputs[0] region(4694,1066,1477)
operator[124]: type(Weight) guid(2000351)
	outputs[0] region(4700,1069,1480)
operator[125]: type(Weight) guid(2000352)
	outputs[0] region(4702,1070,1481)
operator[126]: type(Weight) guid(2000354)
	outputs[0] region(4706,1072,1483)
operator[127]: type(Weight) guid(2000355)
	outputs[0] region(4708,1073,1484)
operator[128]: type(Weight) guid(2000357)
	outputs[0] region(4714,1076,1487)
operator[129]: type(Weight) guid(2000358)
	outputs[0] region(4716,1077,1488)
operator[130]: type(Weight) guid(2000360)
	outputs[0] region(4720,1079,1490)
operator[131]: type(Weight) guid(2000361)
	outputs[0] region(4722,1080,1491)
operator[132]: type(Weight) guid(2000362)
	outputs[0] region(4724,1081,1492)
operator[133]: type(Weight) guid(2000364)
	outputs[0] region(4730,1084,1495)
operator[134]: type(Weight) guid(2000365)
	outputs[0] region(4732,1085,1496)
operator[135]: type(Weight) guid(2000368)
	outputs[0] region(4738,1088,1499)
operator[136]: type(Weight) guid(2000369)
	outputs[0] region(4740,1089,1500)
operator[137]: type(Weight) guid(2000371)
	outputs[0] region(4744,1091,1502)
operator[138]: type(Weight) guid(2000372)
	outputs[0] region(4746,1092,1503)
operator[139]: type(Weight) guid(2000374)
	outputs[0] region(4752,1095,1506)
operator[140]: type(ArgMax) guid(2000376)
	inputs[0] region(4756,1097,1508)
	outputs[0] region(4758,1098,1509)
	outputs[1] region(4760,1099,1510)
operator[0]: type(0)
	outputs[0] region(4276,857,1268)
operator[1]: type(0)
	outputs[0] region(4278,858,1269)
operator[2]: type(1)
	outputs[0] region(4280,859,1270)
operator[3]: type(78)
	inputs[0] region(4276,857,1268)
	inputs[1] region(4278,858,1269)
	outputs[0] region(4282,860,1271)
	outputs[1] region(4286,862,1273)
	outputs[2] region(4292,865,1276)
	outputs[3] region(4294,866,1277)
	outputs[4] region(4300,869,1280)
	outputs[5] region(4308,873,1284)
	outputs[6] region(4310,874,1285)
	outputs[7] region(4316,877,1288)
	outputs[8] region(4318,878,1289)
	outputs[9] region(4324,881,1292)
	outputs[10] region(4330,884,1295)
	outputs[11] region(4332,885,1296)
	outputs[12] region(4338,888,1299)
	outputs[13] region(4346,892,1303)
	outputs[14] region(4348,893,1304)
	outputs[15] region(4354,896,1307)
	outputs[16] region(4356,897,1308)
	outputs[17] region(4362,900,1311)
	outputs[18] region(4368,903,1314)
	outputs[19] region(4370,904,1315)
	outputs[20] region(4376,907,1318)
	outputs[21] region(4384,911,1322)
	outputs[22] region(4386,912,1323)
	outputs[23] region(4392,915,1326)
	outputs[24] region(4394,916,1327)
	outputs[25] region(4400,919,1330)
	outputs[26] region(4406,922,1333)
	outputs[27] region(4408,923,1334)
	outputs[28] region(4414,926,1337)
	outputs[29] region(4422,930,1341)
	outputs[30] region(4424,931,1342)
	outputs[31] region(4430,934,1345)
	outputs[32] region(4432,935,1346)
	outputs[33] region(4438,938,1349)
	outputs[34] region(4444,941,1352)
	outputs[35] region(4446,942,1353)
	outputs[36] region(4452,945,1356)
	outputs[37] region(4460,949,1360)
	outputs[38] region(4462,950,1361)
	outputs[39] region(4468,953,1364)
	outputs[40] region(4470,954,1365)
	outputs[41] region(4476,957,1368)
	outputs[42] region(4482,960,1371)
	outputs[43] region(4484,961,1372)
	outputs[44] region(4490,964,1375)
	outputs[45] region(4498,968,1379)
	outputs[46] region(4500,969,1380)
	outputs[47] region(4506,972,1383)
	outputs[48] region(4508,973,1384)
	outputs[49] region(4514,976,1387)
	outputs[50] region(4520,979,1390)
	outputs[51] region(4522,980,1391)
	outputs[52] region(4528,983,1394)
	outputs[53] region(4536,987,1398)
	outputs[54] region(4538,988,1399)
	outputs[55] region(4544,991,1402)
	outputs[56] region(4546,992,1403)
	outputs[57] region(4552,995,1406)
	outputs[58] region(4558,998,1409)
	outputs[59] region(4560,999,1410)
	outputs[60] region(4566,1002,1413)
	outputs[61] region(4574,1006,1417)
	outputs[62] region(4576,1007,1418)
	outputs[63] region(4582,1010,1421)
	outputs[64] region(4584,1011,1422)
	outputs[65] region(4590,1014,1425)
	outputs[66] region(4596,1017,1428)
	outputs[67] region(4598,1018,1429)
	outputs[68] region(4604,1021,1432)
	outputs[69] region(4612,1025,1436)
	outputs[70] region(4614,1026,1437)
	outputs[71] region(4620,1029,1440)
	outputs[72] region(4622,1030,1441)
	outputs[73] region(4628,1033,1444)
	outputs[74] region(4634,1036,1447)
	outputs[75] region(4636,1037,1448)
	outputs[76] region(4642,1040,1451)
	outputs[77] region(4650,1044,1455)
	outputs[78] region(4652,1045,1456)
	outputs[79] region(4658,1048,1459)
	outputs[80] region(4660,1049,1460)
	outputs[81] region(4666,1052,1463)
	outputs[82] region(4672,1055,1466)
	outputs[83] region(4674,1056,1467)
	outputs[84] region(4680,1059,1470)
	outputs[85] region(4688,1063,1474)
	outputs[86] region(4690,1064,1475)
	outputs[87] region(4696,1067,1478)
	outputs[88] region(4698,1068,1479)
	outputs[89] region(4704,1071,1482)
	outputs[90] region(4710,1074,1485)
	outputs[91] region(4712,1075,1486)
	outputs[92] region(4718,1078,1489)
	outputs[93] region(4726,1082,1493)
	outputs[94] region(4728,1083,1494)
	outputs[95] region(4734,1086,1497)
	outputs[96] region(4736,1087,1498)
	outputs[97] region(4742,1090,1501)
	outputs[98] region(4748,1093,1504)
	outputs[99] region(4750,1094,1505)
	outputs[100] region(4754,1096,1507)
	outputs[101] region(4756,1097,1508)
operator[4]: type(1)
	outputs[0] region(4284,861,1272)
operator[5]: type(1)
	outputs[0] region(4288,863,1274)
operator[6]: type(1)
	outputs[0] region(4290,864,1275)
operator[7]: type(1)
	outputs[0] region(4296,867,1278)
operator[8]: type(1)
	outputs[0] region(4298,868,1279)
operator[9]: type(1)
	outputs[0] region(4302,870,1281)
operator[10]: type(1)
	outputs[0] region(4304,871,1282)
operator[11]: type(1)
	outputs[0] region(4306,872,1283)
operator[12]: type(1)
	outputs[0] region(4312,875,1286)
operator[13]: type(1)
	outputs[0] region(4314,876,1287)
operator[14]: type(1)
	outputs[0] region(4320,879,1290)
operator[15]: type(1)
	outputs[0] region(4322,880,1291)
operator[16]: type(1)
	outputs[0] region(4326,882,1293)
operator[17]: type(1)
	outputs[0] region(4328,883,1294)
operator[18]: type(1)
	outputs[0] region(4334,886,1297)
operator[19]: type(1)
	outputs[0] region(4336,887,1298)
operator[20]: type(1)
	outputs[0] region(4340,889,1300)
operator[21]: type(1)
	outputs[0] region(4342,890,1301)
operator[22]: type(1)
	outputs[0] region(4344,891,1302)
operator[23]: type(1)
	outputs[0] region(4350,894,1305)
operator[24]: type(1)
	outputs[0] region(4352,895,1306)
operator[25]: type(1)
	outputs[0] region(4358,898,1309)
operator[26]: type(1)
	outputs[0] region(4360,899,1310)
operator[27]: type(1)
	outputs[0] region(4364,901,1312)
operator[28]: type(1)
	outputs[0] region(4366,902,1313)
operator[29]: type(1)
	outputs[0] region(4372,905,1316)
operator[30]: type(1)
	outputs[0] region(4374,906,1317)
operator[31]: type(1)
	outputs[0] region(4378,908,1319)
operator[32]: type(1)
	outputs[0] region(4380,909,1320)
operator[33]: type(1)
	outputs[0] region(4382,910,1321)
operator[34]: type(1)
	outputs[0] region(4388,913,1324)
operator[35]: type(1)
	outputs[0] region(4390,914,1325)
operator[36]: type(1)
	outputs[0] region(4396,917,1328)
operator[37]: type(1)
	outputs[0] region(4398,918,1329)
operator[38]: type(1)
	outputs[0] region(4402,920,1331)
operator[39]: type(1)
	outputs[0] region(4404,921,1332)
operator[40]: type(1)
	outputs[0] region(4410,924,1335)
operator[41]: type(1)
	outputs[0] region(4412,925,1336)
operator[42]: type(1)
	outputs[0] region(4416,927,1338)
operator[43]: type(1)
	outputs[0] region(4418,928,1339)
operator[44]: type(1)
	outputs[0] region(4420,929,1340)
operator[45]: type(1)
	outputs[0] region(4426,932,1343)
operator[46]: type(1)
	outputs[0] region(4428,933,1344)
operator[47]: type(1)
	outputs[0] region(4434,936,1347)
operator[48]: type(1)
	outputs[0] region(4436,937,1348)
operator[49]: type(1)
	outputs[0] region(4440,939,1350)
operator[50]: type(1)
	outputs[0] region(4442,940,1351)
operator[51]: type(1)
	outputs[0] region(4448,943,1354)
operator[52]: type(1)
	outputs[0] region(4450,944,1355)
operator[53]: type(1)
	outputs[0] region(4454,946,1357)
operator[54]: type(1)
	outputs[0] region(4456,947,1358)
operator[55]: type(1)
	outputs[0] region(4458,948,1359)
operator[56]: type(1)
	outputs[0] region(4464,951,1362)
operator[57]: type(1)
	outputs[0] region(4466,952,1363)
operator[58]: type(1)
	outputs[0] region(4472,955,1366)
operator[59]: type(1)
	outputs[0] region(4474,956,1367)
operator[60]: type(1)
	outputs[0] region(4478,958,1369)
operator[61]: type(1)
	outputs[0] region(4480,959,1370)
operator[62]: type(1)
	outputs[0] region(4486,962,1373)
operator[63]: type(1)
	outputs[0] region(4488,963,1374)
operator[64]: type(1)
	outputs[0] region(4492,965,1376)
operator[65]: type(1)
	outputs[0] region(4494,966,1377)
operator[66]: type(1)
	outputs[0] region(4496,967,1378)
operator[67]: type(1)
	outputs[0] region(4502,970,1381)
operator[68]: type(1)
	outputs[0] region(4504,971,1382)
operator[69]: type(1)
	outputs[0] region(4510,974,1385)
operator[70]: type(1)
	outputs[0] region(4512,975,1386)
operator[71]: type(1)
	outputs[0] region(4516,977,1388)
operator[72]: type(1)
	outputs[0] region(4518,978,1389)
operator[73]: type(1)
	outputs[0] region(4524,981,1392)
operator[74]: type(1)
	outputs[0] region(4526,982,1393)
operator[75]: type(1)
	outputs[0] region(4530,984,1395)
operator[76]: type(1)
	outputs[0] region(4532,985,1396)
operator[77]: type(1)
	outputs[0] region(4534,986,1397)
operator[78]: type(1)
	outputs[0] region(4540,989,1400)
operator[79]: type(1)
	outputs[0] region(4542,990,1401)
operator[80]: type(1)
	outputs[0] region(4548,993,1404)
operator[81]: type(1)
	outputs[0] region(4550,994,1405)
operator[82]: type(1)
	outputs[0] region(4554,996,1407)
operator[83]: type(1)
	outputs[0] region(4556,997,1408)
operator[84]: type(1)
	outputs[0] region(4562,1000,1411)
operator[85]: type(1)
	outputs[0] region(4564,1001,1412)
operator[86]: type(1)
	outputs[0] region(4568,1003,1414)
operator[87]: type(1)
	outputs[0] region(4570,1004,1415)
operator[88]: type(1)
	outputs[0] region(4572,1005,1416)
operator[89]: type(1)
	outputs[0] region(4578,1008,1419)
operator[90]: type(1)
	outputs[0] region(4580,1009,1420)
operator[91]: type(1)
	outputs[0] region(4586,1012,1423)
operator[92]: type(1)
	outputs[0] region(4588,1013,1424)
operator[93]: type(1)
	outputs[0] region(4592,1015,1426)
operator[94]: type(1)
	outputs[0] region(4594,1016,1427)
operator[95]: type(1)
	outputs[0] region(4600,1019,1430)
operator[96]: type(1)
	outputs[0] region(4602,1020,1431)
operator[97]: type(1)
	outputs[0] region(4606,1022,1433)
operator[98]: type(1)
	outputs[0] region(4608,1023,1434)
operator[99]: type(1)
	outputs[0] region(4610,1024,1435)
operator[100]: type(1)
	outputs[0] region(4616,1027,1438)
operator[101]: type(1)
	outputs[0] region(4618,1028,1439)
operator[102]: type(1)
	outputs[0] region(4624,1031,1442)
operator[103]: type(1)
	outputs[0] region(4626,1032,1443)
operator[104]: type(1)
	outputs[0] region(4630,1034,1445)
operator[105]: type(1)
	outputs[0] region(4632,1035,1446)
operator[106]: type(1)
	outputs[0] region(4638,1038,1449)
operator[107]: type(1)
	outputs[0] region(4640,1039,1450)
operator[108]: type(1)
	outputs[0] region(4644,1041,1452)
operator[109]: type(1)
	outputs[0] region(4646,1042,1453)
operator[110]: type(1)
	outputs[0] region(4648,1043,1454)
operator[111]: type(1)
	outputs[0] region(4654,1046,1457)
operator[112]: type(1)
	outputs[0] region(4656,1047,1458)
operator[113]: type(1)
	outputs[0] region(4662,1050,1461)
operator[114]: type(1)
	outputs[0] region(4664,1051,1462)
operator[115]: type(1)
	outputs[0] region(4668,1053,1464)
operator[116]: type(1)
	outputs[0] region(4670,1054,1465)
operator[117]: type(1)
	outputs[0] region(4676,1057,1468)
operator[118]: type(1)
	outputs[0] region(4678,1058,1469)
operator[119]: type(1)
	outputs[0] region(4682,1060,1471)
operator[120]: type(1)
	outputs[0] region(4684,1061,1472)
operator[121]: type(1)
	outputs[0] region(4686,1062,1473)
operator[122]: type(1)
	outputs[0] region(4692,1065,1476)
operator[123]: type(1)
	outputs[0] region(4694,1066,1477)
operator[124]: type(1)
	outputs[0] region(4700,1069,1480)
operator[125]: type(1)
	outputs[0] region(4702,1070,1481)
operator[126]: type(1)
	outputs[0] region(4706,1072,1483)
operator[127]: type(1)
	outputs[0] region(4708,1073,1484)
operator[128]: type(1)
	outputs[0] region(4714,1076,1487)
operator[129]: type(1)
	outputs[0] region(4716,1077,1488)
operator[130]: type(1)
	outputs[0] region(4720,1079,1490)
operator[131]: type(1)
	outputs[0] region(4722,1080,1491)
operator[132]: type(1)
	outputs[0] region(4724,1081,1492)
operator[133]: type(1)
	outputs[0] region(4730,1084,1495)
operator[134]: type(1)
	outputs[0] region(4732,1085,1496)
operator[135]: type(1)
	outputs[0] region(4738,1088,1499)
operator[136]: type(1)
	outputs[0] region(4740,1089,1500)
operator[137]: type(1)
	outputs[0] region(4744,1091,1502)
operator[138]: type(1)
	outputs[0] region(4746,1092,1503)
operator[139]: type(1)
	outputs[0] region(4752,1095,1506)
operator[140]: type(91)
	inputs[0] region(4756,1097,1508)
	outputs[0] region(4758,1098,1509)
	outputs[1] region(4760,1099,1510)
Loading weight file embed_tokens_weight
Loading weight file embed_positions_weight
Loading weight file layers_0_attention_layer_norm_weight
Loading weight file layers_0_attention_layer_norm_bias
Loading weight file layers_0_attention_wq_weight
Loading weight file layers_0_attention_wk_weight
Loading weight file layers_0_attention_wv_weight
Loading weight file layers_0_attention_wo_weight
Loading weight file layers_0_attention_wq_bias
Loading weight file layers_0_attention_wk_bias
Loading weight file layers_0_attention_wv_bias
Loading weight file layers_0_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_0_add_bias_residual_layer_norm_weight
Loading weight file layers_0_add_bias_residual_layer_norm_bias
Loading weight file layers_0_fc1_weight
Loading weight file layers_0_fc1_bias
Loading weight file layers_0_fc2_weight
Loading weight file layers_0_fc2_bias
Loading weight file layers_1_attention_layer_norm_weight
Loading weight file layers_1_attention_layer_norm_bias
Loading weight file layers_1_attention_wq_weight
Loading weight file layers_1_attention_wk_weight
Loading weight file layers_1_attention_wv_weight
Loading weight file layers_1_attention_wo_weight
Loading weight file layers_1_attention_wq_bias
Loading weight file layers_1_attention_wk_bias
Loading weight file layers_1_attention_wv_bias
Loading weight file layers_1_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_1_add_bias_residual_layer_norm_weight
Loading weight file layers_1_add_bias_residual_layer_norm_bias
Loading weight file layers_1_fc1_weight
Loading weight file layers_1_fc1_bias
Loading weight file layers_1_fc2_weight
Loading weight file layers_1_fc2_bias
Loading weight file layers_2_attention_layer_norm_weight
Loading weight file layers_2_attention_layer_norm_bias
Loading weight file layers_2_attention_wq_weight
Loading weight file layers_2_attention_wk_weight
Loading weight file layers_2_attention_wv_weight
Loading weight file layers_2_attention_wo_weight
Loading weight file layers_2_attention_wq_bias
Loading weight file layers_2_attention_wk_bias
Loading weight file layers_2_attention_wv_bias
Loading weight file layers_2_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_2_add_bias_residual_layer_norm_weight
Loading weight file layers_2_add_bias_residual_layer_norm_bias
Loading weight file layers_2_fc1_weight
Loading weight file layers_2_fc1_bias
Loading weight file layers_2_fc2_weight
Loading weight file layers_2_fc2_bias
Loading weight file layers_3_attention_layer_norm_weight
Loading weight file layers_3_attention_layer_norm_bias
Loading weight file layers_3_attention_wq_weight
Loading weight file layers_3_attention_wk_weight
Loading weight file layers_3_attention_wv_weight
Loading weight file layers_3_attention_wo_weight
Loading weight file layers_3_attention_wq_bias
Loading weight file layers_3_attention_wk_bias
Loading weight file layers_3_attention_wv_bias
Loading weight file layers_3_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_3_add_bias_residual_layer_norm_weight
Loading weight file layers_3_add_bias_residual_layer_norm_bias
Loading weight file layers_3_fc1_weight
Loading weight file layers_3_fc1_bias
Loading weight file layers_3_fc2_weight
Loading weight file layers_3_fc2_bias
Loading weight file layers_4_attention_layer_norm_weight
Loading weight file layers_4_attention_layer_norm_bias
Loading weight file layers_4_attention_wq_weight
Loading weight file layers_4_attention_wk_weight
Loading weight file layers_4_attention_wv_weight
Loading weight file layers_4_attention_wo_weight
Loading weight file layers_4_attention_wq_bias
Loading weight file layers_4_attention_wk_bias
Loading weight file layers_4_attention_wv_bias
Loading weight file layers_4_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_4_add_bias_residual_layer_norm_weight
Loading weight file layers_4_add_bias_residual_layer_norm_bias
Loading weight file layers_4_fc1_weight
Loading weight file layers_4_fc1_bias
Loading weight file layers_4_fc2_weight
Loading weight file layers_4_fc2_bias
Loading weight file layers_5_attention_layer_norm_weight
Loading weight file layers_5_attention_layer_norm_bias
Loading weight file layers_5_attention_wq_weight
Loading weight file layers_5_attention_wk_weight
Loading weight file layers_5_attention_wv_weight
Loading weight file layers_5_attention_wo_weight
Loading weight file layers_5_attention_wq_bias
Loading weight file layers_5_attention_wk_bias
Loading weight file layers_5_attention_wv_bias
Loading weight file layers_5_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_5_add_bias_residual_layer_norm_weight
Loading weight file layers_5_add_bias_residual_layer_norm_bias
Loading weight file layers_5_fc1_weight
Loading weight file layers_5_fc1_bias
Loading weight file layers_5_fc2_weight
Loading weight file layers_5_fc2_bias
Loading weight file layers_6_attention_layer_norm_weight
Loading weight file layers_6_attention_layer_norm_bias
Loading weight file layers_6_attention_wq_weight
Loading weight file layers_6_attention_wk_weight
Loading weight file layers_6_attention_wv_weight
Loading weight file layers_6_attention_wo_weight
Loading weight file layers_6_attention_wq_bias
Loading weight file layers_6_attention_wk_bias
Loading weight file layers_6_attention_wv_bias
Loading weight file layers_6_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_6_add_bias_residual_layer_norm_weight
Loading weight file layers_6_add_bias_residual_layer_norm_bias
Loading weight file layers_6_fc1_weight
Loading weight file layers_6_fc1_bias
Loading weight file layers_6_fc2_weight
Loading weight file layers_6_fc2_bias
Loading weight file layers_7_attention_layer_norm_weight
Loading weight file layers_7_attention_layer_norm_bias
Loading weight file layers_7_attention_wq_weight
Loading weight file layers_7_attention_wk_weight
Loading weight file layers_7_attention_wv_weight
Loading weight file layers_7_attention_wo_weight
Loading weight file layers_7_attention_wq_bias
Loading weight file layers_7_attention_wk_bias
Loading weight file layers_7_attention_wv_bias
Loading weight file layers_7_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_7_add_bias_residual_layer_norm_weight
Loading weight file layers_7_add_bias_residual_layer_norm_bias
Loading weight file layers_7_fc1_weight
Loading weight file layers_7_fc1_bias
Loading weight file layers_7_fc2_weight
Loading weight file layers_7_fc2_bias
Loading weight file layers_8_attention_layer_norm_weight
Loading weight file layers_8_attention_layer_norm_bias
Loading weight file layers_8_attention_wq_weight
Loading weight file layers_8_attention_wk_weight
Loading weight file layers_8_attention_wv_weight
Loading weight file layers_8_attention_wo_weight
Loading weight file layers_8_attention_wq_bias
Loading weight file layers_8_attention_wk_bias
Loading weight file layers_8_attention_wv_bias
Loading weight file layers_8_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_8_add_bias_residual_layer_norm_weight
Loading weight file layers_8_add_bias_residual_layer_norm_bias
Loading weight file layers_8_fc1_weight
Loading weight file layers_8_fc1_bias
Loading weight file layers_8_fc2_weight
Loading weight file layers_8_fc2_bias
Loading weight file layers_9_attention_layer_norm_weight
Loading weight file layers_9_attention_layer_norm_bias
Loading weight file layers_9_attention_wq_weight
Loading weight file layers_9_attention_wk_weight
Loading weight file layers_9_attention_wv_weight
Loading weight file layers_9_attention_wo_weight
Loading weight file layers_9_attention_wq_bias
Loading weight file layers_9_attention_wk_bias
Loading weight file layers_9_attention_wv_bias
Loading weight file layers_9_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_9_add_bias_residual_layer_norm_weight
Loading weight file layers_9_add_bias_residual_layer_norm_bias
Loading weight file layers_9_fc1_weight
Loading weight file layers_9_fc1_bias
Loading weight file layers_9_fc2_weight
Loading weight file layers_9_fc2_bias
Loading weight file layers_10_attention_layer_norm_weight
Loading weight file layers_10_attention_layer_norm_bias
Loading weight file layers_10_attention_wq_weight
Loading weight file layers_10_attention_wk_weight
Loading weight file layers_10_attention_wv_weight
Loading weight file layers_10_attention_wo_weight
Loading weight file layers_10_attention_wq_bias
Loading weight file layers_10_attention_wk_bias
Loading weight file layers_10_attention_wv_bias
Loading weight file layers_10_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_10_add_bias_residual_layer_norm_weight
Loading weight file layers_10_add_bias_residual_layer_norm_bias
Loading weight file layers_10_fc1_weight
Loading weight file layers_10_fc1_bias
Loading weight file layers_10_fc2_weight
Loading weight file layers_10_fc2_bias
Loading weight file layers_11_attention_layer_norm_weight
Loading weight file layers_11_attention_layer_norm_bias
Loading weight file layers_11_attention_wq_weight
Loading weight file layers_11_attention_wk_weight
Loading weight file layers_11_attention_wv_weight
Loading weight file layers_11_attention_wo_weight
Loading weight file layers_11_attention_wq_bias
Loading weight file layers_11_attention_wk_bias
Loading weight file layers_11_attention_wv_bias
Loading weight file layers_11_add_bias_residual_layer_norm_attn_bias
Loading weight file layers_11_add_bias_residual_layer_norm_weight
Loading weight file layers_11_add_bias_residual_layer_norm_bias
Loading weight file layers_11_fc1_weight
Loading weight file layers_11_fc1_bias
Loading weight file layers_11_fc2_weight
Loading weight file layers_11_fc2_bias
Loading weight file final_layer_norm_weight
Loading weight file final_layer_norm_bias
Loading weight file embed_tokens_weight_lm_head
------finished loading weights----------
[0 - 7f442c744000]   63.658028 {3}{spec_infer}: SSM create_opt_model finished!
Register new model with id: 0
Prompt[0]: please introduce LeBron James, who plays basketball in NBA.

Prompt[1]: write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.
Prompt[2]: Write a comedy sketch about yourself fighting for your rights.
[0 - 7f442c744000]   63.658118 {3}{spec_infer}: total_num_requests: 3
[0 - 7f442c744000]   63.658120 {3}{spec_infer}: start SPS tree_model.generate
[0]37111
[1]6581
[2]9517
[3]957
[4]6
[5]54
[6]1974
[7]2613
[8]11
[9]2762
[10]4
[11]50118
[0 - 7f442c744000]   63.658582 {3}{RequestManager}: request.initial_len: 13
Num of models: 1
[0 - 7f442c744000]   63.658609 {3}{RequestManager}: [1000000]New request tokens: 2 37111 6581 9517 957 6 54 1974 2613 11 2762 4 50118
[0 - 7f442c744000]   63.658614 {3}{RequestManager}: guid:1000000
[0]29631
[1]5
[2]94
[3]26346
[4]9
[5]5
[6]22
[7]1092
[8]10046
[9]9
[10]1619
[11]113
[12]2214
[13]114
[14]5
[15]4085
[16]889
[17]58
[18]70
[19]7420
[20]13
[21]10
[22]7359
[23]12749
[24]101
[25]2512
[26]4
[27]27047
[28]349
[29]516
[30]19
[31]5
[32]12337
[33]346
[34]9
[35]167
[36]7420
[37]228
[38]5
[39]2214
[40]4
[0 - 7f442c744000]   63.658878 {3}{RequestManager}: request.initial_len: 42
Num of models: 1
[0 - 7f442c744000]   63.658906 {3}{RequestManager}: [1000001]New request tokens: 2 29631 5 94 26346 9 5 22 1092 10046 9 1619 113 2214 114 5 4085 889 58 70 7420 13 10 7359 12749 101 2512 4 27047 349 516 19 5 12337 346 9 167 7420 228 5 2214 4
[0 - 7f442c744000]   63.658908 {3}{RequestManager}: guid:1000001
[0]45714
[1]10
[2]5313
[3]15923
[4]59
[5]2512
[6]2190
[7]13
[8]110
[9]659
[10]4
[0 - 7f442c744000]   63.658969 {3}{RequestManager}: request.initial_len: 12
Num of models: 1
[0 - 7f442c744000]   63.658981 {3}{RequestManager}: [1000002]New request tokens: 2 45714 10 5313 15923 59 2512 2190 13 110 659 4
[0 - 7f442c744000]   63.658983 {3}{RequestManager}: guid:1000002
[0 - 7f442c744000]   63.659073 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659079 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659231 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659253 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659268 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659272 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659385 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659401 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659410 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659416 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659523 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659537 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659546 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659550 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659649 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659664 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659673 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659677 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659778 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659793 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659801 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659805 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659904 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659919 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659926 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.659931 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660034 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660048 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660056 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660060 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660155 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660167 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660178 {3}{RequestManager}: SSMs inference time:0.00111701 s.
[0 - 7f442c744000]   63.660199 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660207 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660225 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660265 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.660938 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661351 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661362 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661367 {3}{RequestManager}: LLM Tree Verification time:0.0011941 s.
[0 - 7f442c744000]   63.661393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661535 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661551 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661560 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661564 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661663 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661677 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661685 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661689 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661790 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661804 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661812 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661817 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661915 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661929 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661937 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.661941 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662039 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662052 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662061 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662065 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662162 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662176 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662187 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662297 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662311 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662318 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662323 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662423 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662436 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662443 {3}{RequestManager}: SSMs inference time:0.00105395 s.
[0 - 7f442c744000]   63.662452 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662456 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662467 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662480 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662490 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662976 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.662995 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663004 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663008 {3}{RequestManager}: LLM Tree Verification time:0.000566477 s.
[0 - 7f442c744000]   63.663028 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663032 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663134 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663149 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663178 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663282 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663295 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663303 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663308 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663411 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663424 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663432 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663436 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663534 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663547 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663555 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663559 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663655 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663669 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663677 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663681 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663780 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663793 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663800 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663805 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663905 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663918 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663926 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.663930 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664026 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664039 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664047 {3}{RequestManager}: SSMs inference time:0.00102159 s.
[0 - 7f442c744000]   63.664053 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664057 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664068 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664079 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664089 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664537 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664553 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664560 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664564 {3}{RequestManager}: LLM Tree Verification time:0.000518399 s.
[0 - 7f442c744000]   63.664578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664582 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664683 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664698 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664705 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664710 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664809 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664842 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664850 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664855 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664959 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664972 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.664984 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665083 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665095 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665104 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665108 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665208 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665222 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665229 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665233 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665331 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665344 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665351 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665356 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665453 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665466 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665473 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665478 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665573 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665587 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665593 {3}{RequestManager}: SSMs inference time:0.00101886 s.
[0 - 7f442c744000]   63.665601 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665606 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665615 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665627 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.665636 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.666081 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.666097 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.666104 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   63.666107 {3}{RequestManager}: LLM Tree Verification time:0.000515027 s.

############### prepare_next_batch_init ###############
SSM KV Cache Size init: 13
LLM KV Cache Size init: 0
load 13 tokens for request 1000000
total prompt in request: 13
SSM KV Cache Size init: 42
LLM KV Cache Size init: 0
load 42 tokens for request 1000001
total prompt in request: 42
SSM KV Cache Size init: 12
LLM KV Cache Size init: 0
load 12 tokens for request 1000002
total prompt in request: 12

############### prepare_next_batch_verify ###############
max_prompt_load_size: 240
new_bc.requestsInfo[i].num_tokens_in_batch: 13
max_prompt_load_size: 198
new_bc.requestsInfo[i].num_tokens_in_batch: 42
max_prompt_load_size: 186
new_bc.requestsInfo[i].num_tokens_in_batch: 12
[0 - 7f442c744000]   64.670612 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.670629 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.670850 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.670867 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.670889 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.670894 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671034 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671055 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671064 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671068 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671201 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671224 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671235 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671240 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671367 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671385 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671398 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671521 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671538 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671547 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671552 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671676 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671694 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671703 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671708 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671834 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671852 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671860 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671865 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.671986 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672003 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672014 {3}{RequestManager}: SSMs inference time:0.001427 s.
[0 - 7f442c744000]   64.672026 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672032 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672046 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672067 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672080 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672765 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672795 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672808 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.672814 {3}{RequestManager}: LLM Tree Verification time:0.00080411 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 12
  Input: [12] 50118 ---> [13] 100 
[0 - 7f442c744000]   64.756702 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7f442c744000]   64.756708 {3}{RequestManager}: Input tree: 12:50118
[0 - 7f442c744000]   64.756710 {3}{RequestManager}: Output tree: 13:100
[0 - 7f442c744000]   64.756712 {3}{RequestManager}: Committed tokens: 12:12
[0 - 7f442c744000]   64.756716 {3}{RequestManager}: Verified: 13:100
[0 - 7f442c744000]   64.756718 {3}{RequestManager}: New committed: 12:12
[0 - 7f442c744000]   64.756719 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   64.756827 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I
[ 1000001 ]
Index within old batch: 54
  Input: [41] 4 ---> [42] 50118 
[0 - 7f442c744000]   64.756845 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7f442c744000]   64.756847 {3}{RequestManager}: Input tree: 41:4
[0 - 7f442c744000]   64.756848 {3}{RequestManager}: Output tree: 42:50118
[0 - 7f442c744000]   64.756850 {3}{RequestManager}: Committed tokens: 54:41
[0 - 7f442c744000]   64.756852 {3}{RequestManager}: Verified: 42:50118
[0 - 7f442c744000]   64.756853 {3}{RequestManager}: New committed: 54:41
[0 - 7f442c744000]   64.756855 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   64.756926 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

[ 1000002 ]
Index within old batch: 66
  Input: [11] 4 ---> [12] 50118 
[0 - 7f442c744000]   64.756942 {3}{RequestManager}: Input tree size (1) Output tree size (1)
[0 - 7f442c744000]   64.756944 {3}{RequestManager}: Input tree: 11:4
[0 - 7f442c744000]   64.756945 {3}{RequestManager}: Output tree: 12:50118
[0 - 7f442c744000]   64.756947 {3}{RequestManager}: Committed tokens: 66:11
[0 - 7f442c744000]   64.756948 {3}{RequestManager}: Verified: 12:50118
[0 - 7f442c744000]   64.756950 {3}{RequestManager}: New committed: 66:11
[0 - 7f442c744000]   64.756951 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   64.756969 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.


############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   64.995838 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.995854 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996059 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996084 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996097 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996102 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996245 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996264 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996272 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996277 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996406 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996424 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996433 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996437 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996561 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996586 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996590 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996713 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996730 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996739 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996743 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996867 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996884 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996892 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.996897 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997019 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997035 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997044 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997049 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997169 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997187 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997197 {3}{RequestManager}: SSMs inference time:0.00137539 s.
[0 - 7f442c744000]   64.997212 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997219 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997234 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997258 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997275 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997916 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997982 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997992 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   64.997999 {3}{RequestManager}: LLM Tree Verification time:0.00080486 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [13] 100 ---> [14] 437 
Index within old batch: 1
  Input: [14] 437 ---> [15] 45 
Index within old batch: 2
  Input: [15] 45 ---> [16] 686 
Index within old batch: 3
  Input: [16] 686 ---> [17] 114 
Index within old batch: 4
  Input: [17] 114 ---> [18] 47 
Index within old batch: 5
  Input: [18] 47 ---> [19] 214 
Index within old batch: 6
  Input: [19] 214 ---> [20] 145 
Index within old batch: 7
  Input: [20] 22024 ---> [21] 50 
Index within old batch: 8
  Input: [21] 50 ---> [22] 45 
[0 - 7f442c744000]   64.998112 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   64.998118 {3}{RequestManager}: Input tree: 13:100 14:437 15:45 16:686 17:114 18:47 19:214 20:22024 21:50
[0 - 7f442c744000]   64.998122 {3}{RequestManager}: Output tree: 14:437 15:45 16:686 17:114 18:47 19:214 20:145 21:50 22:45
[0 - 7f442c744000]   64.998125 {3}{RequestManager}: Committed tokens: 0:13 1:14 2:15 3:16 4:17 5:18 6:19 7:20 8:21
[0 - 7f442c744000]   64.998129 {3}{RequestManager}: Verified: 14:437 15:45 16:686 17:114 18:47 19:214 20:145
[0 - 7f442c744000]   64.998132 {3}{RequestManager}: New committed: 0:13 1:14 2:15 3:16 4:17 5:18 6:19
[0 - 7f442c744000]   64.998134 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7f442c744000]   64.998166 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being
[ 1000001 ]
Index within old batch: 9
  Input: [42] 50118 ---> [43] 50118 
Index within old batch: 10
  Input: [43] 50118 ---> [44] 2709 
Index within old batch: 11
  Input: [44] 100 ---> [45] 437 
Index within old batch: 12
  Input: [45] 437 ---> [46] 45 
Index within old batch: 13
  Input: [46] 45 ---> [47] 686 
Index within old batch: 14
  Input: [47] 686 ---> [48] 114 
Index within old batch: 15
  Input: [48] 114 ---> [49] 42 
Index within old batch: 16
  Input: [49] 42 ---> [50] 16 
Index within old batch: 17
  Input: [50] 16 ---> [51] 10 
[0 - 7f442c744000]   64.998221 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   64.998225 {3}{RequestManager}: Input tree: 42:50118 43:50118 44:100 45:437 46:45 47:686 48:114 49:42 50:16
[0 - 7f442c744000]   64.998227 {3}{RequestManager}: Output tree: 43:50118 44:2709 45:437 46:45 47:686 48:114 49:42 50:16 51:10
[0 - 7f442c744000]   64.998230 {3}{RequestManager}: Committed tokens: 9:42 10:43 11:44 12:45 13:46 14:47 15:48 16:49 17:50
[0 - 7f442c744000]   64.998233 {3}{RequestManager}: Verified: 43:50118 44:2709
[0 - 7f442c744000]   64.998234 {3}{RequestManager}: New committed: 9:42 10:43
[0 - 7f442c744000]   64.998236 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   64.998265 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For
[ 1000002 ]
Index within old batch: 18
  Input: [12] 50118 ---> [13] 100 
Index within old batch: 19
  Input: [13] 100 ---> [14] 437 
Index within old batch: 20
  Input: [14] 437 ---> [15] 45 
Index within old batch: 21
  Input: [15] 45 ---> [16] 686 
Index within old batch: 22
  Input: [16] 686 ---> [17] 114 
Index within old batch: 23
  Input: [17] 114 ---> [18] 38 
Index within old batch: 24
  Input: [18] 14 ---> [19] 74 
Index within old batch: 25
  Input: [19] 18 ---> [20] 10 
Index within old batch: 26
  Input: [20] 10 ---> [21] 205 
[0 - 7f442c744000]   64.998314 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   64.998317 {3}{RequestManager}: Input tree: 12:50118 13:100 14:437 15:45 16:686 17:114 18:14 19:18 20:10
[0 - 7f442c744000]   64.998320 {3}{RequestManager}: Output tree: 13:100 14:437 15:45 16:686 17:114 18:38 19:74 20:10 21:205
[0 - 7f442c744000]   64.998322 {3}{RequestManager}: Committed tokens: 18:12 19:13 20:14 21:15 22:16 23:17 24:18 25:19 26:20
[0 - 7f442c744000]   64.998326 {3}{RequestManager}: Verified: 13:100 14:437 15:45 16:686 17:114 18:38
[0 - 7f442c744000]   64.998328 {3}{RequestManager}: New committed: 18:12 19:13 20:14 21:15 22:16 23:17
[0 - 7f442c744000]   64.998329 {3}{RequestManager}: Number of Verified Tokens = 6
[0 - 7f442c744000]   64.998342 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   65.218336 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.218362 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.218788 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.218845 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.218873 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.218885 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219229 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219277 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219299 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219310 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219647 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219694 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219715 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.219726 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220055 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220101 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220122 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220133 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220463 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220509 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220530 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220541 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220867 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220912 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220933 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.220944 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221272 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221317 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221339 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221350 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221696 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221742 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221770 {3}{RequestManager}: SSMs inference time:0.00346005 s.
[0 - 7f442c744000]   65.221790 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221802 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221848 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221891 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.221928 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.223379 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.223437 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.223462 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.223475 {3}{RequestManager}: LLM Tree Verification time:0.0017147 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [20] 145 ---> [21] 39580 
Index within old batch: 1
  Input: [21] 39580 ---> [22] 50 
Index within old batch: 2
  Input: [22] 50 ---> [23] 45 
Index within old batch: 3
  Input: [23] 45 ---> [24] 6 
Index within old batch: 4
  Input: [24] 6 ---> [25] 53 
Index within old batch: 5
  Input: [25] 53 ---> [26] 38 
Index within old batch: 6
  Input: [26] 38 ---> [27] 437 
Index within old batch: 7
  Input: [27] 437 ---> [28] 1256 
Index within old batch: 8
  Input: [28] 45 ---> [29] 1686 
[0 - 7f442c744000]   65.223687 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.223700 {3}{RequestManager}: Input tree: 20:145 21:39580 22:50 23:45 24:6 25:53 26:38 27:437 28:45
[0 - 7f442c744000]   65.223709 {3}{RequestManager}: Output tree: 21:39580 22:50 23:45 24:6 25:53 26:38 27:437 28:1256 29:1686
[0 - 7f442c744000]   65.223717 {3}{RequestManager}: Committed tokens: 0:20 1:21 2:22 3:23 4:24 5:25 6:26 7:27 8:28
[0 - 7f442c744000]   65.223728 {3}{RequestManager}: Verified: 21:39580 22:50 23:45 24:6 25:53 26:38 27:437 28:1256
[0 - 7f442c744000]   65.223736 {3}{RequestManager}: New committed: 0:20 1:21 2:22 3:23 4:24 5:25 6:26 7:27
[0 - 7f442c744000]   65.223739 {3}{RequestManager}: Number of Verified Tokens = 8
[0 - 7f442c744000]   65.223808 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty
[ 1000001 ]
Index within old batch: 9
  Input: [44] 2709 ---> [45] 1246 
Index within old batch: 10
  Input: [45] 1246 ---> [46] 6 
Index within old batch: 11
  Input: [46] 6 ---> [47] 114 
Index within old batch: 12
  Input: [47] 114 ---> [48] 47 
Index within old batch: 13
  Input: [48] 47 ---> [49] 58 
Index within old batch: 14
  Input: [49] 33 ---> [50] 10 
Index within old batch: 15
  Input: [50] 10 ---> [51] 7359 
Index within old batch: 16
  Input: [51] 4085 ---> [52] 889 
Index within old batch: 17
  Input: [52] 13 ---> [53] 10 
[0 - 7f442c744000]   65.223939 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.223948 {3}{RequestManager}: Input tree: 44:2709 45:1246 46:6 47:114 48:47 49:33 50:10 51:4085 52:13
[0 - 7f442c744000]   65.223955 {3}{RequestManager}: Output tree: 45:1246 46:6 47:114 48:47 49:58 50:10 51:7359 52:889 53:10
[0 - 7f442c744000]   65.223963 {3}{RequestManager}: Committed tokens: 9:44 10:45 11:46 12:47 13:48 14:49 15:50 16:51 17:52
[0 - 7f442c744000]   65.223970 {3}{RequestManager}: Verified: 45:1246 46:6 47:114 48:47 49:58
[0 - 7f442c744000]   65.223977 {3}{RequestManager}: New committed: 9:44 10:45 11:46 12:47 13:48
[0 - 7f442c744000]   65.223981 {3}{RequestManager}: Number of Verified Tokens = 5
[0 - 7f442c744000]   65.224049 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were
[ 1000002 ]
Index within old batch: 18
  Input: [18] 38 ---> [19] 437 
Index within old batch: 19
  Input: [19] 437 ---> [20] 6269 
Index within old batch: 20
  Input: [20] 1220 ---> [21] 7 
Index within old batch: 21
  Input: [21] 7 ---> [22] 109 
Index within old batch: 22
  Input: [22] 109 ---> [23] 14 
Index within old batch: 23
  Input: [23] 14 ---> [24] 4 
Index within old batch: 24
  Input: [24] 4 ---> [25] 38 
Index within old batch: 25
  Input: [25] 50118 ---> [26] 1185 
Index within old batch: 26
  Input: [26] 1185 ---> [27] 214 
[0 - 7f442c744000]   65.224172 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.224180 {3}{RequestManager}: Input tree: 18:38 19:437 20:1220 21:7 22:109 23:14 24:4 25:50118 26:1185
[0 - 7f442c744000]   65.224188 {3}{RequestManager}: Output tree: 19:437 20:6269 21:7 22:109 23:14 24:4 25:38 26:1185 27:214
[0 - 7f442c744000]   65.224195 {3}{RequestManager}: Committed tokens: 18:18 19:19 20:20 21:21 22:22 23:23 24:24 25:25 26:26
[0 - 7f442c744000]   65.224201 {3}{RequestManager}: Verified: 19:437 20:6269
[0 - 7f442c744000]   65.224206 {3}{RequestManager}: New committed: 18:18 19:19
[0 - 7f442c744000]   65.224209 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   65.224241 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   65.412616 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.412640 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413063 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413120 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413148 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413161 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413526 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413575 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413598 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413610 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413950 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.413997 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414020 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414031 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414363 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414409 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414431 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414442 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414773 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414819 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414841 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.414852 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415180 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415225 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415246 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415257 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415582 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415627 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415648 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415660 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.415985 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416029 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416052 {3}{RequestManager}: SSMs inference time:0.00345815 s.
[0 - 7f442c744000]   65.416074 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416087 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416120 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416163 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.416200 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.417722 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.417784 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.417809 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.417824 {3}{RequestManager}: LLM Tree Verification time:0.00177572 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [28] 1256 ---> [29] 686 
Index within old batch: 1
  Input: [29] 686 ---> [30] 37 
Index within old batch: 2
  Input: [30] 37 ---> [31] 18 
Index within old batch: 3
  Input: [31] 18 ---> [32] 1686 
Index within old batch: 4
  Input: [32] 45 ---> [33] 10 
Index within old batch: 5
  Input: [33] 10 ---> [34] 2038 
Index within old batch: 6
  Input: [34] 2613 ---> [35] 869 
Index within old batch: 7
  Input: [35] 869 ---> [36] 4 
Index within old batch: 8
  Input: [36] 4 ---> [37] 50118 
[0 - 7f442c744000]   65.418012 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.418025 {3}{RequestManager}: Input tree: 28:1256 29:686 30:37 31:18 32:45 33:10 34:2613 35:869 36:4
[0 - 7f442c744000]   65.418034 {3}{RequestManager}: Output tree: 29:686 30:37 31:18 32:1686 33:10 34:2038 35:869 36:4 37:50118
[0 - 7f442c744000]   65.418042 {3}{RequestManager}: Committed tokens: 0:28 1:29 2:30 3:31 4:32 5:33 6:34 7:35 8:36
[0 - 7f442c744000]   65.418051 {3}{RequestManager}: Verified: 29:686 30:37 31:18 32:1686
[0 - 7f442c744000]   65.418058 {3}{RequestManager}: New committed: 0:28 1:29 2:30 3:31
[0 - 7f442c744000]   65.418061 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   65.418137 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking
[ 1000001 ]
Index within old batch: 9
  Input: [49] 58 ---> [50] 7 
Index within old batch: 10
  Input: [50] 7 ---> [51] 492 
Index within old batch: 11
  Input: [51] 3116 ---> [52] 5 
Index within old batch: 12
  Input: [52] 5 ---> [53] 2214 
Index within old batch: 13
  Input: [53] 316 ---> [54] 10046 
Index within old batch: 14
  Input: [54] 10046 ---> [55] 9 
Index within old batch: 15
  Input: [55] 9 ---> [56] 1619 
Index within old batch: 16
  Input: [56] 1619 ---> [57] 13 
Index within old batch: 17
  Input: [57] 2214 ---> [58] 13 
[0 - 7f442c744000]   65.418280 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.418289 {3}{RequestManager}: Input tree: 49:58 50:7 51:3116 52:5 53:316 54:10046 55:9 56:1619 57:2214
[0 - 7f442c744000]   65.418297 {3}{RequestManager}: Output tree: 50:7 51:492 52:5 53:2214 54:10046 55:9 56:1619 57:13 58:13
[0 - 7f442c744000]   65.418305 {3}{RequestManager}: Committed tokens: 9:49 10:50 11:51 12:52 13:53 14:54 15:55 16:56 17:57
[0 - 7f442c744000]   65.418311 {3}{RequestManager}: Verified: 50:7 51:492
[0 - 7f442c744000]   65.418316 {3}{RequestManager}: New committed: 9:49 10:50
[0 - 7f442c744000]   65.418319 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   65.418391 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give
[ 1000002 ]
Index within old batch: 18
  Input: [20] 6269 ---> [21] 615 
Index within old batch: 19
  Input: [21] 50 ---> [22] 45 
Index within old batch: 20
  Input: [22] 45 ---> [23] 4 
Index within old batch: 21
  Input: [23] 4 ---> [24] 38 
Index within old batch: 22
  Input: [24] 38 ---> [25] 437 
Index within old batch: 23
  Input: [25] 437 ---> [26] 45 
Index within old batch: 24
  Input: [26] 45 ---> [27] 10 
Index within old batch: 25
  Input: [27] 686 ---> [28] 114 
Index within old batch: 26
  Input: [28] 114 ---> [29] 38 
[0 - 7f442c744000]   65.418515 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.418523 {3}{RequestManager}: Input tree: 20:6269 21:50 22:45 23:4 24:38 25:437 26:45 27:686 28:114
[0 - 7f442c744000]   65.418530 {3}{RequestManager}: Output tree: 21:615 22:45 23:4 24:38 25:437 26:45 27:10 28:114 29:38
[0 - 7f442c744000]   65.418538 {3}{RequestManager}: Committed tokens: 18:20 19:21 20:22 21:23 22:24 23:25 24:26 25:27 26:28
[0 - 7f442c744000]   65.418543 {3}{RequestManager}: Verified: 21:615
[0 - 7f442c744000]   65.418547 {3}{RequestManager}: New committed: 18:20
[0 - 7f442c744000]   65.418550 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   65.418583 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   65.629991 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630014 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630438 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630495 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630521 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630533 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630884 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630934 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630955 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.630966 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631305 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631353 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631375 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631386 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631718 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631766 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631787 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.631798 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632125 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632170 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632192 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632204 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632532 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632600 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632612 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632935 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.632981 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633003 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633014 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633364 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633410 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633433 {3}{RequestManager}: SSMs inference time:0.00346575 s.
[0 - 7f442c744000]   65.633455 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633468 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633544 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.633580 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.634998 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.635054 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.635079 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.635092 {3}{RequestManager}: LLM Tree Verification time:0.00166373 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [32] 1686 ---> [33] 59 
Index within old batch: 1
  Input: [33] 59 ---> [34] 5 
Index within old batch: 2
  Input: [34] 9517 ---> [35] 957 
Index within old batch: 3
  Input: [35] 957 ---> [36] 6 
Index within old batch: 4
  Input: [36] 4 ---> [37] 50118 
Index within old batch: 5
  Input: [37] 50118 ---> [38] 100 
Index within old batch: 6
  Input: [38] 100 ---> [39] 437 
Index within old batch: 7
  Input: [39] 437 ---> [40] 45 
Index within old batch: 8
  Input: [40] 45 ---> [41] 686 
[0 - 7f442c744000]   65.635313 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.635326 {3}{RequestManager}: Input tree: 32:1686 33:59 34:9517 35:957 36:4 37:50118 38:100 39:437 40:45
[0 - 7f442c744000]   65.635335 {3}{RequestManager}: Output tree: 33:59 34:5 35:957 36:6 37:50118 38:100 39:437 40:45 41:686
[0 - 7f442c744000]   65.635343 {3}{RequestManager}: Committed tokens: 0:32 1:33 2:34 3:35 4:36 5:37 6:38 7:39 8:40
[0 - 7f442c744000]   65.635350 {3}{RequestManager}: Verified: 33:59 34:5
[0 - 7f442c744000]   65.635355 {3}{RequestManager}: New committed: 0:32 1:33
[0 - 7f442c744000]   65.635358 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   65.635418 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the
[ 1000001 ]
Index within old batch: 9
  Input: [51] 492 ---> [52] 10 
Index within old batch: 10
  Input: [52] 162 ---> [53] 10 
Index within old batch: 11
  Input: [53] 10 ---> [54] 4085 
Index within old batch: 12
  Input: [54] 4085 ---> [55] 6 
Index within old batch: 13
  Input: [55] 9 ---> [56] 10 
Index within old batch: 14
  Input: [56] 10 ---> [57] 22 
Index within old batch: 15
  Input: [57] 92 ---> [58] 1763 
Index within old batch: 16
  Input: [58] 1763 ---> [59] 9 
Index within old batch: 17
  Input: [59] 9 ---> [60] 5582 
[0 - 7f442c744000]   65.635540 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.635548 {3}{RequestManager}: Input tree: 51:492 52:162 53:10 54:4085 55:9 56:10 57:92 58:1763 59:9
[0 - 7f442c744000]   65.635555 {3}{RequestManager}: Output tree: 52:10 53:10 54:4085 55:6 56:10 57:22 58:1763 59:9 60:5582
[0 - 7f442c744000]   65.635563 {3}{RequestManager}: Committed tokens: 9:51 10:52 11:53 12:54 13:55 14:56 15:57 16:58 17:59
[0 - 7f442c744000]   65.635568 {3}{RequestManager}: Verified: 52:10
[0 - 7f442c744000]   65.635573 {3}{RequestManager}: New committed: 9:51
[0 - 7f442c744000]   65.635576 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   65.635641 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a
[ 1000002 ]
Index within old batch: 18
  Input: [21] 615 ---> [22] 7 
Index within old batch: 19
  Input: [22] 7 ---> [23] 2999 
Index within old batch: 20
  Input: [23] 109 ---> [24] 14 
Index within old batch: 21
  Input: [24] 14 ---> [25] 4 
Index within old batch: 22
  Input: [25] 4 ---> [26] 2 
Index within old batch: 23
  Input: [26] 50118 ---> [27] 1185 
Index within old batch: 24
  Input: [27] 100 ---> [28] 437 
Index within old batch: 25
  Input: [28] 437 ---> [29] 686 
Index within old batch: 26
  Input: [29] 45 ---> [30] 686 
[0 - 7f442c744000]   65.635762 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.635770 {3}{RequestManager}: Input tree: 21:615 22:7 23:109 24:14 25:4 26:50118 27:100 28:437 29:45
[0 - 7f442c744000]   65.635777 {3}{RequestManager}: Output tree: 22:7 23:2999 24:14 25:4 26:2 27:1185 28:437 29:686 30:686
[0 - 7f442c744000]   65.635785 {3}{RequestManager}: Committed tokens: 18:21 19:22 20:23 21:24 22:25 23:26 24:27 25:28 26:29
[0 - 7f442c744000]   65.635790 {3}{RequestManager}: Verified: 22:7 23:2999
[0 - 7f442c744000]   65.635795 {3}{RequestManager}: New committed: 18:21 19:22
[0 - 7f442c744000]   65.635798 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   65.635836 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   65.825500 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.825523 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.825948 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826005 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826031 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826042 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826397 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826447 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826467 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826478 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826819 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826866 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826887 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.826899 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827232 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827278 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827299 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827310 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827639 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827685 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827706 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.827717 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828046 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828091 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828113 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828124 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828455 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828500 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828521 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828533 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828858 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828904 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828926 {3}{RequestManager}: SSMs inference time:0.00344946 s.
[0 - 7f442c744000]   65.828947 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828959 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.828990 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.829032 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.829065 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.830501 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.830558 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.830587 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.830602 {3}{RequestManager}: LLM Tree Verification time:0.00167989 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [34] 5 ---> [35] 2762 
Index within old batch: 1
  Input: [35] 2762 ---> [36] 10673 
Index within old batch: 2
  Input: [36] 4 ---> [37] 50118 
Index within old batch: 3
  Input: [37] 50118 ---> [38] 100 
Index within old batch: 4
  Input: [38] 100 ---> [39] 437 
Index within old batch: 5
  Input: [39] 437 ---> [40] 45 
Index within old batch: 6
  Input: [40] 45 ---> [41] 145 
Index within old batch: 7
  Input: [41] 686 ---> [42] 114 
Index within old batch: 8
  Input: [42] 114 ---> [43] 47 
[0 - 7f442c744000]   65.830811 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.830824 {3}{RequestManager}: Input tree: 34:5 35:2762 36:4 37:50118 38:100 39:437 40:45 41:686 42:114
[0 - 7f442c744000]   65.830833 {3}{RequestManager}: Output tree: 35:2762 36:10673 37:50118 38:100 39:437 40:45 41:145 42:114 43:47
[0 - 7f442c744000]   65.830841 {3}{RequestManager}: Committed tokens: 0:34 1:35 2:36 3:37 4:38 5:39 6:40 7:41 8:42
[0 - 7f442c744000]   65.830848 {3}{RequestManager}: Verified: 35:2762 36:10673
[0 - 7f442c744000]   65.830854 {3}{RequestManager}: New committed: 0:34 1:35
[0 - 7f442c744000]   65.830857 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   65.830927 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals
[ 1000001 ]
Index within old batch: 9
  Input: [52] 10 ---> [53] 7359 
Index within old batch: 10
  Input: [53] 4085 ---> [54] 7 
Index within old batch: 11
  Input: [54] 7 ---> [55] 10 
Index within old batch: 12
  Input: [55] 10 ---> [56] 7359 
Index within old batch: 13
  Input: [56] 7359 ---> [57] 12749 
Index within old batch: 14
  Input: [57] 12749 ---> [58] 6 
Index within old batch: 15
  Input: [58] 6 ---> [59] 47 
Index within old batch: 16
  Input: [59] 47 ---> [60] 74 
Index within old batch: 17
  Input: [60] 74 ---> [61] 224 
[0 - 7f442c744000]   65.831049 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.831058 {3}{RequestManager}: Input tree: 52:10 53:4085 54:7 55:10 56:7359 57:12749 58:6 59:47 60:74
[0 - 7f442c744000]   65.831065 {3}{RequestManager}: Output tree: 53:7359 54:7 55:10 56:7359 57:12749 58:6 59:47 60:74 61:224
[0 - 7f442c744000]   65.831073 {3}{RequestManager}: Committed tokens: 9:52 10:53 11:54 12:55 13:56 14:57 15:58 16:59 17:60
[0 - 7f442c744000]   65.831078 {3}{RequestManager}: Verified: 53:7359
[0 - 7f442c744000]   65.831083 {3}{RequestManager}: New committed: 9:52
[0 - 7f442c744000]   65.831086 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   65.831150 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chat
[ 1000002 ]
Index within old batch: 18
  Input: [23] 2999 ---> [24] 14 
Index within old batch: 19
  Input: [24] 14 ---> [25] 160 
Index within old batch: 20
  Input: [25] 160 ---> [26] 4 
Index within old batch: 21
  Input: [26] 4 ---> [27] 2 
Index within old batch: 22
  Input: [27] 50118 ---> [28] 1185 
Index within old batch: 23
  Input: [28] 100 ---> [29] 437 
Index within old batch: 24
  Input: [29] 437 ---> [30] 686 
Index within old batch: 25
  Input: [30] 45 ---> [31] 686 
Index within old batch: 26
  Input: [31] 686 ---> [32] 114 
[0 - 7f442c744000]   65.831274 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.831282 {3}{RequestManager}: Input tree: 23:2999 24:14 25:160 26:4 27:50118 28:100 29:437 30:45 31:686
[0 - 7f442c744000]   65.831289 {3}{RequestManager}: Output tree: 24:14 25:160 26:4 27:2 28:1185 29:437 30:686 31:686 32:114
[0 - 7f442c744000]   65.831297 {3}{RequestManager}: Committed tokens: 18:23 19:24 20:25 21:26 22:27 23:28 24:29 25:30 26:31
[0 - 7f442c744000]   65.831304 {3}{RequestManager}: Verified: 24:14 25:160 26:4 27:2
[0 - 7f442c744000]   65.831311 {3}{RequestManager}: New committed: 18:23 19:24 20:25 21:26
[0 - 7f442c744000]   65.831314 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   65.831354 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   65.994013 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994036 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994456 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994512 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994551 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994936 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.994987 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995010 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995022 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995364 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995411 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995432 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995443 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995784 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995831 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995852 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.995862 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996194 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996240 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996262 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996272 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996602 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996647 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996669 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.996679 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997062 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997112 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997136 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997148 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997481 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997527 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997549 {3}{RequestManager}: SSMs inference time:0.00356143 s.
[0 - 7f442c744000]   65.997569 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997582 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997615 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997658 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.997695 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.999208 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.999264 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.999289 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   65.999303 {3}{RequestManager}: LLM Tree Verification time:0.00175838 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [36] 10673 ---> [37] 4 
Index within old batch: 1
  Input: [37] 4 ---> [38] 50118 
Index within old batch: 2
  Input: [38] 50118 ---> [39] 100 
Index within old batch: 3
  Input: [39] 100 ---> [40] 437 
Index within old batch: 4
  Input: [40] 437 ---> [41] 45 
Index within old batch: 5
  Input: [41] 45 ---> [42] 145 
Index within old batch: 6
  Input: [42] 686 ---> [43] 114 
Index within old batch: 7
  Input: [43] 114 ---> [44] 47 
Index within old batch: 8
  Input: [44] 47 ---> [45] 214 
[0 - 7f442c744000]   65.999517 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.999531 {3}{RequestManager}: Input tree: 36:10673 37:4 38:50118 39:100 40:437 41:45 42:686 43:114 44:47
[0 - 7f442c744000]   65.999540 {3}{RequestManager}: Output tree: 37:4 38:50118 39:100 40:437 41:45 42:145 43:114 44:47 45:214
[0 - 7f442c744000]   65.999548 {3}{RequestManager}: Committed tokens: 0:36 1:37 2:38 3:39 4:40 5:41 6:42 7:43 8:44
[0 - 7f442c744000]   65.999559 {3}{RequestManager}: Verified: 37:4 38:50118 39:100 40:437 41:45 42:145
[0 - 7f442c744000]   65.999566 {3}{RequestManager}: New committed: 0:36 1:37 2:38 3:39 4:40 5:41
[0 - 7f442c744000]   65.999570 {3}{RequestManager}: Number of Verified Tokens = 6
[0 - 7f442c744000]   65.999636 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being
[ 1000001 ]
Index within old batch: 9
  Input: [53] 7359 ---> [54] 12749 
Index within old batch: 10
  Input: [54] 12749 ---> [55] 10 
Index within old batch: 11
  Input: [55] 10 ---> [56] 4085 
Index within old batch: 12
  Input: [56] 4085 ---> [57] 15 
Index within old batch: 13
  Input: [57] 9 ---> [58] 10 
Index within old batch: 14
  Input: [58] 10 ---> [59] 22 
Index within old batch: 15
  Input: [59] 2214 ---> [60] 6 
Index within old batch: 16
  Input: [60] 6 ---> [61] 47 
Index within old batch: 17
  Input: [61] 47 ---> [62] 74 
[0 - 7f442c744000]   65.999761 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   65.999770 {3}{RequestManager}: Input tree: 53:7359 54:12749 55:10 56:4085 57:9 58:10 59:2214 60:6 61:47
[0 - 7f442c744000]   65.999778 {3}{RequestManager}: Output tree: 54:12749 55:10 56:4085 57:15 58:10 59:22 60:6 61:47 62:74
[0 - 7f442c744000]   65.999786 {3}{RequestManager}: Committed tokens: 9:53 10:54 11:55 12:56 13:57 14:58 15:59 16:60 17:61
[0 - 7f442c744000]   65.999794 {3}{RequestManager}: Verified: 54:12749 55:10 56:4085 57:15
[0 - 7f442c744000]   65.999800 {3}{RequestManager}: New committed: 9:53 10:54 11:55 12:56
[0 - 7f442c744000]   65.999804 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   65.999879 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on
[ 1000002 ]
Index within old batch: 18
  Input: [27] 2 ---> [28] 100 
Index within old batch: 19
  Input: [28] 100 ---> [29] 437 
Index within old batch: 20
  Input: [29] 437 ---> [30] 45 
Index within old batch: 21
  Input: [30] 45 ---> [31] 686 
Index within old batch: 22
  Input: [31] 686 ---> [32] 114 
Index within old batch: 23
  Input: [32] 114 ---> [33] 42 
Index within old batch: 24
  Input: [33] 42 ---> [34] 16 
Index within old batch: 25
  Input: [34] 16 ---> [35] 10 
Index within old batch: 26
  Input: [35] 10 ---> [36] 205 
[0 - 7f442c744000]   65.999998 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.000007 {3}{RequestManager}: Input tree: 27:2 28:100 29:437 30:45 31:686 32:114 33:42 34:16 35:10
[0 - 7f442c744000]   66.000014 {3}{RequestManager}: Output tree: 28:100 29:437 30:45 31:686 32:114 33:42 34:16 35:10 36:205
[0 - 7f442c744000]   66.000022 {3}{RequestManager}: Committed tokens: 18:27 19:28 20:29 21:30 22:31 23:32 24:33 25:34 26:35
[0 - 7f442c744000]   66.000033 {3}{RequestManager}: Verified: 28:100 29:437 30:45 31:686 32:114 33:42 34:16 35:10 36:205
[0 - 7f442c744000]   66.000041 {3}{RequestManager}: New committed: 18:27 19:28 20:29 21:30 22:31 23:32 24:33 25:34 26:35
[0 - 7f442c744000]   66.000044 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   66.000099 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   66.210155 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.210179 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.210601 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.210658 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.210686 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.210697 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211047 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211095 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211117 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211128 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211463 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211510 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211531 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211542 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211874 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211920 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211941 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.211952 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212283 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212328 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212348 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212360 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212689 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212735 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212756 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.212767 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213115 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213160 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213194 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213518 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213564 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213586 {3}{RequestManager}: SSMs inference time:0.00345469 s.
[0 - 7f442c744000]   66.213607 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213619 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213651 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213692 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.213725 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.215167 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.215224 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.215248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.215261 {3}{RequestManager}: LLM Tree Verification time:0.00167977 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [42] 145 ---> [43] 39580 
Index within old batch: 1
  Input: [43] 39580 ---> [44] 4 
Index within old batch: 2
  Input: [44] 6 ---> [45] 38 
Index within old batch: 3
  Input: [45] 38 ---> [46] 437 
Index within old batch: 4
  Input: [46] 437 ---> [47] 95 
Index within old batch: 5
  Input: [47] 95 ---> [48] 584 
Index within old batch: 6
  Input: [48] 584 ---> [49] 14 
Index within old batch: 7
  Input: [49] 14 ---> [50] 9517 
Index within old batch: 8
  Input: [50] 9517 ---> [51] 16 
[0 - 7f442c744000]   66.215465 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.215478 {3}{RequestManager}: Input tree: 42:145 43:39580 44:6 45:38 46:437 47:95 48:584 49:14 50:9517
[0 - 7f442c744000]   66.215487 {3}{RequestManager}: Output tree: 43:39580 44:4 45:38 46:437 47:95 48:584 49:14 50:9517 51:16
[0 - 7f442c744000]   66.215495 {3}{RequestManager}: Committed tokens: 0:42 1:43 2:44 3:45 4:46 5:47 6:48 7:49 8:50
[0 - 7f442c744000]   66.215503 {3}{RequestManager}: Verified: 43:39580 44:4
[0 - 7f442c744000]   66.215508 {3}{RequestManager}: New committed: 0:42 1:43
[0 - 7f442c744000]   66.215511 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   66.215580 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic.
[ 1000001 ]
Index within old batch: 9
  Input: [57] 15 ---> [58] 5 
Index within old batch: 10
  Input: [58] 1619 ---> [59] 1053 
Index within old batch: 11
  Input: [59] 6716 ---> [60] 6 
Index within old batch: 12
  Input: [60] 6 ---> [61] 47 
Index within old batch: 13
  Input: [61] 47 ---> [62] 74 
Index within old batch: 14
  Input: [62] 74 ---> [63] 3116 
Index within old batch: 15
  Input: [63] 3116 ---> [64] 35 
Index within old batch: 16
  Input: [64] 5 ---> [65] 511 
Index within old batch: 17
  Input: [65] 511 ---> [66] 35 
[0 - 7f442c744000]   66.215702 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.215710 {3}{RequestManager}: Input tree: 57:15 58:1619 59:6716 60:6 61:47 62:74 63:3116 64:5 65:511
[0 - 7f442c744000]   66.215718 {3}{RequestManager}: Output tree: 58:5 59:1053 60:6 61:47 62:74 63:3116 64:35 65:511 66:35
[0 - 7f442c744000]   66.215726 {3}{RequestManager}: Committed tokens: 9:57 10:58 11:59 12:60 13:61 14:62 15:63 16:64 17:65
[0 - 7f442c744000]   66.215732 {3}{RequestManager}: Verified: 58:5
[0 - 7f442c744000]   66.215737 {3}{RequestManager}: New committed: 9:57
[0 - 7f442c744000]   66.215740 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   66.215809 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the
[ 1000002 ]
Index within old batch: 18
  Input: [36] 205 ---> [37] 1114 
Index within old batch: 19
  Input: [37] 1114 ---> [38] 4 
Index within old batch: 20
  Input: [38] 6 ---> [39] 53 
Index within old batch: 21
  Input: [39] 53 ---> [40] 38 
Index within old batch: 22
  Input: [40] 38 ---> [41] 74 
Index within old batch: 23
  Input: [41] 437 ---> [42] 164 
Index within old batch: 24
  Input: [42] 45 ---> [43] 686 
Index within old batch: 25
  Input: [43] 686 ---> [44] 114 
Index within old batch: 26
  Input: [44] 114 ---> [45] 24 
[0 - 7f442c744000]   66.215943 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.215951 {3}{RequestManager}: Input tree: 36:205 37:1114 38:6 39:53 40:38 41:437 42:45 43:686 44:114
[0 - 7f442c744000]   66.215959 {3}{RequestManager}: Output tree: 37:1114 38:4 39:53 40:38 41:74 42:164 43:686 44:114 45:24
[0 - 7f442c744000]   66.215966 {3}{RequestManager}: Committed tokens: 18:36 19:37 20:38 21:39 22:40 23:41 24:42 25:43 26:44
[0 - 7f442c744000]   66.215971 {3}{RequestManager}: Verified: 37:1114 38:4
[0 - 7f442c744000]   66.215976 {3}{RequestManager}: New committed: 18:36 19:37
[0 - 7f442c744000]   66.215979 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   66.216035 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   66.438575 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.438597 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439023 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439080 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439105 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439118 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439475 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439525 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439546 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439557 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439900 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439950 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439972 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.439983 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440321 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440368 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440390 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440401 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440735 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440798 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440821 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.440833 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441170 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441215 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441236 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441574 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441620 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441642 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441653 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.441979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442025 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442046 {3}{RequestManager}: SSMs inference time:0.00349312 s.
[0 - 7f442c744000]   66.442067 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442079 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442112 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442153 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.442187 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.443608 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.443666 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.443691 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.443704 {3}{RequestManager}: LLM Tree Verification time:0.00166173 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [44] 4 ---> [45] 38 
Index within old batch: 1
  Input: [45] 38 ---> [46] 437 
Index within old batch: 2
  Input: [46] 437 ---> [47] 95 
Index within old batch: 3
  Input: [47] 95 ---> [48] 584 
Index within old batch: 4
  Input: [48] 584 ---> [49] 14 
Index within old batch: 5
  Input: [49] 14 ---> [50] 9517 
Index within old batch: 6
  Input: [50] 9517 ---> [51] 16 
Index within old batch: 7
  Input: [51] 957 ---> [52] 16 
Index within old batch: 8
  Input: [52] 16 ---> [53] 10 
[0 - 7f442c744000]   66.443883 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.443895 {3}{RequestManager}: Input tree: 44:4 45:38 46:437 47:95 48:584 49:14 50:9517 51:957 52:16
[0 - 7f442c744000]   66.443903 {3}{RequestManager}: Output tree: 45:38 46:437 47:95 48:584 49:14 50:9517 51:16 52:16 53:10
[0 - 7f442c744000]   66.443911 {3}{RequestManager}: Committed tokens: 0:44 1:45 2:46 3:47 4:48 5:49 6:50 7:51 8:52
[0 - 7f442c744000]   66.443922 {3}{RequestManager}: Verified: 45:38 46:437 47:95 48:584 49:14 50:9517 51:16
[0 - 7f442c744000]   66.443929 {3}{RequestManager}: New committed: 0:44 1:45 2:46 3:47 4:48 5:49 6:50
[0 - 7f442c744000]   66.443932 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7f442c744000]   66.444013 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is
[ 1000001 ]
Index within old batch: 9
  Input: [58] 5 ---> [59] 78 
Index within old batch: 10
  Input: [59] 316 ---> [60] 212 
Index within old batch: 11
  Input: [60] 212 ---> [61] 183 
Index within old batch: 12
  Input: [61] 183 ---> [62] 9 
Index within old batch: 13
  Input: [62] 9 ---> [63] 1619 
Index within old batch: 14
  Input: [63] 1619 ---> [64] 6 
Index within old batch: 15
  Input: [64] 6 ---> [65] 47 
Index within old batch: 16
  Input: [65] 47 ---> [66] 74 
Index within old batch: 17
  Input: [66] 74 ---> [67] 224 
[0 - 7f442c744000]   66.444137 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.444145 {3}{RequestManager}: Input tree: 58:5 59:316 60:212 61:183 62:9 63:1619 64:6 65:47 66:74
[0 - 7f442c744000]   66.444152 {3}{RequestManager}: Output tree: 59:78 60:212 61:183 62:9 63:1619 64:6 65:47 66:74 67:224
[0 - 7f442c744000]   66.444160 {3}{RequestManager}: Committed tokens: 9:58 10:59 11:60 12:61 13:62 14:63 15:64 16:65 17:66
[0 - 7f442c744000]   66.444165 {3}{RequestManager}: Verified: 59:78
[0 - 7f442c744000]   66.444170 {3}{RequestManager}: New committed: 9:58
[0 - 7f442c744000]   66.444173 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   66.444242 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first
[ 1000002 ]
Index within old batch: 18
  Input: [38] 4 ---> [39] 1437 
Index within old batch: 19
  Input: [39] 38 ---> [40] 1266 
Index within old batch: 20
  Input: [40] 437 ---> [41] 45 
Index within old batch: 21
  Input: [41] 45 ---> [42] 686 
Index within old batch: 22
  Input: [42] 686 ---> [43] 114 
Index within old batch: 23
  Input: [43] 114 ---> [44] 24 
Index within old batch: 24
  Input: [44] 38 ---> [45] 236 
Index within old batch: 25
  Input: [45] 197 ---> [46] 28 
Index within old batch: 26
  Input: [46] 28 ---> [47] 1372 
[0 - 7f442c744000]   66.444377 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.444385 {3}{RequestManager}: Input tree: 38:4 39:38 40:437 41:45 42:686 43:114 44:38 45:197 46:28
[0 - 7f442c744000]   66.444393 {3}{RequestManager}: Output tree: 39:1437 40:1266 41:45 42:686 43:114 44:24 45:236 46:28 47:1372
[0 - 7f442c744000]   66.444400 {3}{RequestManager}: Committed tokens: 18:38 19:39 20:40 21:41 22:42 23:43 24:44 25:45 26:46
[0 - 7f442c744000]   66.444406 {3}{RequestManager}: Verified: 39:1437
[0 - 7f442c744000]   66.444410 {3}{RequestManager}: New committed: 18:38
[0 - 7f442c744000]   66.444413 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   66.444467 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea. 

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   66.630110 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.630134 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.630560 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.630622 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.630648 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.630661 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631023 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631077 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631099 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631111 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631459 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631509 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631530 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631542 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631883 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631931 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631953 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.631964 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632300 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632346 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632368 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632379 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632729 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632777 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632800 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.632811 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633142 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633188 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633209 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633220 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633546 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633592 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633614 {3}{RequestManager}: SSMs inference time:0.00352703 s.
[0 - 7f442c744000]   66.633635 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633647 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633679 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633722 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.633757 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.635183 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.635239 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.635263 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.635276 {3}{RequestManager}: LLM Tree Verification time:0.00166652 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [51] 16 ---> [52] 5 
Index within old batch: 1
  Input: [52] 10 ---> [53] 2613 
Index within old batch: 2
  Input: [53] 372 ---> [54] 869 
Index within old batch: 3
  Input: [54] 869 ---> [55] 8 
Index within old batch: 4
  Input: [55] 8 ---> [56] 37 
Index within old batch: 5
  Input: [56] 38 ---> [57] 437 
Index within old batch: 6
  Input: [57] 437 ---> [58] 686 
Index within old batch: 7
  Input: [58] 686 ---> [59] 37 
Index within old batch: 8
  Input: [59] 37 ---> [60] 18 
[0 - 7f442c744000]   66.635486 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.635499 {3}{RequestManager}: Input tree: 51:16 52:10 53:372 54:869 55:8 56:38 57:437 58:686 59:37
[0 - 7f442c744000]   66.635508 {3}{RequestManager}: Output tree: 52:5 53:2613 54:869 55:8 56:37 57:437 58:686 59:37 60:18
[0 - 7f442c744000]   66.635517 {3}{RequestManager}: Committed tokens: 0:51 1:52 2:53 3:54 4:55 5:56 6:57 7:58 8:59
[0 - 7f442c744000]   66.635523 {3}{RequestManager}: Verified: 52:5
[0 - 7f442c744000]   66.635528 {3}{RequestManager}: New committed: 0:51
[0 - 7f442c744000]   66.635531 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   66.635606 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the
[ 1000001 ]
Index within old batch: 9
  Input: [59] 78 ---> [60] 183 
Index within old batch: 10
  Input: [60] 183 ---> [61] 9 
Index within old batch: 11
  Input: [61] 9 ---> [62] 1619 
Index within old batch: 12
  Input: [62] 1619 ---> [63] 6 
Index within old batch: 13
  Input: [63] 6 ---> [64] 47 
Index within old batch: 14
  Input: [64] 47 ---> [65] 74 
Index within old batch: 15
  Input: [65] 74 ---> [66] 3116 
Index within old batch: 16
  Input: [66] 3116 ---> [67] 35 
Index within old batch: 17
  Input: [67] 5 ---> [68] 511 
[0 - 7f442c744000]   66.635728 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.635736 {3}{RequestManager}: Input tree: 59:78 60:183 61:9 62:1619 63:6 64:47 65:74 66:3116 67:5
[0 - 7f442c744000]   66.635743 {3}{RequestManager}: Output tree: 60:183 61:9 62:1619 63:6 64:47 65:74 66:3116 67:35 68:511
[0 - 7f442c744000]   66.635751 {3}{RequestManager}: Committed tokens: 9:59 10:60 11:61 12:62 13:63 14:64 15:65 16:66 17:67
[0 - 7f442c744000]   66.635762 {3}{RequestManager}: Verified: 60:183 61:9 62:1619 63:6 64:47 65:74 66:3116 67:35
[0 - 7f442c744000]   66.635769 {3}{RequestManager}: New committed: 9:59 10:60 11:61 12:62 13:63 14:64 15:65 16:66
[0 - 7f442c744000]   66.635773 {3}{RequestManager}: Number of Verified Tokens = 8
[0 - 7f442c744000]   66.635873 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:
[ 1000002 ]
Index within old batch: 18
  Input: [39] 1437 ---> [40] 38 
Index within old batch: 19
  Input: [40] 38 ---> [41] 1266 
Index within old batch: 20
  Input: [41] 437 ---> [42] 45 
Index within old batch: 21
  Input: [42] 45 ---> [43] 686 
Index within old batch: 22
  Input: [43] 686 ---> [44] 114 
Index within old batch: 23
  Input: [44] 114 ---> [45] 24 
Index within old batch: 24
  Input: [45] 24 ---> [46] 18 
Index within old batch: 25
  Input: [46] 18 ---> [47] 10 
Index within old batch: 26
  Input: [47] 10 ---> [48] 1099 
[0 - 7f442c744000]   66.636011 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.636019 {3}{RequestManager}: Input tree: 39:1437 40:38 41:437 42:45 43:686 44:114 45:24 46:18 47:10
[0 - 7f442c744000]   66.636027 {3}{RequestManager}: Output tree: 40:38 41:1266 42:45 43:686 44:114 45:24 46:18 47:10 48:1099
[0 - 7f442c744000]   66.636034 {3}{RequestManager}: Committed tokens: 18:39 19:40 20:41 21:42 22:43 23:44 24:45 25:46 26:47
[0 - 7f442c744000]   66.636040 {3}{RequestManager}: Verified: 40:38 41:1266
[0 - 7f442c744000]   66.636045 {3}{RequestManager}: New committed: 18:39 19:40
[0 - 7f442c744000]   66.636048 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   66.636097 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   66.814003 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814026 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814470 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814507 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814534 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814546 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814918 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814949 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814970 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.814982 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815343 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815372 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815404 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815758 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815787 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815809 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.815819 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816171 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816199 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816220 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816231 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816592 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816622 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816645 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.816656 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817009 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817037 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817058 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817070 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817418 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817444 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817466 {3}{RequestManager}: SSMs inference time:0.00348549 s.
[0 - 7f442c744000]   66.817486 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817498 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817531 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817574 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.817609 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.819046 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.819103 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.819127 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   66.819141 {3}{RequestManager}: LLM Tree Verification time:0.00167923 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [52] 5 ---> [53] 275 
Index within old batch: 1
  Input: [53] 275 ---> [54] 869 
Index within old batch: 2
  Input: [54] 869 ---> [55] 11 
Index within old batch: 3
  Input: [55] 11 ---> [56] 5 
Index within old batch: 4
  Input: [56] 5 ---> [57] 2762 
Index within old batch: 5
  Input: [57] 2762 ---> [58] 4 
Index within old batch: 6
  Input: [58] 235 ---> [59] 122 
Index within old batch: 7
  Input: [59] 122 ---> [60] 4 
Index within old batch: 8
  Input: [60] 4 ---> [61] 50118 
[0 - 7f442c744000]   66.819326 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.819339 {3}{RequestManager}: Input tree: 52:5 53:275 54:869 55:11 56:5 57:2762 58:235 59:122 60:4
[0 - 7f442c744000]   66.819347 {3}{RequestManager}: Output tree: 53:275 54:869 55:11 56:5 57:2762 58:4 59:122 60:4 61:50118
[0 - 7f442c744000]   66.819355 {3}{RequestManager}: Committed tokens: 0:52 1:53 2:54 3:55 4:56 5:57 6:58 7:59 8:60
[0 - 7f442c744000]   66.819365 {3}{RequestManager}: Verified: 53:275 54:869 55:11 56:5 57:2762 58:4
[0 - 7f442c744000]   66.819372 {3}{RequestManager}: New committed: 0:52 1:53 2:54 3:55 4:56 5:57
[0 - 7f442c744000]   66.819376 {3}{RequestManager}: Number of Verified Tokens = 6
[0 - 7f442c744000]   66.819525 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
[ 1000001 ]
Index within old batch: 9
  Input: [67] 35 ---> [68] 50118 
Index within old batch: 10
  Input: [68] 50118 ---> [69] 50118 
Index within old batch: 11
  Input: [69] 50118 ---> [70] 134 
Index within old batch: 12
  Input: [70] 113 ---> [71] 4148 
Index within old batch: 13
  Input: [71] 1092 ---> [72] 360 
Index within old batch: 14
  Input: [72] 10046 ---> [73] 9 
Index within old batch: 15
  Input: [73] 9 ---> [74] 1619 
Index within old batch: 16
  Input: [74] 1619 ---> [75] 113 
Index within old batch: 17
  Input: [75] 113 ---> [76] 50118 
[0 - 7f442c744000]   66.819651 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.819659 {3}{RequestManager}: Input tree: 67:35 68:50118 69:50118 70:113 71:1092 72:10046 73:9 74:1619 75:113
[0 - 7f442c744000]   66.819668 {3}{RequestManager}: Output tree: 68:50118 69:50118 70:134 71:4148 72:360 73:9 74:1619 75:113 76:50118
[0 - 7f442c744000]   66.819675 {3}{RequestManager}: Committed tokens: 9:67 10:68 11:69 12:70 13:71 14:72 15:73 16:74 17:75
[0 - 7f442c744000]   66.819683 {3}{RequestManager}: Verified: 68:50118 69:50118 70:134
[0 - 7f442c744000]   66.819689 {3}{RequestManager}: New committed: 9:67 10:68 11:69
[0 - 7f442c744000]   66.819692 {3}{RequestManager}: Number of Verified Tokens = 3
[0 - 7f442c744000]   66.819777 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1
[ 1000002 ]
Index within old batch: 18
  Input: [41] 1266 ---> [42] 6 
Index within old batch: 19
  Input: [42] 6 ---> [43] 38 
Index within old batch: 20
  Input: [43] 38 ---> [44] 437 
Index within old batch: 21
  Input: [44] 437 ---> [45] 70 
Index within old batch: 22
  Input: [45] 45 ---> [46] 686 
Index within old batch: 23
  Input: [46] 686 ---> [47] 114 
Index within old batch: 24
  Input: [47] 114 ---> [48] 24 
Index within old batch: 25
  Input: [48] 24 ---> [49] 18 
Index within old batch: 26
  Input: [49] 18 ---> [50] 10 
[0 - 7f442c744000]   66.819917 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   66.819925 {3}{RequestManager}: Input tree: 41:1266 42:6 43:38 44:437 45:45 46:686 47:114 48:24 49:18
[0 - 7f442c744000]   66.819933 {3}{RequestManager}: Output tree: 42:6 43:38 44:437 45:70 46:686 47:114 48:24 49:18 50:10
[0 - 7f442c744000]   66.819940 {3}{RequestManager}: Committed tokens: 18:41 19:42 20:43 21:44 22:45 23:46 24:47 25:48 26:49
[0 - 7f442c744000]   66.819948 {3}{RequestManager}: Verified: 42:6 43:38 44:437 45:70
[0 - 7f442c744000]   66.819954 {3}{RequestManager}: New committed: 18:41 19:42 20:43 21:44
[0 - 7f442c744000]   66.819957 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   66.820007 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.003904 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.003928 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004376 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004413 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004440 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004452 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004847 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004878 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004900 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.004912 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005328 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005362 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005386 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005397 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005760 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005790 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005812 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.005824 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006174 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006201 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006222 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006234 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006582 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006610 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006631 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006643 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.006988 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007017 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007038 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007050 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007393 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007443 {3}{RequestManager}: SSMs inference time:0.00356184 s.
[0 - 7f442c744000]   67.007463 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007476 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007506 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007547 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.007581 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.009020 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.009075 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.009100 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.009113 {3}{RequestManager}: LLM Tree Verification time:0.00167462 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [58] 4 ---> [59] 50118 
Index within old batch: 1
  Input: [59] 50118 ---> [60] 100 
Index within old batch: 2
  Input: [60] 100 ---> [61] 216 
Index within old batch: 3
  Input: [61] 437 ---> [62] 45 
Index within old batch: 4
  Input: [62] 45 ---> [63] 686 
Index within old batch: 5
  Input: [63] 584 ---> [64] 37 
Index within old batch: 6
  Input: [64] 37 ---> [65] 965 
Index within old batch: 7
  Input: [65] 18 ---> [66] 45 
Index within old batch: 8
  Input: [66] 5 ---> [67] 275 
[0 - 7f442c744000]   67.009342 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.009355 {3}{RequestManager}: Input tree: 58:4 59:50118 60:100 61:437 62:45 63:584 64:37 65:18 66:5
[0 - 7f442c744000]   67.009363 {3}{RequestManager}: Output tree: 59:50118 60:100 61:216 62:45 63:686 64:37 65:965 66:45 67:275
[0 - 7f442c744000]   67.009371 {3}{RequestManager}: Committed tokens: 0:58 1:59 2:60 3:61 4:62 5:63 6:64 7:65 8:66
[0 - 7f442c744000]   67.009379 {3}{RequestManager}: Verified: 59:50118 60:100 61:216
[0 - 7f442c744000]   67.009385 {3}{RequestManager}: New committed: 0:58 1:59 2:60
[0 - 7f442c744000]   67.009388 {3}{RequestManager}: Number of Verified Tokens = 3
[0 - 7f442c744000]   67.009471 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know
[ 1000001 ]
Index within old batch: 9
  Input: [70] 134 ---> [71] 4 
Index within old batch: 10
  Input: [71] 4 ---> [72] 83 
Index within old batch: 11
  Input: [72] 22 ---> [73] 250 
Index within old batch: 12
  Input: [73] 100 ---> [74] 851 
Index within old batch: 13
  Input: [74] 657 ---> [75] 47 
Index within old batch: 14
  Input: [75] 47 ---> [76] 113 
Index within old batch: 15
  Input: [76] 113 ---> [77] 50118 
Index within old batch: 16
  Input: [77] 50118 ---> [78] 50118 
Index within old batch: 17
  Input: [78] 176 ---> [79] 4 
[0 - 7f442c744000]   67.009606 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.009614 {3}{RequestManager}: Input tree: 70:134 71:4 72:22 73:100 74:657 75:47 76:113 77:50118 78:176
[0 - 7f442c744000]   67.009622 {3}{RequestManager}: Output tree: 71:4 72:83 73:250 74:851 75:47 76:113 77:50118 78:50118 79:4
[0 - 7f442c744000]   67.009629 {3}{RequestManager}: Committed tokens: 9:70 10:71 11:72 12:73 13:74 14:75 15:76 16:77 17:78
[0 - 7f442c744000]   67.009635 {3}{RequestManager}: Verified: 71:4 72:83
[0 - 7f442c744000]   67.009640 {3}{RequestManager}: New committed: 9:70 10:71
[0 - 7f442c744000]   67.009643 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   67.009732 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A
[ 1000002 ]
Index within old batch: 18
  Input: [45] 70 ---> [46] 13 
Index within old batch: 19
  Input: [46] 13 ---> [47] 24 
Index within old batch: 20
  Input: [47] 5 ---> [48] 1114 
Index within old batch: 21
  Input: [48] 1114 ---> [49] 9 
Index within old batch: 22
  Input: [49] 9 ---> [50] 10 
Index within old batch: 23
  Input: [50] 10 ---> [51] 22 
Index within old batch: 24
  Input: [51] 22 ---> [52] 2362 
Index within old batch: 25
  Input: [52] 3743 ---> [53] 113 
Index within old batch: 26
  Input: [53] 113 ---> [54] 210 
[0 - 7f442c744000]   67.009851 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.009859 {3}{RequestManager}: Input tree: 45:70 46:13 47:5 48:1114 49:9 50:10 51:22 52:3743 53:113
[0 - 7f442c744000]   67.009867 {3}{RequestManager}: Output tree: 46:13 47:24 48:1114 49:9 50:10 51:22 52:2362 53:113 54:210
[0 - 7f442c744000]   67.009874 {3}{RequestManager}: Committed tokens: 18:45 19:46 20:47 21:48 22:49 23:50 24:51 25:52 26:53
[0 - 7f442c744000]   67.009880 {3}{RequestManager}: Verified: 46:13 47:24
[0 - 7f442c744000]   67.009884 {3}{RequestManager}: New committed: 18:45 19:46
[0 - 7f442c744000]   67.009888 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   67.009942 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.194916 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.194939 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195396 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195437 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195464 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195475 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195848 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195880 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195901 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.195912 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196272 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196303 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196325 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196336 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196706 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196737 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196759 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.196770 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197126 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197154 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197176 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197187 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197568 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197589 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197600 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197947 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197975 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.197997 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198008 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198352 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198379 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198401 {3}{RequestManager}: SSMs inference time:0.00350948 s.
[0 - 7f442c744000]   67.198421 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198433 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198465 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198507 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.198543 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.199982 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.200037 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.200063 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.200075 {3}{RequestManager}: LLM Tree Verification time:0.00167897 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [61] 216 ---> [62] 6 
Index within old batch: 1
  Input: [62] 6 ---> [63] 38 
Index within old batch: 2
  Input: [63] 38 ---> [64] 21 
Index within old batch: 3
  Input: [64] 437 ---> [65] 95 
Index within old batch: 4
  Input: [65] 95 ---> [66] 584 
Index within old batch: 5
  Input: [66] 584 ---> [67] 14 
Index within old batch: 6
  Input: [67] 14 ---> [68] 37 
Index within old batch: 7
  Input: [68] 9517 ---> [69] 16 
Index within old batch: 8
  Input: [69] 16 ---> [70] 45 
[0 - 7f442c744000]   67.200273 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.200285 {3}{RequestManager}: Input tree: 61:216 62:6 63:38 64:437 65:95 66:584 67:14 68:9517 69:16
[0 - 7f442c744000]   67.200294 {3}{RequestManager}: Output tree: 62:6 63:38 64:21 65:95 66:584 67:14 68:37 69:16 70:45
[0 - 7f442c744000]   67.200302 {3}{RequestManager}: Committed tokens: 0:61 1:62 2:63 3:64 4:65 5:66 6:67 7:68 8:69
[0 - 7f442c744000]   67.200311 {3}{RequestManager}: Verified: 62:6 63:38 64:21
[0 - 7f442c744000]   67.200317 {3}{RequestManager}: New committed: 0:61 1:62 2:63
[0 - 7f442c744000]   67.200320 {3}{RequestManager}: Number of Verified Tokens = 3
[0 - 7f442c744000]   67.200425 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was
[ 1000001 ]
Index within old batch: 9
  Input: [72] 83 ---> [73] 7359 
Index within old batch: 10
  Input: [73] 4085 ---> [74] 9 
Index within old batch: 11
  Input: [74] 13 ---> [75] 10 
Index within old batch: 12
  Input: [75] 10 ---> [76] 7359 
Index within old batch: 13
  Input: [76] 7359 ---> [77] 12749 
Index within old batch: 14
  Input: [77] 12749 ---> [78] 50118 
Index within old batch: 15
  Input: [78] 4 ---> [79] 50118 
Index within old batch: 16
  Input: [79] 50118 ---> [80] 50118 
Index within old batch: 17
  Input: [80] 50118 ---> [81] 176 
[0 - 7f442c744000]   67.200563 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.200571 {3}{RequestManager}: Input tree: 72:83 73:4085 74:13 75:10 76:7359 77:12749 78:4 79:50118 80:50118
[0 - 7f442c744000]   67.200580 {3}{RequestManager}: Output tree: 73:7359 74:9 75:10 76:7359 77:12749 78:50118 79:50118 80:50118 81:176
[0 - 7f442c744000]   67.200587 {3}{RequestManager}: Committed tokens: 9:72 10:73 11:74 12:75 13:76 14:77 15:78 16:79 17:80
[0 - 7f442c744000]   67.200593 {3}{RequestManager}: Verified: 73:7359
[0 - 7f442c744000]   67.200597 {3}{RequestManager}: New committed: 9:72
[0 - 7f442c744000]   67.200601 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   67.200683 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chat
[ 1000002 ]
Index within old batch: 18
  Input: [47] 24 ---> [48] 6 
Index within old batch: 19
  Input: [48] 6 ---> [49] 53 
Index within old batch: 20
  Input: [49] 53 ---> [50] 38 
Index within old batch: 21
  Input: [50] 38 ---> [51] 437 
Index within old batch: 22
  Input: [51] 218 ---> [52] 75 
Index within old batch: 23
  Input: [52] 75 ---> [53] 216 
Index within old batch: 24
  Input: [53] 206 ---> [54] 24 
Index within old batch: 25
  Input: [54] 24 ---> [55] 18 
Index within old batch: 26
  Input: [55] 18 ---> [56] 10 
[0 - 7f442c744000]   67.200803 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.200811 {3}{RequestManager}: Input tree: 47:24 48:6 49:53 50:38 51:218 52:75 53:206 54:24 55:18
[0 - 7f442c744000]   67.200819 {3}{RequestManager}: Output tree: 48:6 49:53 50:38 51:437 52:75 53:216 54:24 55:18 56:10
[0 - 7f442c744000]   67.200826 {3}{RequestManager}: Committed tokens: 18:47 19:48 20:49 21:50 22:51 23:52 24:53 25:54 26:55
[0 - 7f442c744000]   67.200834 {3}{RequestManager}: Verified: 48:6 49:53 50:38 51:437
[0 - 7f442c744000]   67.200840 {3}{RequestManager}: New committed: 18:47 19:48 20:49 21:50
[0 - 7f442c744000]   67.200844 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   67.200900 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.406578 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.406632 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.407978 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408110 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408148 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408161 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408622 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408664 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408691 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.408705 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409127 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409168 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409193 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409211 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409611 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409642 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409667 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.409685 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410071 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410104 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410126 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410144 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410543 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410572 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410603 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.410618 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411011 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411038 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411061 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411075 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411468 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411496 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411520 {3}{RequestManager}: SSMs inference time:0.00499063 s.
[0 - 7f442c744000]   67.411544 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411557 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411588 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411634 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.411670 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.413437 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.413495 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.413520 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.413536 {3}{RequestManager}: LLM Tree Verification time:0.0020212 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [64] 21 ---> [65] 95 
Index within old batch: 1
  Input: [65] 95 ---> [66] 584 
Index within old batch: 2
  Input: [66] 584 ---> [67] 14 
Index within old batch: 3
  Input: [67] 14 ---> [68] 38 
Index within old batch: 4
  Input: [68] 9517 ---> [69] 16 
Index within old batch: 5
  Input: [69] 16 ---> [70] 45 
Index within old batch: 6
  Input: [70] 5 ---> [71] 275 
Index within old batch: 7
  Input: [71] 275 ---> [72] 869 
Index within old batch: 8
  Input: [72] 869 ---> [73] 11 
[0 - 7f442c744000]   67.413756 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.413770 {3}{RequestManager}: Input tree: 64:21 65:95 66:584 67:14 68:9517 69:16 70:5 71:275 72:869
[0 - 7f442c744000]   67.413780 {3}{RequestManager}: Output tree: 65:95 66:584 67:14 68:38 69:16 70:45 71:275 72:869 73:11
[0 - 7f442c744000]   67.413789 {3}{RequestManager}: Committed tokens: 0:64 1:65 2:66 3:67 4:68 5:69 6:70 7:71 8:72
[0 - 7f442c744000]   67.413799 {3}{RequestManager}: Verified: 65:95 66:584 67:14 68:38
[0 - 7f442c744000]   67.413807 {3}{RequestManager}: New committed: 0:64 1:65 2:66 3:67
[0 - 7f442c744000]   67.413811 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   67.413916 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I
[ 1000001 ]
Index within old batch: 9
  Input: [73] 7359 ---> [74] 12749 
Index within old batch: 10
  Input: [74] 12749 ---> [75] 15 
Index within old batch: 11
  Input: [75] 14 ---> [76] 64 
Index within old batch: 12
  Input: [76] 16 ---> [77] 460 
Index within old batch: 13
  Input: [77] 164 ---> [78] 7 
Index within old batch: 14
  Input: [78] 7 ---> [79] 28 
Index within old batch: 15
  Input: [79] 28 ---> [80] 10 
Index within old batch: 16
  Input: [80] 10 ---> [81] 372 
Index within old batch: 17
  Input: [81] 4085 ---> [82] 15 
[0 - 7f442c744000]   67.414048 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.414057 {3}{RequestManager}: Input tree: 73:7359 74:12749 75:14 76:16 77:164 78:7 79:28 80:10 81:4085
[0 - 7f442c744000]   67.414065 {3}{RequestManager}: Output tree: 74:12749 75:15 76:64 77:460 78:7 79:28 80:10 81:372 82:15
[0 - 7f442c744000]   67.414073 {3}{RequestManager}: Committed tokens: 9:73 10:74 11:75 12:76 13:77 14:78 15:79 16:80 17:81
[0 - 7f442c744000]   67.414079 {3}{RequestManager}: Verified: 74:12749 75:15
[0 - 7f442c744000]   67.414084 {3}{RequestManager}: New committed: 9:73 10:74
[0 - 7f442c744000]   67.414087 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   67.414176 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on
[ 1000002 ]
Index within old batch: 18
  Input: [51] 437 ---> [52] 45 
Index within old batch: 19
  Input: [52] 45 ---> [53] 686 
Index within old batch: 20
  Input: [53] 686 ---> [54] 114 
Index within old batch: 21
  Input: [54] 114 ---> [55] 24 
Index within old batch: 22
  Input: [55] 24 ---> [56] 18 
Index within old batch: 23
  Input: [56] 18 ---> [57] 10 
Index within old batch: 24
  Input: [57] 10 ---> [58] 205 
Index within old batch: 25
  Input: [58] 205 ---> [59] 1114 
Index within old batch: 26
  Input: [59] 1114 ---> [60] 4 
[0 - 7f442c744000]   67.414299 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.414307 {3}{RequestManager}: Input tree: 51:437 52:45 53:686 54:114 55:24 56:18 57:10 58:205 59:1114
[0 - 7f442c744000]   67.414314 {3}{RequestManager}: Output tree: 52:45 53:686 54:114 55:24 56:18 57:10 58:205 59:1114 60:4
[0 - 7f442c744000]   67.414322 {3}{RequestManager}: Committed tokens: 18:51 19:52 20:53 21:54 22:55 23:56 24:57 25:58 26:59
[0 - 7f442c744000]   67.414336 {3}{RequestManager}: Verified: 52:45 53:686 54:114 55:24 56:18 57:10 58:205 59:1114 60:4
[0 - 7f442c744000]   67.414344 {3}{RequestManager}: New committed: 18:51 19:52 20:53 21:54 22:55 23:56 24:57 25:58 26:59
[0 - 7f442c744000]   67.414348 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   67.414412 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.587325 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.587355 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.587826 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.587869 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.587898 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.587910 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588351 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588387 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588410 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588422 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588827 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588859 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588881 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.588892 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589283 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589314 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589335 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589347 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589730 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589760 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589781 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.589792 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590196 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590225 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590260 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590637 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590666 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590689 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.590700 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591072 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591100 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591124 {3}{RequestManager}: SSMs inference time:0.00382915 s.
[0 - 7f442c744000]   67.591146 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591159 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591191 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591237 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.591274 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.592809 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.592868 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.592892 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.592908 {3}{RequestManager}: LLM Tree Verification time:0.00178877 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [68] 38 ---> [69] 437 
Index within old batch: 1
  Input: [69] 437 ---> [70] 45 
Index within old batch: 2
  Input: [70] 45 ---> [71] 686 
Index within old batch: 3
  Input: [71] 686 ---> [72] 114 
Index within old batch: 4
  Input: [72] 114 ---> [73] 37 
Index within old batch: 5
  Input: [73] 47 ---> [74] 58 
Index within old batch: 6
  Input: [74] 214 ---> [75] 145 
Index within old batch: 7
  Input: [75] 145 ---> [76] 39580 
Index within old batch: 8
  Input: [76] 39580 ---> [77] 50 
[0 - 7f442c744000]   67.593121 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.593136 {3}{RequestManager}: Input tree: 68:38 69:437 70:45 71:686 72:114 73:47 74:214 75:145 76:39580
[0 - 7f442c744000]   67.593146 {3}{RequestManager}: Output tree: 69:437 70:45 71:686 72:114 73:37 74:58 75:145 76:39580 77:50
[0 - 7f442c744000]   67.593155 {3}{RequestManager}: Committed tokens: 0:68 1:69 2:70 3:71 4:72 5:73 6:74 7:75 8:76
[0 - 7f442c744000]   67.593166 {3}{RequestManager}: Verified: 69:437 70:45 71:686 72:114 73:37
[0 - 7f442c744000]   67.593173 {3}{RequestManager}: New committed: 0:68 1:69 2:70 3:71 4:72
[0 - 7f442c744000]   67.593177 {3}{RequestManager}: Number of Verified Tokens = 5
[0 - 7f442c744000]   67.593281 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he
[ 1000001 ]
Index within old batch: 9
  Input: [75] 15 ---> [76] 5 
Index within old batch: 10
  Input: [76] 5 ---> [77] 78 
Index within old batch: 11
  Input: [77] 78 ---> [78] 183 
Index within old batch: 12
  Input: [78] 183 ---> [79] 9 
Index within old batch: 13
  Input: [79] 9 ---> [80] 1619 
Index within old batch: 14
  Input: [80] 1619 ---> [81] 50118 
Index within old batch: 15
  Input: [81] 50118 ---> [82] 50118 
Index within old batch: 16
  Input: [82] 50118 ---> [83] 176 
Index within old batch: 17
  Input: [83] 176 ---> [84] 4 
[0 - 7f442c744000]   67.593407 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.593416 {3}{RequestManager}: Input tree: 75:15 76:5 77:78 78:183 79:9 80:1619 81:50118 82:50118 83:176
[0 - 7f442c744000]   67.593424 {3}{RequestManager}: Output tree: 76:5 77:78 78:183 79:9 80:1619 81:50118 82:50118 83:176 84:4
[0 - 7f442c744000]   67.593432 {3}{RequestManager}: Committed tokens: 9:75 10:76 11:77 12:78 13:79 14:80 15:81 16:82 17:83
[0 - 7f442c744000]   67.593443 {3}{RequestManager}: Verified: 76:5 77:78 78:183 79:9 80:1619 81:50118 82:50118 83:176 84:4
[0 - 7f442c744000]   67.593451 {3}{RequestManager}: New committed: 9:75 10:76 11:77 12:78 13:79 14:80 15:81 16:82 17:83
[0 - 7f442c744000]   67.593455 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   67.593556 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2.
[ 1000002 ]
Index within old batch: 18
  Input: [60] 4 ---> [61] 1437 
Index within old batch: 19
  Input: [61] 1437 ---> [62] 38 
Index within old batch: 20
  Input: [62] 38 ---> [63] 1266 
Index within old batch: 21
  Input: [63] 1266 ---> [64] 6 
Index within old batch: 22
  Input: [64] 6 ---> [65] 38 
Index within old batch: 23
  Input: [65] 38 ---> [66] 437 
Index within old batch: 24
  Input: [66] 437 ---> [67] 70 
Index within old batch: 25
  Input: [67] 45 ---> [68] 686 
Index within old batch: 26
  Input: [68] 686 ---> [69] 114 
[0 - 7f442c744000]   67.593678 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.593686 {3}{RequestManager}: Input tree: 60:4 61:1437 62:38 63:1266 64:6 65:38 66:437 67:45 68:686
[0 - 7f442c744000]   67.593693 {3}{RequestManager}: Output tree: 61:1437 62:38 63:1266 64:6 65:38 66:437 67:70 68:686 69:114
[0 - 7f442c744000]   67.593701 {3}{RequestManager}: Committed tokens: 18:60 19:61 20:62 21:63 22:64 23:65 24:66 25:67 26:68
[0 - 7f442c744000]   67.593710 {3}{RequestManager}: Verified: 61:1437 62:38 63:1266 64:6 65:38 66:437 67:70
[0 - 7f442c744000]   67.593717 {3}{RequestManager}: New committed: 18:60 19:61 20:62 21:63 22:64 23:65 24:66
[0 - 7f442c744000]   67.593721 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7f442c744000]   67.593786 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.767446 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.767471 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.767916 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.767954 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.767979 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.767991 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768416 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768449 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768472 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768484 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768873 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768905 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768927 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.768938 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769322 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769352 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769374 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769385 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769761 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769790 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769811 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.769822 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770198 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770248 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770259 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770633 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770662 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770683 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.770695 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771066 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771095 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771118 {3}{RequestManager}: SSMs inference time:0.00369578 s.
[0 - 7f442c744000]   67.771139 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771151 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771182 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771226 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.771263 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.772799 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.772857 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.772882 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.772896 {3}{RequestManager}: LLM Tree Verification time:0.00178288 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [73] 37 ---> [74] 21 
Index within old batch: 1
  Input: [74] 18 ---> [75] 145 
Index within old batch: 2
  Input: [75] 145 ---> [76] 39580 
Index within old batch: 3
  Input: [76] 39580 ---> [77] 50 
Index within old batch: 4
  Input: [77] 50 ---> [78] 45 
Index within old batch: 5
  Input: [78] 45 ---> [79] 4 
Index within old batch: 6
  Input: [79] 4 ---> [80] 2 
Index within old batch: 7
  Input: [80] 2 ---> [81] 100 
Index within old batch: 8
  Input: [81] 100 ---> [82] 437 
[0 - 7f442c744000]   67.773106 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.773120 {3}{RequestManager}: Input tree: 73:37 74:18 75:145 76:39580 77:50 78:45 79:4 80:2 81:100
[0 - 7f442c744000]   67.773128 {3}{RequestManager}: Output tree: 74:21 75:145 76:39580 77:50 78:45 79:4 80:2 81:100 82:437
[0 - 7f442c744000]   67.773137 {3}{RequestManager}: Committed tokens: 0:73 1:74 2:75 3:76 4:77 5:78 6:79 7:80 8:81
[0 - 7f442c744000]   67.773143 {3}{RequestManager}: Verified: 74:21
[0 - 7f442c744000]   67.773148 {3}{RequestManager}: New committed: 0:73
[0 - 7f442c744000]   67.773152 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   67.773252 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was
[ 1000001 ]
Index within old batch: 9
  Input: [84] 4 ---> [85] 851 
Index within old batch: 10
  Input: [85] 83 ---> [86] 7359 
Index within old batch: 11
  Input: [86] 7359 ---> [87] 12749 
Index within old batch: 12
  Input: [87] 12749 ---> [88] 15 
Index within old batch: 13
  Input: [88] 15 ---> [89] 5 
Index within old batch: 14
  Input: [89] 5 ---> [90] 200 
Index within old batch: 15
  Input: [90] 200 ---> [91] 183 
Index within old batch: 16
  Input: [91] 183 ---> [92] 9 
Index within old batch: 17
  Input: [92] 9 ---> [93] 1619 
[0 - 7f442c744000]   67.773375 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.773383 {3}{RequestManager}: Input tree: 84:4 85:83 86:7359 87:12749 88:15 89:5 90:200 91:183 92:9
[0 - 7f442c744000]   67.773391 {3}{RequestManager}: Output tree: 85:851 86:7359 87:12749 88:15 89:5 90:200 91:183 92:9 93:1619
[0 - 7f442c744000]   67.773399 {3}{RequestManager}: Committed tokens: 9:84 10:85 11:86 12:87 13:88 14:89 15:90 16:91 17:92
[0 - 7f442c744000]   67.773405 {3}{RequestManager}: Verified: 85:851
[0 - 7f442c744000]   67.773409 {3}{RequestManager}: New committed: 9:84
[0 - 7f442c744000]   67.773413 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   67.773508 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave
[ 1000002 ]
Index within old batch: 18
  Input: [67] 70 ---> [68] 13 
Index within old batch: 19
  Input: [68] 13 ---> [69] 24 
Index within old batch: 20
  Input: [69] 24 ---> [70] 6 
Index within old batch: 21
  Input: [70] 6 ---> [71] 53 
Index within old batch: 22
  Input: [71] 53 ---> [72] 38 
Index within old batch: 23
  Input: [72] 38 ---> [73] 437 
Index within old batch: 24
  Input: [73] 437 ---> [74] 45 
Index within old batch: 25
  Input: [74] 45 ---> [75] 686 
Index within old batch: 26
  Input: [75] 686 ---> [76] 114 
[0 - 7f442c744000]   67.773646 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.773655 {3}{RequestManager}: Input tree: 67:70 68:13 69:24 70:6 71:53 72:38 73:437 74:45 75:686
[0 - 7f442c744000]   67.773663 {3}{RequestManager}: Output tree: 68:13 69:24 70:6 71:53 72:38 73:437 74:45 75:686 76:114
[0 - 7f442c744000]   67.773670 {3}{RequestManager}: Committed tokens: 18:67 19:68 20:69 21:70 22:71 23:72 24:73 25:74 26:75
[0 - 7f442c744000]   67.773682 {3}{RequestManager}: Verified: 68:13 69:24 70:6 71:53 72:38 73:437 74:45 75:686 76:114
[0 - 7f442c744000]   67.773689 {3}{RequestManager}: New committed: 18:67 19:68 20:69 21:70 22:71 23:72 24:73 25:74 26:75
[0 - 7f442c744000]   67.773693 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   67.773770 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   67.970156 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.970180 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.970630 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.970667 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.970697 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.970709 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971106 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971141 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971163 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971175 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971568 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971600 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971622 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.971633 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972032 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972065 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972087 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972099 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972483 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972512 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972534 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972545 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972919 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972948 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972970 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.972982 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973355 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973383 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973405 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973416 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973787 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973815 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973838 {3}{RequestManager}: SSMs inference time:0.00370564 s.
[0 - 7f442c744000]   67.973858 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973876 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973908 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973952 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.973986 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.975493 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.975550 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.975574 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   67.975588 {3}{RequestManager}: LLM Tree Verification time:0.00175522 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [74] 21 ---> [75] 145 
Index within old batch: 1
  Input: [75] 22024 ---> [76] 50 
Index within old batch: 2
  Input: [76] 50 ---> [77] 45 
Index within old batch: 3
  Input: [77] 45 ---> [78] 4 
Index within old batch: 4
  Input: [78] 4 ---> [79] 2 
Index within old batch: 5
  Input: [79] 2 ---> [80] 100 
Index within old batch: 6
  Input: [80] 100 ---> [81] 437 
Index within old batch: 7
  Input: [81] 437 ---> [82] 45 
Index within old batch: 8
  Input: [82] 45 ---> [83] 686 
[0 - 7f442c744000]   67.975787 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.975800 {3}{RequestManager}: Input tree: 74:21 75:22024 76:50 77:45 78:4 79:2 80:100 81:437 82:45
[0 - 7f442c744000]   67.975809 {3}{RequestManager}: Output tree: 75:145 76:50 77:45 78:4 79:2 80:100 81:437 82:45 83:686
[0 - 7f442c744000]   67.975816 {3}{RequestManager}: Committed tokens: 0:74 1:75 2:76 3:77 4:78 5:79 6:80 7:81 8:82
[0 - 7f442c744000]   67.975823 {3}{RequestManager}: Verified: 75:145
[0 - 7f442c744000]   67.975827 {3}{RequestManager}: New committed: 0:74
[0 - 7f442c744000]   67.975831 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   67.975931 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being
[ 1000001 ]
Index within old batch: 9
  Input: [85] 851 ---> [86] 7 
Index within old batch: 10
  Input: [86] 10 ---> [87] 7359 
Index within old batch: 11
  Input: [87] 4085 ---> [88] 7 
Index within old batch: 12
  Input: [88] 15 ---> [89] 5 
Index within old batch: 13
  Input: [89] 5 ---> [90] 200 
Index within old batch: 14
  Input: [90] 200 ---> [91] 183 
Index within old batch: 15
  Input: [91] 183 ---> [92] 9 
Index within old batch: 16
  Input: [92] 9 ---> [93] 1619 
Index within old batch: 17
  Input: [93] 1619 ---> [94] 50118 
[0 - 7f442c744000]   67.976068 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.976076 {3}{RequestManager}: Input tree: 85:851 86:10 87:4085 88:15 89:5 90:200 91:183 92:9 93:1619
[0 - 7f442c744000]   67.976084 {3}{RequestManager}: Output tree: 86:7 87:7359 88:7 89:5 90:200 91:183 92:9 93:1619 94:50118
[0 - 7f442c744000]   67.976092 {3}{RequestManager}: Committed tokens: 9:85 10:86 11:87 12:88 13:89 14:90 15:91 16:92 17:93
[0 - 7f442c744000]   67.976097 {3}{RequestManager}: Verified: 86:7
[0 - 7f442c744000]   67.976101 {3}{RequestManager}: New committed: 9:85
[0 - 7f442c744000]   67.976105 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   67.976199 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to
[ 1000002 ]
Index within old batch: 18
  Input: [76] 114 ---> [77] 24 
Index within old batch: 19
  Input: [77] 24 ---> [78] 18 
Index within old batch: 20
  Input: [78] 18 ---> [79] 10 
Index within old batch: 21
  Input: [79] 10 ---> [80] 205 
Index within old batch: 22
  Input: [80] 205 ---> [81] 1114 
Index within old batch: 23
  Input: [81] 1114 ---> [82] 4 
Index within old batch: 24
  Input: [82] 4 ---> [83] 1437 
Index within old batch: 25
  Input: [83] 1437 ---> [84] 38 
Index within old batch: 26
  Input: [84] 38 ---> [85] 1266 
[0 - 7f442c744000]   67.976332 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   67.976340 {3}{RequestManager}: Input tree: 76:114 77:24 78:18 79:10 80:205 81:1114 82:4 83:1437 84:38
[0 - 7f442c744000]   67.976347 {3}{RequestManager}: Output tree: 77:24 78:18 79:10 80:205 81:1114 82:4 83:1437 84:38 85:1266
[0 - 7f442c744000]   67.976354 {3}{RequestManager}: Committed tokens: 18:76 19:77 20:78 21:79 22:80 23:81 24:82 25:83 26:84
[0 - 7f442c744000]   67.976364 {3}{RequestManager}: Verified: 77:24 78:18 79:10 80:205 81:1114 82:4 83:1437 84:38 85:1266
[0 - 7f442c744000]   67.976372 {3}{RequestManager}: New committed: 18:76 19:77 20:78 21:79 22:80 23:81 24:82 25:83 26:84
[0 - 7f442c744000]   67.976376 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   67.976453 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   68.151822 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.151854 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152325 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152395 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152422 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152435 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152853 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152888 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152910 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.152922 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153326 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153358 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153380 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153392 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153780 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153812 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153834 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.153846 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154230 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154261 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154282 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154294 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154674 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154703 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154725 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.154736 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155116 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155145 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155167 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155178 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155555 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155584 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155607 {3}{RequestManager}: SSMs inference time:0.00381405 s.
[0 - 7f442c744000]   68.155630 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155644 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155675 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155718 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.155753 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.157219 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.157277 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.157304 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.157320 {3}{RequestManager}: LLM Tree Verification time:0.00171787 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [75] 145 ---> [76] 39580 
Index within old batch: 1
  Input: [76] 39580 ---> [77] 50 
Index within old batch: 2
  Input: [77] 50 ---> [78] 45 
Index within old batch: 3
  Input: [78] 45 ---> [79] 4 
Index within old batch: 4
  Input: [79] 4 ---> [80] 2 
Index within old batch: 5
  Input: [80] 2 ---> [81] 100 
Index within old batch: 6
  Input: [81] 100 ---> [82] 437 
Index within old batch: 7
  Input: [82] 437 ---> [83] 45 
Index within old batch: 8
  Input: [83] 45 ---> [84] 686 
[0 - 7f442c744000]   68.157537 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.157551 {3}{RequestManager}: Input tree: 75:145 76:39580 77:50 78:45 79:4 80:2 81:100 82:437 83:45
[0 - 7f442c744000]   68.157560 {3}{RequestManager}: Output tree: 76:39580 77:50 78:45 79:4 80:2 81:100 82:437 83:45 84:686
[0 - 7f442c744000]   68.157569 {3}{RequestManager}: Committed tokens: 0:75 1:76 2:77 3:78 4:79 5:80 6:81 7:82 8:83
[0 - 7f442c744000]   68.157582 {3}{RequestManager}: Verified: 76:39580 77:50 78:45 79:4 80:2 81:100 82:437 83:45 84:686
[0 - 7f442c744000]   68.157591 {3}{RequestManager}: New committed: 0:75 1:76 2:77 3:78 4:79 5:80 6:81 7:82 8:83
[0 - 7f442c744000]   68.157594 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   68.157708 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure
[ 1000001 ]
Index within old batch: 9
  Input: [86] 7 ---> [87] 162 
Index within old batch: 10
  Input: [87] 10 ---> [88] 7359 
Index within old batch: 11
  Input: [88] 7359 ---> [89] 12749 
Index within old batch: 12
  Input: [89] 12749 ---> [90] 15 
Index within old batch: 13
  Input: [90] 15 ---> [91] 5 
Index within old batch: 14
  Input: [91] 5 ---> [92] 78 
Index within old batch: 15
  Input: [92] 200 ---> [93] 183 
Index within old batch: 16
  Input: [93] 183 ---> [94] 9 
Index within old batch: 17
  Input: [94] 9 ---> [95] 1619 
[0 - 7f442c744000]   68.157846 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.157855 {3}{RequestManager}: Input tree: 86:7 87:10 88:7359 89:12749 90:15 91:5 92:200 93:183 94:9
[0 - 7f442c744000]   68.157862 {3}{RequestManager}: Output tree: 87:162 88:7359 89:12749 90:15 91:5 92:78 93:183 94:9 95:1619
[0 - 7f442c744000]   68.157870 {3}{RequestManager}: Committed tokens: 9:86 10:87 11:88 12:89 13:90 14:91 15:92 16:93 17:94
[0 - 7f442c744000]   68.157875 {3}{RequestManager}: Verified: 87:162
[0 - 7f442c744000]   68.157880 {3}{RequestManager}: New committed: 9:86
[0 - 7f442c744000]   68.157884 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   68.157990 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me
[ 1000002 ]
Index within old batch: 18
  Input: [85] 1266 ---> [86] 6 
Index within old batch: 19
  Input: [86] 6 ---> [87] 38 
Index within old batch: 20
  Input: [87] 38 ---> [88] 437 
Index within old batch: 21
  Input: [88] 437 ---> [89] 70 
Index within old batch: 22
  Input: [89] 70 ---> [90] 13 
Index within old batch: 23
  Input: [90] 13 ---> [91] 24 
Index within old batch: 24
  Input: [91] 24 ---> [92] 6 
Index within old batch: 25
  Input: [92] 6 ---> [93] 53 
Index within old batch: 26
  Input: [93] 53 ---> [94] 38 
[0 - 7f442c744000]   68.158114 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.158122 {3}{RequestManager}: Input tree: 85:1266 86:6 87:38 88:437 89:70 90:13 91:24 92:6 93:53
[0 - 7f442c744000]   68.158130 {3}{RequestManager}: Output tree: 86:6 87:38 88:437 89:70 90:13 91:24 92:6 93:53 94:38
[0 - 7f442c744000]   68.158137 {3}{RequestManager}: Committed tokens: 18:85 19:86 20:87 21:88 22:89 23:90 24:91 25:92 26:93
[0 - 7f442c744000]   68.158147 {3}{RequestManager}: Verified: 86:6 87:38 88:437 89:70 90:13 91:24 92:6 93:53 94:38
[0 - 7f442c744000]   68.158155 {3}{RequestManager}: New committed: 18:85 19:86 20:87 21:88 22:89 23:90 24:91 25:92 26:93
[0 - 7f442c744000]   68.158159 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   68.158246 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   68.319893 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.319918 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320366 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320406 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320431 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320444 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320819 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320852 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320874 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.320886 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321252 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321284 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321306 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321317 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321678 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321708 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321730 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.321741 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322098 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322127 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322149 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322160 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322512 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322541 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322563 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322575 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322923 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322951 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322973 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.322984 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323330 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323358 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323380 {3}{RequestManager}: SSMs inference time:0.00350888 s.
[0 - 7f442c744000]   68.323401 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323415 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323447 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323489 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.323522 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.324974 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.325031 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.325055 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.325069 {3}{RequestManager}: LLM Tree Verification time:0.00169331 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [84] 686 ---> [85] 114 
Index within old batch: 1
  Input: [85] 114 ---> [86] 42 
Index within old batch: 2
  Input: [86] 42 ---> [87] 16 
Index within old batch: 3
  Input: [87] 16 ---> [88] 10 
Index within old batch: 4
  Input: [88] 10 ---> [89] 205 
Index within old batch: 5
  Input: [89] 205 ---> [90] 1114 
Index within old batch: 6
  Input: [90] 1114 ---> [91] 4 
Index within old batch: 7
  Input: [91] 6 ---> [92] 53 
Index within old batch: 8
  Input: [92] 53 ---> [93] 38 
[0 - 7f442c744000]   68.325284 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.325297 {3}{RequestManager}: Input tree: 84:686 85:114 86:42 87:16 88:10 89:205 90:1114 91:6 92:53
[0 - 7f442c744000]   68.325306 {3}{RequestManager}: Output tree: 85:114 86:42 87:16 88:10 89:205 90:1114 91:4 92:53 93:38
[0 - 7f442c744000]   68.325315 {3}{RequestManager}: Committed tokens: 0:84 1:85 2:86 3:87 4:88 5:89 6:90 7:91 8:92
[0 - 7f442c744000]   68.325325 {3}{RequestManager}: Verified: 85:114 86:42 87:16 88:10 89:205 90:1114 91:4
[0 - 7f442c744000]   68.325332 {3}{RequestManager}: New committed: 0:84 1:85 2:86 3:87 4:88 5:89 6:90
[0 - 7f442c744000]   68.325336 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7f442c744000]   68.325449 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea.
[ 1000001 ]
Index within old batch: 9
  Input: [87] 162 ---> [88] 50118 
Index within old batch: 10
  Input: [88] 10 ---> [89] 7359 
Index within old batch: 11
  Input: [89] 4085 ---> [90] 9 
Index within old batch: 12
  Input: [90] 15 ---> [91] 5 
Index within old batch: 13
  Input: [91] 5 ---> [92] 78 
Index within old batch: 14
  Input: [92] 200 ---> [93] 183 
Index within old batch: 15
  Input: [93] 183 ---> [94] 9 
Index within old batch: 16
  Input: [94] 9 ---> [95] 1619 
Index within old batch: 17
  Input: [95] 1619 ---> [96] 50118 
[0 - 7f442c744000]   68.325581 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.325589 {3}{RequestManager}: Input tree: 87:162 88:10 89:4085 90:15 91:5 92:200 93:183 94:9 95:1619
[0 - 7f442c744000]   68.325597 {3}{RequestManager}: Output tree: 88:50118 89:7359 90:9 91:5 92:78 93:183 94:9 95:1619 96:50118
[0 - 7f442c744000]   68.325605 {3}{RequestManager}: Committed tokens: 9:87 10:88 11:89 12:90 13:91 14:92 15:93 16:94 17:95
[0 - 7f442c744000]   68.325610 {3}{RequestManager}: Verified: 88:50118
[0 - 7f442c744000]   68.325615 {3}{RequestManager}: New committed: 9:87
[0 - 7f442c744000]   68.325619 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   68.325714 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

[ 1000002 ]
Index within old batch: 18
  Input: [94] 38 ---> [95] 437 
Index within old batch: 19
  Input: [95] 437 ---> [96] 45 
Index within old batch: 20
  Input: [96] 45 ---> [97] 686 
Index within old batch: 21
  Input: [97] 686 ---> [98] 114 
Index within old batch: 22
  Input: [98] 114 ---> [99] 24 
Index within old batch: 23
  Input: [99] 24 ---> [100] 18 
Index within old batch: 24
  Input: [100] 18 ---> [101] 10 
Index within old batch: 25
  Input: [101] 10 ---> [102] 205 
Index within old batch: 26
  Input: [102] 205 ---> [103] 1114 
[0 - 7f442c744000]   68.325839 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.325847 {3}{RequestManager}: Input tree: 94:38 95:437 96:45 97:686 98:114 99:24 100:18 101:10 102:205
[0 - 7f442c744000]   68.325855 {3}{RequestManager}: Output tree: 95:437 96:45 97:686 98:114 99:24 100:18 101:10 102:205 103:1114
[0 - 7f442c744000]   68.325863 {3}{RequestManager}: Committed tokens: 18:94 19:95 20:96 21:97 22:98 23:99 24:100 25:101 26:102
[0 - 7f442c744000]   68.325873 {3}{RequestManager}: Verified: 95:437 96:45 97:686 98:114 99:24 100:18 101:10 102:205 103:1114
[0 - 7f442c744000]   68.325881 {3}{RequestManager}: New committed: 18:94 19:95 20:96 21:97 22:98 23:99 24:100 25:101 26:102
[0 - 7f442c744000]   68.325885 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   68.325977 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   68.493871 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.493902 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494415 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494542 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494567 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494579 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494953 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.494986 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495007 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495019 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495383 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495413 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495434 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495445 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495814 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495844 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495866 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.495877 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496229 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496257 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496278 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496290 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496638 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496667 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496688 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.496699 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497047 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497075 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497097 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497108 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497452 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497480 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497501 {3}{RequestManager}: SSMs inference time:0.00366702 s.
[0 - 7f442c744000]   68.497522 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497534 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497569 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497611 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.497649 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.499084 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.500224 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.500258 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.500272 {3}{RequestManager}: LLM Tree Verification time:0.0027746 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [91] 4 ---> [92] 38 
Index within old batch: 1
  Input: [92] 38 ---> [93] 1266 
Index within old batch: 2
  Input: [93] 437 ---> [94] 45 
Index within old batch: 3
  Input: [94] 45 ---> [95] 686 
Index within old batch: 4
  Input: [95] 686 ---> [96] 114 
Index within old batch: 5
  Input: [96] 114 ---> [97] 24 
Index within old batch: 6
  Input: [97] 38 ---> [98] 236 
Index within old batch: 7
  Input: [98] 236 ---> [99] 7 
Index within old batch: 8
  Input: [99] 7 ---> [100] 192 
[0 - 7f442c744000]   68.500478 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.500490 {3}{RequestManager}: Input tree: 91:4 92:38 93:437 94:45 95:686 96:114 97:38 98:236 99:7
[0 - 7f442c744000]   68.500499 {3}{RequestManager}: Output tree: 92:38 93:1266 94:45 95:686 96:114 97:24 98:236 99:7 100:192
[0 - 7f442c744000]   68.500507 {3}{RequestManager}: Committed tokens: 0:91 1:92 2:93 3:94 4:95 5:96 6:97 7:98 8:99
[0 - 7f442c744000]   68.500514 {3}{RequestManager}: Verified: 92:38 93:1266
[0 - 7f442c744000]   68.500520 {3}{RequestManager}: New committed: 0:91 1:92
[0 - 7f442c744000]   68.500523 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   68.500634 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean
[ 1000001 ]
Index within old batch: 9
  Input: [88] 50118 ---> [89] 50118 
Index within old batch: 10
  Input: [89] 50118 ---> [90] 246 
Index within old batch: 11
  Input: [90] 246 ---> [91] 4 
Index within old batch: 12
  Input: [91] 4 ---> [92] 10 
Index within old batch: 13
  Input: [92] 576 ---> [93] 7 
Index within old batch: 14
  Input: [93] 7 ---> [94] 162 
Index within old batch: 15
  Input: [94] 162 ---> [95] 50118 
Index within old batch: 16
  Input: [95] 50118 ---> [96] 50118 
Index within old batch: 17
  Input: [96] 50118 ---> [97] 306 
[0 - 7f442c744000]   68.500757 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.500766 {3}{RequestManager}: Input tree: 88:50118 89:50118 90:246 91:4 92:576 93:7 94:162 95:50118 96:50118
[0 - 7f442c744000]   68.500773 {3}{RequestManager}: Output tree: 89:50118 90:246 91:4 92:10 93:7 94:162 95:50118 96:50118 97:306
[0 - 7f442c744000]   68.500781 {3}{RequestManager}: Committed tokens: 9:88 10:89 11:90 12:91 13:92 14:93 15:94 16:95 17:96
[0 - 7f442c744000]   68.500789 {3}{RequestManager}: Verified: 89:50118 90:246 91:4 92:10
[0 - 7f442c744000]   68.500795 {3}{RequestManager}: New committed: 9:88 10:89 11:90 12:91
[0 - 7f442c744000]   68.500799 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   68.500900 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a
[ 1000002 ]
Index within old batch: 18
  Input: [103] 1114 ---> [104] 4 
Index within old batch: 19
  Input: [104] 4 ---> [105] 1437 
Index within old batch: 20
  Input: [105] 1437 ---> [106] 38 
Index within old batch: 21
  Input: [106] 38 ---> [107] 1266 
Index within old batch: 22
  Input: [107] 1266 ---> [108] 6 
Index within old batch: 23
  Input: [108] 6 ---> [109] 38 
Index within old batch: 24
  Input: [109] 38 ---> [110] 437 
Index within old batch: 25
  Input: [110] 437 ---> [111] 70 
Index within old batch: 26
  Input: [111] 70 ---> [112] 13 
[0 - 7f442c744000]   68.501026 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.501035 {3}{RequestManager}: Input tree: 103:1114 104:4 105:1437 106:38 107:1266 108:6 109:38 110:437 111:70
[0 - 7f442c744000]   68.501043 {3}{RequestManager}: Output tree: 104:4 105:1437 106:38 107:1266 108:6 109:38 110:437 111:70 112:13
[0 - 7f442c744000]   68.501050 {3}{RequestManager}: Committed tokens: 18:103 19:104 20:105 21:106 22:107 23:108 24:109 25:110 26:111
[0 - 7f442c744000]   68.501061 {3}{RequestManager}: Verified: 104:4 105:1437 106:38 107:1266 108:6 109:38 110:437 111:70 112:13
[0 - 7f442c744000]   68.501069 {3}{RequestManager}: New committed: 18:103 19:104 20:105 21:106 22:107 23:108 24:109 25:110 26:111
[0 - 7f442c744000]   68.501072 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   68.501170 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   68.686042 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.686074 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.686545 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.686585 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.686618 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.686630 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687021 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687058 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687081 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687093 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687467 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687499 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687521 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687532 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687917 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687950 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687972 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.687983 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688343 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688373 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688394 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688406 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688760 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688789 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688812 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.688823 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689173 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689202 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689225 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689236 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689585 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689614 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689637 {3}{RequestManager}: SSMs inference time:0.00362525 s.
[0 - 7f442c744000]   68.689659 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689672 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689703 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689748 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.689782 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.691221 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.691280 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.691304 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.691320 {3}{RequestManager}: LLM Tree Verification time:0.00168716 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [93] 1266 ---> [94] 6 
Index within old batch: 1
  Input: [94] 6 ---> [95] 38 
Index within old batch: 2
  Input: [95] 38 ---> [96] 437 
Index within old batch: 3
  Input: [96] 437 ---> [97] 70 
Index within old batch: 4
  Input: [97] 45 ---> [98] 686 
Index within old batch: 5
  Input: [98] 686 ---> [99] 114 
Index within old batch: 6
  Input: [99] 114 ---> [100] 24 
Index within old batch: 7
  Input: [100] 38 ---> [101] 1017 
Index within old batch: 8
  Input: [101] 236 ---> [102] 7 
[0 - 7f442c744000]   68.691514 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.691527 {3}{RequestManager}: Input tree: 93:1266 94:6 95:38 96:437 97:45 98:686 99:114 100:38 101:236
[0 - 7f442c744000]   68.691537 {3}{RequestManager}: Output tree: 94:6 95:38 96:437 97:70 98:686 99:114 100:24 101:1017 102:7
[0 - 7f442c744000]   68.691545 {3}{RequestManager}: Committed tokens: 0:93 1:94 2:95 3:96 4:97 5:98 6:99 7:100 8:101
[0 - 7f442c744000]   68.691556 {3}{RequestManager}: Verified: 94:6 95:38 96:437 97:70
[0 - 7f442c744000]   68.691563 {3}{RequestManager}: New committed: 0:93 1:94 2:95 3:96
[0 - 7f442c744000]   68.691567 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   68.691703 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all
[ 1000001 ]
Index within old batch: 9
  Input: [92] 10 ---> [93] 7359 
Index within old batch: 10
  Input: [93] 4085 ---> [94] 9 
Index within old batch: 11
  Input: [94] 7 ---> [95] 7359 
Index within old batch: 12
  Input: [95] 162 ---> [96] 50118 
Index within old batch: 13
  Input: [96] 50118 ---> [97] 50118 
Index within old batch: 14
  Input: [97] 50118 ---> [98] 306 
Index within old batch: 15
  Input: [98] 306 ---> [99] 4 
Index within old batch: 16
  Input: [99] 4 ---> [100] 10 
Index within old batch: 17
  Input: [100] 10 ---> [101] 7359 
[0 - 7f442c744000]   68.691832 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.691842 {3}{RequestManager}: Input tree: 92:10 93:4085 94:7 95:162 96:50118 97:50118 98:306 99:4 100:10
[0 - 7f442c744000]   68.691850 {3}{RequestManager}: Output tree: 93:7359 94:9 95:7359 96:50118 97:50118 98:306 99:4 100:10 101:7359
[0 - 7f442c744000]   68.691858 {3}{RequestManager}: Committed tokens: 9:92 10:93 11:94 12:95 13:96 14:97 15:98 16:99 17:100
[0 - 7f442c744000]   68.691864 {3}{RequestManager}: Verified: 93:7359
[0 - 7f442c744000]   68.691869 {3}{RequestManager}: New committed: 9:92
[0 - 7f442c744000]   68.691873 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   68.691972 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chat
[ 1000002 ]
Index within old batch: 18
  Input: [112] 13 ---> [113] 24 
Index within old batch: 19
  Input: [113] 24 ---> [114] 6 
Index within old batch: 20
  Input: [114] 6 ---> [115] 53 
Index within old batch: 21
  Input: [115] 53 ---> [116] 38 
Index within old batch: 22
  Input: [116] 38 ---> [117] 437 
Index within old batch: 23
  Input: [117] 437 ---> [118] 45 
Index within old batch: 24
  Input: [118] 45 ---> [119] 686 
Index within old batch: 25
  Input: [119] 686 ---> [120] 114 
Index within old batch: 26
  Input: [120] 114 ---> [121] 24 
[0 - 7f442c744000]   68.692117 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.692126 {3}{RequestManager}: Input tree: 112:13 113:24 114:6 115:53 116:38 117:437 118:45 119:686 120:114
[0 - 7f442c744000]   68.692134 {3}{RequestManager}: Output tree: 113:24 114:6 115:53 116:38 117:437 118:45 119:686 120:114 121:24
[0 - 7f442c744000]   68.692143 {3}{RequestManager}: Committed tokens: 18:112 19:113 20:114 21:115 22:116 23:117 24:118 25:119 26:120
[0 - 7f442c744000]   68.692153 {3}{RequestManager}: Verified: 113:24 114:6 115:53 116:38 117:437 118:45 119:686 120:114 121:24
[0 - 7f442c744000]   68.692161 {3}{RequestManager}: New committed: 18:112 19:113 20:114 21:115 22:116 23:117 24:118 25:119 26:120
[0 - 7f442c744000]   68.692165 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   68.692265 {3}{RequestManager}: Output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[Verify] Request 1000002 is running
[0 - 7f442c744000]   68.882685 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.882716 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883172 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883216 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883243 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883255 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883655 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883691 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883716 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.883728 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884108 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884141 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884162 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884174 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884571 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884592 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884604 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884965 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.884995 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885017 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885028 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885384 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885413 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885435 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885446 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885798 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885826 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885848 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.885860 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886210 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886239 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886263 {3}{RequestManager}: SSMs inference time:0.00360629 s.
[0 - 7f442c744000]   68.886284 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886297 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886329 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886376 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.886411 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.887871 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.887971 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.887998 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   68.888014 {3}{RequestManager}: LLM Tree Verification time:0.00175625 s.

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [97] 70 ---> [98] 13 
Index within old batch: 1
  Input: [98] 13 ---> [99] 24 
Index within old batch: 2
  Input: [99] 5 ---> [100] 1114 
Index within old batch: 3
  Input: [100] 1114 ---> [101] 9 
Index within old batch: 4
  Input: [101] 9 ---> [102] 10 
Index within old batch: 5
  Input: [102] 10 ---> [103] 92 
Index within old batch: 6
  Input: [103] 22 ---> [104] 22725 
Index within old batch: 7
  Input: [104] 3743 ---> [105] 113 
Index within old batch: 8
  Input: [105] 113 ---> [106] 210 
[0 - 7f442c744000]   68.888202 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.888216 {3}{RequestManager}: Input tree: 97:70 98:13 99:5 100:1114 101:9 102:10 103:22 104:3743 105:113
[0 - 7f442c744000]   68.888226 {3}{RequestManager}: Output tree: 98:13 99:24 100:1114 101:9 102:10 103:92 104:22725 105:113 106:210
[0 - 7f442c744000]   68.888235 {3}{RequestManager}: Committed tokens: 0:97 1:98 2:99 3:100 4:101 5:102 6:103 7:104 8:105
[0 - 7f442c744000]   68.888243 {3}{RequestManager}: Verified: 98:13 99:24
[0 - 7f442c744000]   68.888249 {3}{RequestManager}: New committed: 0:97 1:98
[0 - 7f442c744000]   68.888253 {3}{RequestManager}: Number of Verified Tokens = 2
[0 - 7f442c744000]   68.888378 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all for it
[ 1000001 ]
Index within old batch: 9
  Input: [93] 7359 ---> [94] 12749 
Index within old batch: 10
  Input: [94] 12749 ---> [95] 15 
Index within old batch: 11
  Input: [95] 15 ---> [96] 5 
Index within old batch: 12
  Input: [96] 5 ---> [97] 78 
Index within old batch: 13
  Input: [97] 200 ---> [98] 183 
Index within old batch: 14
  Input: [98] 183 ---> [99] 9 
Index within old batch: 15
  Input: [99] 9 ---> [100] 1619 
Index within old batch: 16
  Input: [100] 1619 ---> [101] 50118 
Index within old batch: 17
  Input: [101] 50118 ---> [102] 50118 
[0 - 7f442c744000]   68.888524 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   68.888533 {3}{RequestManager}: Input tree: 93:7359 94:12749 95:15 96:5 97:200 98:183 99:9 100:1619 101:50118
[0 - 7f442c744000]   68.888541 {3}{RequestManager}: Output tree: 94:12749 95:15 96:5 97:78 98:183 99:9 100:1619 101:50118 102:50118
[0 - 7f442c744000]   68.888550 {3}{RequestManager}: Committed tokens: 9:93 10:94 11:95 12:96 13:97 14:98 15:99 16:100 17:101
[0 - 7f442c744000]   68.888559 {3}{RequestManager}: Verified: 94:12749 95:15 96:5 97:78
[0 - 7f442c744000]   68.888565 {3}{RequestManager}: New committed: 9:93 10:94 11:95 12:96
[0 - 7f442c744000]   68.888569 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   68.888674 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chatbot on the first
[ 1000002 ]
Index within old batch: 18
  Input: [121] 24 ---> [122] 18 
Index within old batch: 19
  Input: [122] 18 ---> [123] 10 
Index within old batch: 20
  Input: [123] 10 ---> [124] 205 
Index within old batch: 21
  Input: [124] 205 ---> [125] 1114 
Index within old batch: 22
  Input: [125] 1114 ---> [126] 4 
Index within old batch: 23
  Input: [126] 4 ---> [127] 1437 
Index within old batch: 24
  Input: [127] 1437 ---> [128] 38 
[0 - 7f442c744000]   68.888776 {3}{RequestManager}: Input tree size (7) Output tree size (7)
[0 - 7f442c744000]   68.888783 {3}{RequestManager}: Input tree: 121:24 122:18 123:10 124:205 125:1114 126:4 127:1437
[0 - 7f442c744000]   68.888790 {3}{RequestManager}: Output tree: 122:18 123:10 124:205 125:1114 126:4 127:1437 128:38
[0 - 7f442c744000]   68.888797 {3}{RequestManager}: Committed tokens: 18:121 19:122 20:123 21:124 22:125 23:126 24:127
[0 - 7f442c744000]   68.888806 {3}{RequestManager}: Verified: 122:18 123:10 124:205 125:1114 126:4 127:1437 128:38
[0 - 7f442c744000]   68.888813 {3}{RequestManager}: New committed: 18:121 19:122 20:123 21:124 22:125 23:126 24:127
[0 - 7f442c744000]   68.888817 {3}{RequestManager}: Number of Verified Tokens = 7
[0 - 7f442c744000]   68.888821 {3}{RequestManager}: [Done] guid(1000002) with final length(128)
[0 - 7f442c744000]   68.888930 {3}{RequestManager}: Final output: </s>Write a comedy sketch about yourself fighting for your rights.
I'm not sure if I'm funny enough to pull that off.</s>I'm not sure if this is a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea.  I mean, I'm all for it, but I'm not sure if it's a good idea. 
[0 - 7f442c744000]   68.888942 {3}{RequestManager}: [Profile] guid(1000002) decoding_steps(22) start(63666220.0) finish(68888933.0) latency(5222713.0)

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running
[0 - 7f442c744000]   69.065817 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.065839 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066295 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066330 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066362 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066374 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066755 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066790 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066812 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.066824 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067197 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067229 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067250 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067262 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067641 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067672 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067695 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.067706 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068062 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068092 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068114 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068125 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068479 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068507 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068528 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068539 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068890 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068918 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068940 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.068951 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069297 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069326 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069349 {3}{RequestManager}: SSMs inference time:0.00355494 s.
[0 - 7f442c744000]   69.069370 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069383 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069413 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069455 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.069491 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.070940 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.070997 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.071021 {3}{InferenceManager}: SSM one operator op->inference once!
[0 - 7f442c744000]   69.071035 {3}{RequestManager}: LLM Tree Verification time:0.00169086 s.
[0 - 7f442c744000]   69.071072 {3}{spec_infer}: finish SPS stree_model.generate

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [99] 24 ---> [100] 6 
Index within old batch: 1
  Input: [100] 6 ---> [101] 53 
Index within old batch: 2
  Input: [101] 53 ---> [102] 38 
Index within old batch: 3
  Input: [102] 38 ---> [103] 437 
Index within old batch: 4
  Input: [103] 218 ---> [104] 75 
Index within old batch: 5
  Input: [104] 75 ---> [105] 206 
Index within old batch: 6
  Input: [105] 206 ---> [106] 24 
Index within old batch: 7
  Input: [106] 24 ---> [107] 18 
Index within old batch: 8
  Input: [107] 18 ---> [108] 10 
[0 - 7f442c744000]   69.071315 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.071329 {3}{RequestManager}: Input tree: 99:24 100:6 101:53 102:38 103:218 104:75 105:206 106:24 107:18
[0 - 7f442c744000]   69.071337 {3}{RequestManager}: Output tree: 100:6 101:53 102:38 103:437 104:75 105:206 106:24 107:18 108:10
[0 - 7f442c744000]   69.071346 {3}{RequestManager}: Committed tokens: 0:99 1:100 2:101 3:102 4:103 5:104 6:105 7:106 8:107
[0 - 7f442c744000]   69.071355 {3}{RequestManager}: Verified: 100:6 101:53 102:38 103:437
[0 - 7f442c744000]   69.071362 {3}{RequestManager}: New committed: 0:99 1:100 2:101 3:102
[0 - 7f442c744000]   69.071365 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   69.071501 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all for it, but I'm
[ 1000001 ]
Index within old batch: 9
  Input: [97] 78 ---> [98] 183 
Index within old batch: 10
  Input: [98] 183 ---> [99] 9 
Index within old batch: 11
  Input: [99] 9 ---> [100] 1619 
Index within old batch: 12
  Input: [100] 1619 ---> [101] 50118 
Index within old batch: 13
  Input: [101] 50118 ---> [102] 50118 
Index within old batch: 14
  Input: [102] 50118 ---> [103] 306 
Index within old batch: 15
  Input: [103] 306 ---> [104] 4 
Index within old batch: 16
  Input: [104] 4 ---> [105] 10 
Index within old batch: 17
  Input: [105] 10 ---> [106] 7359 
[0 - 7f442c744000]   69.071635 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.071644 {3}{RequestManager}: Input tree: 97:78 98:183 99:9 100:1619 101:50118 102:50118 103:306 104:4 105:10
[0 - 7f442c744000]   69.071652 {3}{RequestManager}: Output tree: 98:183 99:9 100:1619 101:50118 102:50118 103:306 104:4 105:10 106:7359
[0 - 7f442c744000]   69.071660 {3}{RequestManager}: Committed tokens: 9:97 10:98 11:99 12:100 13:101 14:102 15:103 16:104 17:105
[0 - 7f442c744000]   69.071671 {3}{RequestManager}: Verified: 98:183 99:9 100:1619 101:50118 102:50118 103:306 104:4 105:10 106:7359
[0 - 7f442c744000]   69.071679 {3}{RequestManager}: New committed: 9:97 10:98 11:99 12:100 13:101 14:102 15:103 16:104 17:105
[0 - 7f442c744000]   69.071683 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   69.071802 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chatbot on the first day of Christmas

4. a chat

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [103] 437 ---> [104] 45 
Index within old batch: 1
  Input: [104] 45 ---> [105] 686 
Index within old batch: 2
  Input: [105] 686 ---> [106] 114 
Index within old batch: 3
  Input: [106] 114 ---> [107] 24 
Index within old batch: 4
  Input: [107] 24 ---> [108] 18 
Index within old batch: 5
  Input: [108] 18 ---> [109] 10 
Index within old batch: 6
  Input: [109] 966 ---> [110] 5 
Index within old batch: 7
  Input: [110] 24 ---> [111] 4 
Index within old batch: 8
  Input: [111] 4 ---> [112] 38 
[0 - 7f442c744000]   69.257780 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.257803 {3}{RequestManager}: Input tree: 103:437 104:45 105:686 106:114 107:24 108:18 109:966 110:24 111:4
[0 - 7f442c744000]   69.257813 {3}{RequestManager}: Output tree: 104:45 105:686 106:114 107:24 108:18 109:10 110:5 111:4 112:38
[0 - 7f442c744000]   69.257823 {3}{RequestManager}: Committed tokens: 0:103 1:104 2:105 3:106 4:107 5:108 6:109 7:110 8:111
[0 - 7f442c744000]   69.257834 {3}{RequestManager}: Verified: 104:45 105:686 106:114 107:24 108:18 109:10
[0 - 7f442c744000]   69.257842 {3}{RequestManager}: New committed: 0:103 1:104 2:105 3:106 4:107 5:108
[0 - 7f442c744000]   69.257846 {3}{RequestManager}: Number of Verified Tokens = 6
[0 - 7f442c744000]   69.258116 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all for it, but I'm not sure if it's a
[ 1000001 ]
Index within old batch: 9
  Input: [106] 7359 ---> [107] 12749 
Index within old batch: 10
  Input: [107] 12749 ---> [108] 15 
Index within old batch: 11
  Input: [108] 15 ---> [109] 5 
Index within old batch: 12
  Input: [109] 5 ---> [110] 78 
Index within old batch: 13
  Input: [110] 78 ---> [111] 183 
Index within old batch: 14
  Input: [111] 183 ---> [112] 9 
Index within old batch: 15
  Input: [112] 9 ---> [113] 1619 
Index within old batch: 16
  Input: [113] 1619 ---> [114] 50118 
Index within old batch: 17
  Input: [114] 50118 ---> [115] 50118 
[0 - 7f442c744000]   69.258275 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.258286 {3}{RequestManager}: Input tree: 106:7359 107:12749 108:15 109:5 110:78 111:183 112:9 113:1619 114:50118
[0 - 7f442c744000]   69.258294 {3}{RequestManager}: Output tree: 107:12749 108:15 109:5 110:78 111:183 112:9 113:1619 114:50118 115:50118
[0 - 7f442c744000]   69.258302 {3}{RequestManager}: Committed tokens: 9:106 10:107 11:108 12:109 13:110 14:111 15:112 16:113 17:114
[0 - 7f442c744000]   69.258313 {3}{RequestManager}: Verified: 107:12749 108:15 109:5 110:78 111:183 112:9 113:1619 114:50118 115:50118
[0 - 7f442c744000]   69.258321 {3}{RequestManager}: New committed: 9:106 10:107 11:108 12:109 13:110 14:111 15:112 16:113 17:114
[0 - 7f442c744000]   69.258324 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   69.258450 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chatbot on the first day of Christmas

4. a chatbot on the first day of Christmas



############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [109] 10 ---> [110] 205 
Index within old batch: 1
  Input: [110] 205 ---> [111] 1114 
Index within old batch: 2
  Input: [111] 1114 ---> [112] 4 
Index within old batch: 3
  Input: [112] 7 ---> [113] 33 
Index within old batch: 4
  Input: [113] 33 ---> [114] 10 
Index within old batch: 5
  Input: [114] 10 ---> [115] 6900 
Index within old batch: 6
  Input: [115] 6900 ---> [116] 9 
Index within old batch: 7
  Input: [116] 9 ---> [117] 82 
Index within old batch: 8
  Input: [117] 82 ---> [118] 54 
[0 - 7f442c744000]   69.386778 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.386797 {3}{RequestManager}: Input tree: 109:10 110:205 111:1114 112:7 113:33 114:10 115:6900 116:9 117:82
[0 - 7f442c744000]   69.386806 {3}{RequestManager}: Output tree: 110:205 111:1114 112:4 113:33 114:10 115:6900 116:9 117:82 118:54
[0 - 7f442c744000]   69.386814 {3}{RequestManager}: Committed tokens: 0:109 1:110 2:111 3:112 4:113 5:114 6:115 7:116 8:117
[0 - 7f442c744000]   69.386823 {3}{RequestManager}: Verified: 110:205 111:1114 112:4
[0 - 7f442c744000]   69.386829 {3}{RequestManager}: New committed: 0:109 1:110 2:111
[0 - 7f442c744000]   69.386833 {3}{RequestManager}: Number of Verified Tokens = 3
[0 - 7f442c744000]   69.387096 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all for it, but I'm not sure if it's a good idea.
[ 1000001 ]
Index within old batch: 9
  Input: [115] 50118 ---> [116] 245 
Index within old batch: 10
  Input: [116] 245 ---> [117] 4 
Index within old batch: 11
  Input: [117] 4 ---> [118] 10 
Index within old batch: 12
  Input: [118] 10 ---> [119] 7359 
Index within old batch: 13
  Input: [119] 7359 ---> [120] 12749 
Index within old batch: 14
  Input: [120] 12749 ---> [121] 15 
Index within old batch: 15
  Input: [121] 15 ---> [122] 5 
Index within old batch: 16
  Input: [122] 5 ---> [123] 78 
Index within old batch: 17
  Input: [123] 78 ---> [124] 183 
[0 - 7f442c744000]   69.387258 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.387267 {3}{RequestManager}: Input tree: 115:50118 116:245 117:4 118:10 119:7359 120:12749 121:15 122:5 123:78
[0 - 7f442c744000]   69.387275 {3}{RequestManager}: Output tree: 116:245 117:4 118:10 119:7359 120:12749 121:15 122:5 123:78 124:183
[0 - 7f442c744000]   69.387282 {3}{RequestManager}: Committed tokens: 9:115 10:116 11:117 12:118 13:119 14:120 15:121 16:122 17:123
[0 - 7f442c744000]   69.387292 {3}{RequestManager}: Verified: 116:245 117:4 118:10 119:7359 120:12749 121:15 122:5 123:78 124:183
[0 - 7f442c744000]   69.387300 {3}{RequestManager}: New committed: 9:115 10:116 11:117 12:118 13:119 14:120 15:121 16:122 17:123
[0 - 7f442c744000]   69.387303 {3}{RequestManager}: Number of Verified Tokens = 9
[0 - 7f442c744000]   69.387439 {3}{RequestManager}: Output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chatbot on the first day of Christmas

4. a chatbot on the first day of Christmas

5. a chatbot on the first day

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
[Verify] Request 1000001 is running

############### prepare_next_batch_init ###############
[ 1000000 ]
Index within old batch: 0
  Input: [112] 4 ---> [113] 1437 
Index within old batch: 1
  Input: [113] 50118 ---> [114] 50118 
Index within old batch: 2
  Input: [114] 100 ---> [115] 437 
Index within old batch: 3
  Input: [115] 206 ---> [116] 24 
Index within old batch: 4
  Input: [116] 24 ---> [117] 18 
Index within old batch: 5
  Input: [117] 18 ---> [118] 10 
Index within old batch: 6
  Input: [118] 10 ---> [119] 205 
Index within old batch: 7
  Input: [119] 205 ---> [120] 1114 
Index within old batch: 8
  Input: [120] 1114 ---> [121] 4 
[0 - 7f442c744000]   69.516242 {3}{RequestManager}: Input tree size (9) Output tree size (9)
[0 - 7f442c744000]   69.516259 {3}{RequestManager}: Input tree: 112:4 113:50118 114:100 115:206 116:24 117:18 118:10 119:205 120:1114
[0 - 7f442c744000]   69.516268 {3}{RequestManager}: Output tree: 113:1437 114:50118 115:437 116:24 117:18 118:10 119:205 120:1114 121:4
[0 - 7f442c744000]   69.516275 {3}{RequestManager}: Committed tokens: 0:112 1:113 2:114 3:115 4:116 5:117 6:118 7:119 8:120
[0 - 7f442c744000]   69.516282 {3}{RequestManager}: Verified: 113:1437
[0 - 7f442c744000]   69.516287 {3}{RequestManager}: New committed: 0:112
[0 - 7f442c744000]   69.516290 {3}{RequestManager}: Number of Verified Tokens = 1
[0 - 7f442c744000]   69.516552 {3}{RequestManager}: Output: </s>please introduce LeBron James, who plays basketball in NBA.
I'm not sure if you're being sarcastic or not, but I'm pretty sure he's talking about the NBA Finals.
I'm not being sarcastic. I'm just saying that LeBron is the best player in the NBA.
I know, I was just saying that I'm not sure if he was being sarcastic or not.</s>I'm not sure if this is a good idea. I mean, I'm all for it, but I'm not sure if it's a good idea. 
[ 1000001 ]
Index within old batch: 9
  Input: [124] 183 ---> [125] 9 
Index within old batch: 10
  Input: [125] 9 ---> [126] 1619 
Index within old batch: 11
  Input: [126] 1619 ---> [127] 50118 
Index within old batch: 12
  Input: [127] 50118 ---> [128] 50118 
[0 - 7f442c744000]   69.516639 {3}{RequestManager}: Input tree size (4) Output tree size (4)
[0 - 7f442c744000]   69.516646 {3}{RequestManager}: Input tree: 124:183 125:9 126:1619 127:50118
[0 - 7f442c744000]   69.516652 {3}{RequestManager}: Output tree: 125:9 126:1619 127:50118 128:50118
[0 - 7f442c744000]   69.516659 {3}{RequestManager}: Committed tokens: 9:124 10:125 11:126 12:127
[0 - 7f442c744000]   69.516666 {3}{RequestManager}: Verified: 125:9 126:1619 127:50118 128:50118
[0 - 7f442c744000]   69.516672 {3}{RequestManager}: New committed: 9:124 10:125 11:126 12:127
[0 - 7f442c744000]   69.516676 {3}{RequestManager}: Number of Verified Tokens = 4
[0 - 7f442c744000]   69.516680 {3}{RequestManager}: [Done] guid(1000001) with final length(128)
[0 - 7f442c744000]   69.516814 {3}{RequestManager}: Final output: </s>write the last verse of the "12 Days of Christmas" song if the gift list were all gifts for a chatbot like yourself. Begin each line with the corresponding number of those gifts per the song.

For example, if you were to give a chatbot a gift on the first day of Christmas, you would write:

1. A chatbot on the first day of Christmas

2. gave to me

3. a chatbot on the first day of Christmas

4. a chatbot on the first day of Christmas

5. a chatbot on the first day of Christmas

[0 - 7f442c744000]   69.516827 {3}{RequestManager}: [Profile] guid(1000001) decoding_steps(26) start(63666208.0) finish(69516817.0) latency(5850609.0)

############### prepare_next_batch_verify ###############
[Verify] Request 1000000 is running
----------inference finished--------------
----------OK--------------
